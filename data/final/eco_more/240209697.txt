We study a three-layer data market comprising users (data owners), platforms, and a data buyer. Each user benefits from platform services in exchange for data, incurring privacy loss when their data, albeit noisily, is shared with the buyer. The user chooses platforms to share data with, while platforms decide on data noise levels and pricing before selling to the buyer. The buyer selects platforms to purchase data from. We model these interactions via a multistage game, focusing on the subgame Nash equilibrium. We find that when the buyer places a high value on user data (and platforms can command high prices), all platforms offer services to the user who joins and shares data with every platform. Conversely, when the buyer’s valuation of user data is low, only large platforms with low service costs can afford to serve users. In this scenario, users exclusively join and share data with these low-cost platforms. Interestingly, increased competition benefits the buyer, not the user: as the number of platforms increases, the user utility does not necessarily improve while the buyer utility improves. However, increasing the competition improves the overall utilitarian welfare. Building on our analysis, we then study regulations to improve the user utility. We discover that banning data sharing maximizes user utility only when all platforms are low-cost. In mixed markets of highand low-cost platforms, users prefer a minimum noise mandate over a sharing ban. Imposing this mandate on high-cost platforms and banning data sharing for low-cost ones further enhances user utility. 1 introduction In the digital era, online platforms have become integral to our daily lives, offering a plethora of services that range from social networking to personalized shopping experiences. While these platforms provide convenience and connectivity, they also engage in extensive data collection practices. Users’ interactions with these platforms generate vast amounts of data, encompassing personal preferences, behaviors, and other sensitive information. This data, a valuable commodity, is often shared with third-party buyers. *University of California, Berkeley †Fuqua School of Business, Duke University ‡Rotman School of Management, University of Toronto. ar X
iv :2
40 2. 09 69
7v 2
[ ec
on .T
H ]
2 0
Fe b
20 24
With the advent of new functionalities by information technology companies such as Apple or Google that reduce or eliminate tracking via third-party cookies, there has been an increased reliance on first-party data, which is information gathered by a company from its own user base. For example, as elaborated in Cross [2023b], major retailers such as BestBuy and Walmart capitalize on this data through loyalty programs, customer purchase records, and subscriptions. They do this by selling the data to advertisers who aim to place targeted ads on the retailers’ websites or across various online platforms. In a similar vein, Cross [2023a] notes that Mastercard, a leading payment technology firm, trades cardholder transaction information via third-party online data marketplaces and its internal “Data and Services” division. This practice grants numerous entities access to extensive consumer data and insights. For instance, their Intelligent Targeting service allows businesses to leverage “Mastercard 360◦ data insights” to create and execute advertising campaigns that specifically target potential “high-value” customers. In this complex digital ecosystem, users face the dilemma of benefiting from the services provided by these platforms while potentially compromising their privacy. Platforms, on the other hand, must balance the profitability derived from data sharing with the need to maintain user trust and satisfaction. This interplay between users’ privacy concerns and the economic incentives of platforms raises important questions about the sustainability of current data market practices. Notable regulatory actions have been taken to improve user experiences. For instance, the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) have been introduced to protect user privacy and to limit the amount of data shared with the platforms. Although, at first sight, this helps users, there have been several studies pointing to its detrimental impact both on platforms and users. This is because these regulations have led to a more concentrated market structure by limiting competition in data markets. This results from the regulation’s restrictions on data sharing, which may slow down data-based innovations and services. For instance, studies have shown that GDPR has led to a significant reduction in the number of available apps in the market, with new app entries falling by half following the regulation’s implementation (Janssen et al. [2022]). This decline in market entries indicates a potential loss of innovation as new and smaller players find it increasingly difficult to compete under these regulations. This effect is particularly detrimental to small companies that rely on these data synergies for innovation and market growth (see also Gal and Aviv [2020]). In this paper, we aim to understand the user and platform strategies that arise when considering the collection and usage of user data. We also explore regulatory frameworks that could be implemented to enhance user utility while maintaining the benefits provided by online platforms. 1.1 our model and main results We adopt an analytical-modeling-based approach and develop a framework to examine the choices of both users and platforms, taking into account users’ privacy concerns. We also explore regulations and policies that could alleviate these concerns. In our model, multiple platforms interact with a user who owns data and seeks the services of these platforms, as well as with a third-party
buyer interested in purchasing the user’s data from the platforms. Throughout our study, we consider MasterCard as an example of such a platform. The user represents an individual in a specific population segment with particular preferences, and the buyer is conceptualized as a third-party advertiser aiming to understand and leverage these user preferences for its own benefit. The utility of each platform is determined by three factors: the gains obtained from using user data to provide services, potential payments received from buyers purchasing this data, and the costs incurred in providing services to the user. Let us highlight the cost of services, as it plays an important role in our analysis. It is particularly important to distinguish between high-cost and low-cost platforms. The low-cost platforms are those that do not necessarily need to sell data to stay in the market, as their gains from the service already cover their costs of operation. In our leading examples, low-cost platforms are exemplified by payment-technology companies or big retailers, where either their operational costs per user are low, or their main source of revenue is not derived from selling data. Conversely, for high-cost platforms, the gains from service provision are not enough to offset their operational costs. Hence, they require a minimum level of data selling to be incentivized to enter the market (i.e., to provide services to the user). Examples of these platforms typically include smaller firms or companies that heavily rely on data collection for advertising to ensure their continued operation. We model the interaction between the players as a multi-stage game in which, in the first stage, the platforms decide whether they want to provide services to the user and the privacy level they want to deliver to the data buyer (so that the user is incentivized to share). We model the privacy level that the platform provides as a noise level added to the user data. Adding a suitable level of noise is common practice in, for example, the analysis of census data Abowd [2018] and is theoretically justified in the literature on differential privacy Dwork et al. [2014]. In the second stage of the game, the user decides which platform to join. The user’s utility is the service quality of the platform, proportional to the amount of user information revealed to the platform minus the user’s privacy loss. The privacy loss refers to the amount of information all platforms reveal to the data buyer. In the third and fourth stages, the platforms determine the price to charge the data buyer, and the buyer decides from which platforms to purchase. The data buyer’s utility is the user’s leaked information from all platforms minus the payments made to acquire this information. Again, the data buyer can be viewed as a third-party advertiser in our example mentioned above who pays the platforms to obtain user data. They then use this data for potential gain, with their gain being proportional to the accuracy of the user data obtained. Equilibrium characterization and insights: We adopt the subgame Nash equilibrium as our equilibrium concept and use backward induction to characterize it. Finding the equilibrium of this game is complex mainly because the platforms’ choice of noise level not only directly impacts the user’s utility but also changes the data buyer’s decision, which indirectly impacts the user’s utility. Also, the competition among platforms further complicates the dynamic of the game. For instance, a platform may still be incentivized to sell data at a noise level higher than needed for
the user to be willing to share their data. At first glance, this may seem unreasonable as it reduces the quality of the data that they can sell, and hence, the data buyer would pay less for it. However, increasing the privacy could persuade the user to forgo other platforms that offer less stringent privacy guarantees and only use this platform’s service. As a result, this can give a monopoly to the platform in terms of access to the user’s data, and hence, the data buyer would end up paying more to them. We start our analysis of equilibrium by focusing on the case of two platforms. This setting allows us to infer insights about equilibrium properties that are applicable to more general cases. Here, we identify up to three primary regimes, depending on the data buyer’s valuation of user data acquisition, denoted by β in our model. When β falls below a certain threshold, neither of the two platforms enters the market due to insufficient payment to cover service costs. This regime ceases to exist when at least one platform is low-cost, meaning it can cover service costs solely through service provision without needing to sell data. Conversely, when β is sufficiently high, both platforms will participate in the market. Interestingly, in this case, and when the user is privacy-conscious and requires a minimum non-zero level of noise for data sharing, the user utility is equal to zero at equilibrium. However, as the data buyer compensates each platform at the marginal value of the data, their utility remains positive. Finally, there exists an intermediate regime of β, where only the lower-cost platform engages in the market. Here, both the user and the data buyer utilities are zero at equilibrium, indicating that having both platforms in the market to compete benefits the data buyers but not the user. We demonstrate that these findings extend to the general scenario with K > 2 platforms. Specifically, we establish that when β exceeds a certain threshold, signifying the data buyer’s willingness to pay more for the user data, all platforms will enter the market and provides services to the user. Conversely, when β is below this threshold, only low-cost platforms will participate, while high-cost ones will abstain. Although competition does not favor the user, it results in positive utility for the data buyer. Moreover, the overall utilitarian welfare increases proportionally with the number of participating platforms. Regulation and policy design: Building on our equilibrium characterization, we then study regulations that aim to improve user utility. Here, our analysis provides three main insights. Firstly, we consider a ban on platforms sharing user data with the data buyers. This regulation only maximizes the user utility if all the platforms are low-cost. Specifically, under this regulation, users obtain the best of both worlds: all platforms (that have a low cost for providing services) enter the market, and the user benefits from the services of all of them while incurring zero privacy loss. This observation suggests that if we only had large firms whose costs of providing service per user are small, then the draconian regulation that involves banning data sharing would have been optimal. However, this is no longer the case if the market includes both high and low-cost platforms. In this case, our second insight reveals that imposing a uniform minimum privacy mandate
improves user utility, particularly when the value of the user data to the data buyer is significant enough for platforms to charge a high price for it. This means that all platforms need to perturb the user data by adding to it a noise with a high enough noise level. Here, our analysis identifies specific conditions where GDPR-type policies, which limit user data usage, can benefit users. Finally, our third insight suggests that, despite potential implementation challenges, a non-uniform minimum privacy mandate — banning data sharing for low-cost platforms while imposing a minimum privacy standard for high-cost platforms — further enhances user utility. This regulation entails prohibiting large, low-cost platforms from sharing user data, while permitting smaller, high-cost platforms to do so, albeit in a limited manner through privacy mechanisms. This approach aligns with our earlier discussion that GDPR-type regulations disproportionately harm small businesses. Therefore, a non-uniform regulation favoring small businesses is preferred not only by these businesses but also by the users. 1.2 related literature Our paper broadly relates to the emerging literature on data markets and online platform behavior. Earlier works on this topic include Acquisti et al. [2016], Posner and Weyl [2018], Ali et al. [2019], Jones and Tonetti [2020], and Dosis and Sand-Zantman [2022] which study the consequences of protecting and disclosing personal information about individuals. Additionally, Acemoglu et al. [2022], Bergemann et al. [2020], Ichihashi [2020b], and Fainmesser et al. [2022] study the privacy consequences of data externality (whereby a user’s data reveals information about others). Acemoglu et al. [2023a] study user-optimal privacy-preserving mechanisms that platforms can adopt to balance privacy and learning and Acemoglu et al. [2023b] develop an experimentation game to study the implications of the platform’s information advantage in product offering. Finally, Ichihashi [2021] studies data intermediaries, and Ichihashi [2020a] studies consumer privacy choices while online platforms adjust their privacy guarantees dynamically to incentivize more data sharing from consumers. More closely related to ours are papers that study data sharing among users, platforms, and third-party data buyers and, in particular, the impacts of banning such data sharing. In this regard, Bimpikis et al. [2021] and Argenziano and Bonatti [2023] develop a two-round model of the interaction between a user and two competing platforms that can collect data on user preferences (and potentially use it for price discrimination). Bimpikis et al. [2021] show that banning data sharing can hurt the user when the platforms offer complementary products, and Argenziano and Bonatti [2023] show that banning data sharing can hurt the user if the benefits of knowing user preferences by the seller and personalized services are limited. The above papers consider the interactions between a user and a platform that itself uses the user data for price discrimination and, therefore, can potentially hurt the user. In contrast, we study a different problem that relates to how platforms sell user data to other third-party data buyers. Therefore, in addition to the differences in modeling choices and analysis, we depart from the above papers by considering a three-layer data market that includes the interaction between the platforms and the data buyer
and focusing on deriving insights on effective regulations. Also related to our work is Ravichandran and Korula [2019] who empirically study the effect of the data-sharing ban on platforms’ revenues and Madsen and Vellodi [2023] who study the effects of a complete ban on innovation (we refer to Pino [2022] for a comprehensive survey on the microeconomics of data). We depart from these papers by focusing on the impact of regulations (and in particular data-sharing ban) on user’s utility. Our paper also relates to the literature that studies various forms of monetizing user data by platforms, such as selling cookies Bergemann and Bonatti [2015], efficient pricing for large data sets Abolhassani et al. [2017], dynamic sales Immorlica et al. [2021], Drakopoulos and Makhdoumi [2023], monetization while ensuring the data is replicable Falconer et al. [2023], and the design and price of information where a data buyer faces a decision problem under uncertainty and can augment their initial private information with supplemental data from a data seller Bergemann et al. [2018]. Finally, our paper relates to the growing literature on data acquisition and the design of mechanisms for incentivizing data sharing, including Ghosh and Roth [2011], Ligett and Roth [2012], Nissim et al. [2014], Cummings et al. [2015], Chen et al. [2018], Chen and Zheng [2019], Fallah et al. [2023], Cummings et al. [2023], Fallah et al. [2022], and Karimireddy et al. [2022]. We depart from this line of work as we consider a three-layer market where the privacy cost occurs due to selling data to a third-party buyer. The rest of the paper proceeds as follows. In Section 2, we describe our model and the interactions among the platforms, the data buyer, and the user. We also present some properties of the revealed information measure in our setting such as its monotonicity and submodularity. In Section 3, we introduce our equilibrium concept and provide preliminary characterizations of it. In Section 4, we focus on a setting with two platforms and provide a full characterization of the equilibrium. The focus on two platforms allows us to describe some of the nuances of the interactions in our model. In Section 5, we establish that our main characterizations continue to hold in the general setting with any number of platforms. We also provide several insights and comparative statics, leading to our discussion of the regulations in Section 6. Finally, Section 7 concludes while the appendix contains all the omitted proofs from the text. 2 model We consider K ∈ N platforms that are interacting with a user and a data buyer. The user benefits from using the services of these platforms. In return, the platforms acquire data about the user’s preferences and behavior. The platforms may subsequently sell this data to a third party, such as an advertiser, which we refer to as a data buyer (or, interchangeably, a buyer). The data buyer is interested in learning about the user’s preferences, which can adversely impact the user’s utility. This negative impact can be because of price discrimination, unfairly targeted advertising, manipulation, or intrinsic privacy losses. In the example of MasterCard described in the introduction, MasterCard is one of the platforms, and the data buyer is any other firm that purchases user data
from MasterCard. Formally, we represent the user’s data by θ ∈ Rd, which follows a Gaussian distribution with zero mean and identity variance, that is, θ ∼ N (0, Id). This vector θ can be interpreted as the user’s feature vector. Each platform i ∈ [K] ≜ {1, . . . ,K} offers a service whose quality depends on how accurately the platform can learn the match between the user’s feature vector and the platform’s characteristics, i.e.,
x⊤i θ. Here, xi ∈ Rd is a known unit-norm vector symbolizing the characteristic vector of platform i. The user decides whether to share their data with each of the K platforms in exchange for their service. We let ai ∈ {0, 1} denote whether the user has shared data with platform i and a ∈ {0, 1}K denote the user strategy profile. Specifically, if the user opts to share their data with platform i, meaning ai = 1, then platform i receives a signal
si := x ⊤ i θ +N (0, 1). The introduced noise ensures a degree of privacy concerning the user’s data.1
The data buyer aims to estimate a linear function of the user’s data, y⊤θ. Here, y ∈ Rd with ∥y∥ = 1 denotes the data buyer’s known characteristic vector. If platform i possesses the user’s data (i.e., ai = 1), they present the data buyer with an option to acquire a noisy version of their data at a price pi. Therefore, the data buyer strategy profile is b ∈ {0, 1}K , with bi = 1 denoting their acceptance of the platform i’s offer. The data buyer then receives a signal
s̃i := si +N (0, σ2i )
for the price pi, where σ2i represents the variance of the noise that platform i adds to the data they share with the data buyer. Lastly, each platform i ∈ [K] decides on the noise level to add to the user data before offering it to the data buyer, denoted by σi ∈ R+. We find it more convenient to work with the standard deviation of the noise σi and assume, without loss of generality, it is positive rather than the variance σ2i . Each platform also decides whether to enter the market and provide services to the user, denoted by ei ∈ {0, 1}. Therefore, the platforms’ strategy profile is (σ, e) ∈ RK+ × {0, 1}K . We set s̃i = NA when the data buyer does not obtain any information from platform i. This can occur either because the user has not shared their data with platform i or because the data buyer declines the offer from platform i or the platform has not provided the service to the user. In this case, pi is irrelevant, and we set it to zero. Throughout the paper, we make the following assumption:
1We set the noise variance to one to simplify the results. However, the analysis remains valid for any (potentially heterogeneous) level of noise. Assumption 1. Let
γi = x T i y for all i ∈ [K]
denote the correlation between the user i’s data and the data buyer. Then, we assume
(xi − γiy)T (xj − γjy) = 0 for all i ̸= j ∈ [K]. Note that under this assumption, the data offered by different platforms are viewed as substitutes for each other from the data buyer’s perspective. However, if this assumption does not hold, a complementary effect could also be observed. To illustrate this, suppose we have K = 2 platforms where x1 is orthogonal to y, i.e., γ1 = 0, and also x2 = γ2y + (1− γ2)x1. In this scenario, the data from platform 1 alone has no value to the data buyer, as x⊤1 θ provides no information about θ⊤y. However, if the data buyer decides to purchase data from the second platform, then the data from the first platform could also become valuable. To understand why, observe that the data from the second platform is a convex combination of two components: x⊤1 θ and y
⊤θ. Therefore, if the data buyer acquires the data from the second platform, learning x⊤1 θ could assist in better distinguishing these two components. In other words, the data from the first platform is valuable only if accompanied by the data from the second platform. This scenario exemplifies the complementary effect we described earlier. Assumption 1 excludes this possibility, allowing us to primarily focus on the substitution effect. This assumption also implies that the correlation among data for different platforms is given by
E[xixj ] = γiγj . 2.1 utility functions To define the utility functions, we need to first quantify how much information is revealed by observing the signals. We do so by using the following definition, which captures the reduction in uncertainty following the observation of a set of signals. Definition 1 (Revealed information). Consider a random variable Z drawn from the distribution π(.). Let πS(.) represent the posterior distribution of Z upon observing a set of signals S. The revealed information about Z by observing S is quantified as the reduction in the mean-squared error of Z, i.e.,
I(Z | S) = E [ (Z − EZ∼π [Z])2 ] − E [ (Z − EZ∼πS [Z]) 2 ] ,
where the outer expectations are over the randomness in Z and the signals. Measuring the revealed information, or information gain, through the variance of the posterior distribution has been used widely in economics, statistics, and learning theory (see, for example, Breiman et al. [1984], Bergemann et al. [2020], and Acemoglu et al. [2022]). Given this definition, the user’s utility function is given by
Uuser(σ, e,a,p, b) := K∑ i=1 aieiIi − α I(σ, e,a, b), (1)
where the term
Ii ≜ I(x⊤i θ | si)
is the user’s revealed information to platform i if the user shares her information (i.e., when ai = 1) and the platform is offering service to the user (i.e., when ei = 1). The term
I(σ, e,a, b) ≜ I(y⊤θ | s̃),
is the user’s revealed information to the data buyer. Here, s̃ denotes the vector (s̃i)Ki=1, which is the revealed information to the data buyer. Notice that the user’s utility does not directly depend on p, but we retain this notation to highlight that through the data buyer’s decision, the revealed information depends on p. Also, notice that in finding the revealed information to the data buyer, all that matters is the set {σi : s.t. ai = bi = ei = 1}. Therefore, we also find it convenient to define
I(σS) for σS = (σi : i ∈ S) for any S ⊆ [K], (2)
where we may drop the subindex S whenever the indices of the elements of σ are clear from the context. The first term in (1) captures the user’s gain from the service offered by each platform. Notice that this term is present if the platform has entered the market (i.e., ei = 1) and if the user shares with the platform (i.e., ai = 1). The second term represents the user’s privacy loss from the sharing of their data with the data buyer. Additionally, α indicates the user’s relative importance on these two opposing terms. For each i ∈ [K], platform i’s utility is given by
Ui(σ, e,a,p, b) := aiIi + bipi − ci ei = 10 ei = 0. (3) When the platform has not entered the market (i.e., ei = 0), the platform’s utility is zero. When the platform has entered the market (i.e., ei = 1), the second term bipi represents the platform’s revenue from selling the user’s data to the data buyer. The first term aiIi, similar to the user’s utility, reflects the quality of service the platform provides (if the user ends up utilizing their service). This term is concluded to capture the fact that a better service by the platform also enhances the platform’s utility. For example, it could increase ad revenue or expand the user base. Lastly, the cost ci ∈ R+ reflects the per-user cost incurred by the platform for providing the service. Finally, the data buyer’s utility is given by
Ubuyer(σ, e,a,p, b) := β I(σ, e,a, b)− K∑ i=1 bipi, (4)
which is the data buyer’s gain from learning the user’s information minus the amount they pay to all the platforms to purchase their data. Here, β ∈ [0, 1] is some constant that captures the importance of the revealed information compared to the payments in the data buyer’s utility. We refer to the above game among the platforms, user, and buyer of data as a three-layer data market with parameters (α, β, c,γ). Here is the timing of the game (see Figure 1):
1. In the first stage, all platforms simultaneously choose (σ, e) ∈ RK+ × {0, 1}K that specifies their noise levels and whether they want to enter the market to provide services to the user. 2. In the second stage, the user chooses a ∈ {0, 1}K that specifies which platforms to join and share data with. 3. In the third stage, the platforms simultaneously choose p ∈ RK that determines their offered prices. 4. In the fourth stage, the data buyer chooses b ∈ {0, 1}K that determines whether they accept or decline each offer made by the platforms. 2.2 revealed information properties Before analyzing this game, we provide some properties of our notion of revealed information. In stating the properties, we recall that the leaked information to the data buyer depends on e, a, and b through the set of platforms that share user data with the data buyer and the noise level of each of them. Therefore, we make use of the shorthand notation for the leaked information given in (2). In what follows, we also consider the lattice (L,≤), where
L := {ℓ | ℓ ∈ {0, 1}K} and ℓ ≤ ℓ′ if ℓi ≤ ℓ′i for all i ∈ [K]. (5)
The revealed information admits the following closed-form expression. Lemma 1. For any i ∈ [K], we have Ii = 1/2. Moreover, for any σ and S ⊆ [K] we have
I(σS) = mTM−1m,
where mi = γi, [M ]ii = 2 + σ2i , and [M ]ij = γiγj for all i, j ∈ S such that i ̸= j.
Lemma 1 follows by using the properties of multivariate normal distribution. We should highlight that for simplicity, we assumed that the user adds the same noise level to their data before sharing it with any platform, which results in Ii for all I ∈ [K] being equal. Our analysis continues to hold for any heterogeneous level of noise. Importantly, Lemma 1 enables us to obtain some structural properties of the revealed information, as we now demonstrate. Lemma 2 (monotonicity). The revealed information is increasing in the set of platforms that share the user data with the data buyer and is decreasing in σ, i.e., for any σ and S ⊆ [K], I(σS) is increasing in S and decreasing in σ.
Lemma 2 simply states that more data sharing with the data buyer increases its revealed information. Moreover, data with a lower noise level increases the revealed information to the data buyer. Lemma 3 (submodularity in actions). For a given vector of noise levels σ, the revealed information is submodular in the set of platforms that share the user data with the data buyer, i.e., for any σ, S ⊆ T ⊆ [K], and i ̸∈ T , we have
I((σi,σS))− I(σS) ≥ I((σi,σT ))− I(σT ). Lemma 3 states the intuitively appealing result that as more data is shared with the data buyer, the marginal increase in the revealed information from one more unit of shared data becomes smaller. Lemma 4 (submodularity in noise variance). For any σ, S ⊆ [K], i ̸∈ S, and j ∈ S
I((σi,σS))− I(σS)
is decreasing in σi and increasing in σj . Lemma 4 states the data of platform i reveals a relatively higher amount of information for smaller σi values and for larger σj values. To understand the former, let us compare the case of σi ≈ 0 and σi → ∞. When σi ≈ 0, the data of platform i reveals a lot, which helps the data buyer learn much better. However, when σi → ∞, the data of platform i does not contain any information, and therefore, the relative gain in the revealed information is ≈ 0. To understand the
former, let us again compare the case of σj ≈ 0 and σj → ∞. When σj ≈ 0, the data of platform j reveals a lot; therefore, the marginal increase in the revealed information of platform i is small. However, when σj → ∞, the data of platform j does not contain any information, and therefore, the relative increase in the revealed information from platform i’s data is much larger. 3 preliminary equilibrium characterization We adopt subgame perfect equilibrium as our solution concept, which means that the strategy profile of all players is a Nash equilibrium of every subgame of the game. We next formally define and characterize the subgame perfect equilibrium in our setting, starting from the last stage. Buyer equilibrium: For a given (σ, e,a,p), a data buyer profile bE is an equilibrium if it achieves the data buyer’s highest utility, i.e.,
bE ∈ argmax b∈{0,1}K Ubuyer(σ, e,a,p, b). Given that there is a finite set of 2n possibilities, one of them achieves the maximum data buyer’s utility, and therefore, an equilibrium buyer profile strategy always exists. We let BE(σ, e,a,p) be the set of such buyer equilibria. Price equilibrium: For a given (σ, e,a), a pricing strategy by the platforms pE is an equilibrium if no platform has a profitable deviation (taking the data buyer’s updated decision into account):
Ui(σ, e,a,pE, bE) ≥ Ui(σ, e,a, (pi,pE−i), b) for all i ∈ [K], bE ∈ BE(σ, e,a,pE), pi, b ∈ BE(σ, e,a, (pi,pE−i)). Before proceeding with the rest of the game, we establish that the data buyer and price equilibria admit a simple characterization, stated next. Proposition 1. For a given (σ, e,a), there exists a unique price equilibrium given by
p∗i = β (I(σ, e,a,1)− I(σ, e,a, (bi = 0,1−i))) for all i ∈ [K]
and the corresponding unique buyer equilibrium is bi = 1 for all i ∈ [K], where 1−i is the vector of all ones for all j ∈ [K] \ {i}. The proof of Proposition 1, given in the appendix, directly follows from the submodularity of the revealed information established in Lemma 3 for the following reason. Consider platform i ∈ [K] and suppose the contrary that in equilibrium, the buyer is not purchasing from it. This platform has a profitable deviation by lowering its price so that the data buyer finds it optimal to purchase from it. Also, notice that the submodularity of the revealed information implies that if one more platform’s data is shared with the data buyer, the marginal increase in the revealed
information decreases. Therefore, if the data buyer was purchasing from another platform j ̸= i, they still find it optimal to purchase from that platform. Proposition 1 characterizes the equilibrium of the third and fourth stages of the game. Therefore, it remains to characterize the user sharing profile and the platform’s noise level and entry decisions in equilibrium, taking into account the equilibrium of the subsequent stages that we have already identified. User equilibrium: For a given (σ, e), a user sharing profile aE is an equilibrium if it achieves the user’s highest utility, i.e.,
aE ∈ argmax a∈{0,1}K Uuser(σ, e,a,p∗,1). Again, given that there are 2n possibilities, one of them achieves the maximum user’s utility, and therefore, an equilibrium sharing profile strategy always exists. We let AE(σ, e) be the set of such user equilibria. This set has the following important lattice structure that we use in the rest of the analysis. Lemma 5. For a given (σ, e), the set of user equilibria AE(σ, e) is a sublattice of the lattice (L,≤) (defined in (5)). Therefore, it has a maximum and a minimum. For a platform strategy profile (σ, e), we select the platforms’ Pareto-optimal one if there are multiple user equilibria. Using Lemma 5, such a user equilibrium exists and is the one that shares with the highest number of platforms.2
Platform equilibrium: A noise level and entry strategy (σE, eE) is an equilibrium if no platform has a profitable deviation, i.e.,
Ui(σE, eE,aE,p∗,1) ≥ Ui((σi,σE−i), (ei, eE−i),a,p∗,1)
for all i ∈ [K],aE ∈ AE(σE, eE),a ∈ AE((σi,σE−i), (ei, eE−i)). We refer to a platform’s noise level and entry decision as the platform’s decision and to the corresponding equilibrium as the platforms’ equilibrium. The following characterizes the set of possible platforms’ equilibria. Proposition 2. For any platforms’ equilibrium strategy (σ, e), we must have
AE(σ, e) = {(ai = 1 : for all i s.t. ei = 1))},
that is, the user must find it optimal to share with all platforms that have entered the market. 2We can view this as Stackelberg Nash equilibrium in which because the platforms move first, we break the ties in their favor. Similar concepts have appeared in the literature with different terms, such as sender-preferred equilibrium in Bayesian persuasion [Kamenica and Gentzkow, 2011]. This proposition follows by noting that a platform that has entered the market can always increase its noise level so that the user finds it optimal to share with the platform. Motivated by Proposition 2 and Lemma 5, we conclude that for any set of platforms that have entered the market (captured by e ∈ {0, 1}K), the set of possible noise levels in equilibrium is Σ1,e, where we have
Σa,e := {(σi : i s.t. ei = 1) : a is the highest element of AE(σ, e)} for all a ∈ {0, 1}K . (6)
We are interested in characterizing Σ1,e for any e and finding the equilibrium that belongs to one of these sets for an equilibrium choice of e.
Throughout the paper, we focus on the case in which the user asks for some level of privacy in order to share their data. This means that if the noise levels are all zero, then the user does not share with the platforms. More formally, we make the following assumption:
Assumption 2. The weight of privacy on the user utility, i.e., α, is large enough such that, for any e ∈ {0, 1}K , the point (σi = 0 : i s.t. ei = 1) belongs to the set Σ0,e. We will further clarify this assumption’s role in the next section. 4 equilibrium characterization with k = 2 platforms We begin our analysis by considering a setting with K = 2 platforms. We then show that the main insights from this analysis extend to the general setting with K > 2 platforms. Depending on which platforms enter the market, we have four cases:
Case 1 where both platforms enter the market: In this case, the user’s utility if they share their data with both platforms is given by3
Uuser(σ1, σ2) := 1− αI(σ1, σ2), (7)
and the user’s utility if they share their data with platform i ∈ {1, 2} only is equal to
Uuser(σi) := 1
2 − αI(σi). (8)
Recall the definition of Σa,e with e = (1, 1) in (6). To simplify the notation, we drop the e and use Σ̃a. In particular,
Σ̃(1,1) := {(σ1, σ2) : Uuser(σ1, σ2) = max (Uuser(σ1, σ2),Uuser(σ1),Uuser(σ2), 0)}. 3With a slight abuse of notation, we drop the other dependencies of the user utility here. Similarly, Σ̃(1,0) and Σ̃(0,1) denote the cases where Uuser(σ1) and Uuser(σ2), respectively, have the highest value. Finally,
Σ̃(0,0) := {(σ1, σ2) : 0 = max (Uuser(σ1, σ2),Uuser(σ1),Uuser(σ2), 0)}. Notice that we operate under Assumption 2, which implies that Σ̃(0,0) is non-empty. In particular, for K = 2, this assumption translates to
α > 4− γ21γ22 2 ( γ21 + γ 2 2 − γ21γ22 ) . (9) Figure 2a depicts the sets Σ̃(1,1), Σ̃(0,1), Σ̃(1,0), and Σ̃(0,0) as a function of the noise variance that the two platforms add to the data, i.e., (σ21, σ 2 2), for parameters γ1 = 0.8 and γ2 = 0.7. Using Proposition 2, the noise level equilibrium is in the set Σ̃(1,1). In fact, we argue that it must belong to Σ̃(1,1) ∩ Σ̃(0,0) because, otherwise, one of the platforms can increase its utility by decreasing its noise level such that the user still shares with it. Now, for any (σ1, σ2) ∈ Σ̃(1,1) ∩ Σ̃(0,0), the only possible deviation for platform 1 is to increase σ1 to σ̃1 to move to the point (σ̃1, σ2) which resides in Σ̃(1,0), exactly next to the boundary with Σ̃(1,1) (see Figure 2a). At first glance, it might look like this can never be a deviation because it reduces the revealed information to the buyer. However, notice that, by this action, platform 1 pushes platform 2 out of the market because (σ̃1, σ2) is in the yellow region Σ̃(1,0) in which the user does not share their data with the second platform. Therefore, it is possible that the first
platform’s payment increases, as they are now the only platform with access to the data. Note that this is the only deviation that we need to consider. Because if it ends up not being a deviation, it would imply that a further increase of σ1 into the yellow region is also not profitable. Also, it is evident that increasing σ1 but staying in the Σ̃(1,1) region or decreasing it and going into the Σ̃(0,0) region in which the user shares no data are not profitable deviations. Considering these deviations results in the following. Lemma 6. Suppose Assumptions 1 and 2 hold. Assuming both platforms have entered the market, there exists an equilibrium noise level (σ1, σ2) ∈ Σ̃(1,1) ∩ Σ̃(0,0) if and only if α ≥ ᾱ ≈ 1.884. In particular, for α ≥ ᾱ, (σ1, σ2) is an equilibrium where
2 + σ21 γ21 = 2 + σ22 γ22 = 2α− 1. (10)
Lemma 6 is under the assumption that both platforms enter the market. The final point to check is whether any platform has an incentive to enter the market. Proposition 3. Suppose Assumptions 1 and 2 hold. Also, recall ᾱ ≈ 1.88 from Lemma 6. If an equilibrium exists in which both platforms enter the market, then
α ≥ ᾱ and β ≥ 2α (max{c1, c2} − 1
2 ). (11)
Conversely, for any α ≥ ᾱ and any β ≥ β̄(α) such an equilibrium in which both platforms enter the market exists, where
β̄(α) ≜ (2 + 1
α− 1 ) α (max{c1, c2} −
1 2 ). (12)
Both parts of the result provide a lower bound on β, with the difference that the first part establishes a necessary condition for an equilibrium to exist, while the second part presents a sufficient condition. Note that the ratio between these two lower bounds converges to one as α grows. However, we next highlight a subtle difference between the two results. Note that, for any value ξ greater than 2 (max c1, c2 − 12), we can choose sufficiently large α and β such that an equilibrium exists for these parameters and the ratio of β over α is less than or equal to ξ. In other words, we have
inf
{ β
α ∣∣∣ α, β s.t. an equilibrium exists} = 2(max{c1, c2} − 1 2 ) . This, in fact, is a direct consequence of the second part of Proposition 3 along with the fact that β̄ converges to 2 (max{c1, c2} − 12) as α grows. However, the infimum mentioned above does not imply that any α and β satisfying the condition (11) will necessarily result in an equilibrium. In fact, as our proof establishes, to have an
equilibrium for α = ᾱ, we must have β ≥ β̄(ᾱ). In other words, we have
sup α≥ᾱ inf
{ β
α ∣∣∣ β s.t. an equilibrium exists with the given α} = β̄(ᾱ). Cases 2 and 3 where only one platform enters the market: Suppose only platform 1 enters the market at some equilibrium. In this case, the first platform wants to choose the noise level σ1 as small as possible but also large enough so that user shares their data. Therefore, the platform chooses σ1 at the value that makes the user indifferent between sharing and not sharing (recall that we assumed the user breaks the ties in favor of the platforms), i.e.,
Uuser(σ1) = 1
2 − αI(σ1) = 0, (13)
which implies σ21 = 2αγ 2 1 − 2. Notice that this is equivalent to the σ1 corresponding to points B and X in Figure 2b. Now, for this noise level to be an equilibrium, we need to verify two potential deviations: (i) platform one has no incentive to abstain from participating, i.e., their utility should be nonnegative, and (ii) the second platform has no profitable deviation by entering the market. Using (13), the first condition simply implies
1 2 − c1 + β 1 2α ≥ 0. (14)
For the second deviation check, we argue that it suffices to ensure the second platform’s utility at point B in Figure 2b is nonnegative. Let us denote the noise levels corresponding to point B as (σB1 , σ B 2 ). To understand why we only need to check the point B, consider that, given platform one’s chosen noise level (equal to σB1 ), if the second platform enters the market and selects a certain noise variance, it will result in a point on the line BX . The smallest noise level for the second platform that motivates the user to share their data with them (and thus has the potential to be profitable) is σB2 . One might argue that the second platform could opt for a very large noise level so that the vector of noise levels falls into the green region Σ̃(0,1), implying that only the second platform receives the data. However, this is not feasible, as the line BX stays within the blue region Σ̃(1,1) for any value of σ2 (and in fact, it becomes tangent to the border of Σ̃(0,1) and Σ̃(1,1) as σ2 approaches infinity). To confirm this, we need to demonstrate that
Uuser(σB1 , σ2) = 1− αI(σB1 , σ2) ≥ 1
2 − αI(σ2) = Uuser(σ2),
holds for any σ2. This is indeed the case, given that due to the submodularity of the revealed information, I(σB1 , σ2)−I(σ2) decreases with increasing σ2 and equals I(σB1 ) = 12α when σ2 = ∞. Now, checking the second platform’s utility at point B along with (14) yields the following result. Proposition 4. Suppose Assumptions 1 and 2 hold. For any i ∈ {1, 2}, there exists an equilibrium in which only platform i enters the market if and only if ci ≤ c−i and
β ∈ [ 2α(ci − 1
2 ), 2α(c−i −
1 2 )
] . Case 4 where no platform enters the market: Finally, we ask whether there is an equilibrium in which no platform enters the market. In such a scenario, we need to ensure no platform has a profitable deviation by entering the market and choosing some noise level. For instance, if platform 1 wants to deviate, the smallest noise level that they would choose would be σB1 as it makes the user indifferent between sharing and not sharing their data with them. In this case, the platform’s utility, as derived in (14), is given by
1 2 − c1 + β 1 α ,
which is nonpositive when β ≤ 2α(c1 − 12). Making the same argument for the second platform’s deviation, we obtain the following result. Proposition 5. Suppose Assumptions 1 and 2 hold. There exists an equilibrium in which neither of the platforms enters the market if and only if
β ≤ 2α ( min{c1, c2} − 1
2
) . 4.1 insights from the case with k = 2 We conclude this section by highlighting a few implications and insights of our results for the case K = 2, which, as we will see, also extend to the general case. Note that the term β determines the value the buyer places on the user’s data. The higher β is, the more money the platform can earn by selling the user’s data. Our results indicate that there are, at most, three main regimes for β, and the market equilibrium depending on the interval β falls into. First, as established in Proposition 5, when β is small, the platform’s monetary gain from selling data is limited, so platforms may decide not to provide any service as they cannot fully compensate for their service costs. This regime would not exist if at least one of the platforms operates at a low cost, meaning its gain from the user’s data already compensates for the cost of service (this corresponds to the case ci ≤ 1/2 for some i). On the other hand, as shown in Proposition 3, when β is large enough and platforms can charge a high price for the user’s data, both platforms would enter the market. Finally, there is an intermediary regime for β where only the platform with the lower cost enters the market, and the platform with a higher service cost opts out. Interestingly, the user’s utility in all these cases would be equal to zero. However, the buyer’s utility could be positive when both platforms enter the market. As we establish next, these obser-
vations continue to hold in the general case with K > 2 platforms. 5 equilibrium characterization with k > 2 platforms This section shows how our equilibrium characterization extends to a general setting with any K > 2 number of platforms. In what follows, we make use of the following definition. Definition 2 (High- and low-cost platforms). We say a platform i ∈ [K] is of high cost if ci > 12 and is of low cost if ci < 12 . The comparison of the cost to 1/2 in the above definition comes from the fact that the leaked information to any platform is Ii = 1/2 and therefore, high-cost platforms enter the market only if the payment they receive from the buyer is large enough. Conversely, low-cost platforms enter the market irrespective of the payment they receive from the buyer. We can view low-cost platforms as large platforms with small operation costs that do not need extra payments from the data buyer to enter the market and provide services. High-cost platforms, however, are small platforms with large operation costs that do need extra payments from the buyer to be able to provide service. Theorem 1. Suppose Assumptions 1 and 2 hold. There exists ᾱ, β̄, and β such that for α ≥ ᾱ, we have the following:
• If β ≥ β̄, an equilibrium of the game exists. Moreover, in any equilibrium, all platforms enter the market, the user utility is zero, and the buyer purchases the data of all platforms and has a strictly positive utility. • If β ≤ β, an equilibirum of the game exists. Moreover, in any equilibrium, only low-cost platforms enter the market, the user utility is zero, and the buyer purchases the data of low-cost platforms and has a strictly positive utility only if there is more than one low-cost platform. Let us explain the qualifiers of Theorem 1 and then explain its intuition. First, notice that similar to the setting with K = 2 platforms, for small enough α and also for intermediary values of β, a pure-strategy equilibrium may not exist. Therefore, we focus on large enough α and also avoid intermediary values of β. In the proof of Theorem 1, we have provided explicit expressions for ᾱ, β̄, and β. To gain the intuition of the first part of Theorem 1, notice that for large enough β the data buyer gains a lot when the user’s data is revealed to them and therefore is willing to pay a high price for the user data. This, in turn, means that even high-cost platforms find it optimal to enter the market. As established in Proposition 1 and Proposition 2, in equilibrium, the user shares with all platforms, and the data buyer purchases from all platforms. To see that the user utility becomes zero in equilibrium, suppose the contrary, that the user utility is strictly positive. This means that the equilibrium noise level strategy is in the interior of the set Σ1,1. Given that noise level strategy is in the interior of Σ1,1, there exists i ∈ [K] such that by decreasing its noise level, we remain
in the set Σ1,1 (i.e., the user still finds it optimal to share with all platforms), but this deviation increases the payment and therefore the utility of platform i. Also, Lemma 3 guarantees that the user still finds it optimal to share with all platforms. To gain the intuition of the second part of Theorem 1, notice that for small enough β, the data buyer’s gain when the user’s data is revealed to them is small and therefore, the buyer is willing to pay only a low price for the user data. This means that high-cost platforms will never find it optimal to enter the market. Nonetheless, the low-cost platforms always enter the market. The fact that the user shares with all the low-cost platforms (that have entered), the buyer purchases from them, and the user utility becomes zero in equilibrium follows from a similar argument to the one discussed above. Theorem 1 leads to the following insights. Competition among platforms helps the buyer and not the user: Let us first characterize the equilibrium when we have only one platform. Proposition 6. Suppose Assumption 1 holds. When K = 1, we have the following:
• Suppose α ≤ 1/γ21 . If c1 ≤ 1/2 + βγ21/2 (which holds whenever c1 ≤ 1/2), then in equilibrium, the platform enters the market and chooses σ1 = 0, the user shares with the platform, and the buyer purchases the data. In this case, the user utility is (1− αγ21)/2, and the buyer utility is zero. Otherwise, if c1 > 1/2 + βγ21/2, then the platform does not enter the market, and all utilities are zero. • Suppose α > 1/γ21 . If c1 ≤ 1/2 + β/2α, then in equilibrium, the platform enters the market and chooses σ1 = √ 2(αγ21 − 1), the user shares with the platform and the buyer purchases the data. In
this case, both the user utility and the buyer utility are zero. Otherwise, if c1 > 1/2+β/2α, then the platform does not enter the market, and all utilities are zero. We are interested in the second regime where α is large enough so that the user is not incentivized to share with the platform, irrespective of the noise level choice of the platform. In this case, as established in Proposition 6, both the user and the data buyer utilities are zero. Now, let us compare this setting to a setting with K ≥ 2 platforms that are competing to obtain the user’s data and sell it to the data buyer, established in Theorem 1. Interestingly, we observe that competition does not help the user (as the user obtains zero utility for any K). However, increasing the number of platforms from K = 1 to K ≥ 2 improves the data buyer’s utility. To gain the intuition for this observation, notice that the user’s utility will always be zero because otherwise, the platforms can always decrease their noise levels by a small margin so that the user still shares and increases their payments. Now, why does the competition help the data buyer? This is because of the data externality among the platforms’ data about the user, similar to that of Acemoglu et al. [2022] and Bergemann et al. [2020]. In particular, the data of a platform (because of the submodularity of the revealed information, proved in Lemma 3) decreases the marginal value of another platform’s data, and therefore, the platforms end up competing with each other, and sell their data at lower marginal prices. More platforms imply higher utilitarian welfare: Let us first find the overall utilitarian welfare in equilibrium, where utilitarian welfare is defined as the sum of the utilities of the platforms, the user, and the data buyer. Corollary 1. Consider ᾱ, β̄, and β established in Theorem 1. For α ≥ ᾱ, we have the following:
• If β ≥ β̄, the utilitarian welfare in equilibrium becomes
K
( 1
2 +
β
2α
) − K∑ i=1 ci. • If β ≤ β, the utilitarian welfare in equilibrium becomes
(number of low-cost platforms) ( 1
2 +
β
2α
) − ∑ i∈[K] : ci< 12 ci. Notably, Corollary 1 shows that, within the ranges of each case, the overall utilitarian welfare is increasing in β and decreasing in α. This is because the payments always cancel each other out, and as β increases, the data buyer’s gain becomes larger, and as α increases, the user’s loss becomes larger. Moreover, in the first case, the utilitarian welfare is increasing in the number of platforms, and in the second case, it is increasing in the number of low-cost platforms. 6 regulations In this section, we consider regulations of the three-layer data market to improve the user utility. As we have established in Theorem 1, the user utility in equilibrium is zero. We now explore whether we can improve the user utility by imposing a regulation. As discussed in the introduction, one possible regulation is to impose a limit on the amount of information each platform can leak about the user to the data buyer. This means imposing a lower bound on the noise level. Let us formally define this regulation. Definition 3 (Minimum privacy mandate). A minimum privacy mandate, represented by σ̄ = (σ̄1, . . . , σ̄K), is a regulation that mandates that each platform i ∈ [K] must choose a noise level above σ̄i ∈ R+. A special case of this regulation is uniform minimum privacy mandate is such that σ̄i = σ̄ for all i ∈ [K]. Another special case of this regulation is to ban the platforms from sharing with the buyer, i.e., σ̄i = ∞ for all i ∈ [K]. Uniform minimum privacy mandate versus ban: One may conjecture that banning the platforms from sharing their data with the buyer is user-optimal in the class of all uniform minimum privacy mandate regulations because it reduces the privacy loss of the user to zero. We next prove that this is not necessarily true. The main intuition is that if we ban data sharing, then only lowcost platforms enter the market. This, in turn, implies that the user does not obtain the gain from
the services provided by the high-cost platforms, and this loss in the service gain can dominate the gain in privacy loss. We next formalize this intuition. Proposition 7. Consider α ≥ ᾱ for ᾱ established in Theorem 1. We have:
• If all platforms are low-cost, then irrespective of the minimum privacy mandate, all platforms enter the market in equilibrium. In this case, banning data sharing achieves a higher user utility than any (uniform or non-uniform) minimum privacy mandate. • Otherwise, if there is at least one high-cost platform, then there exists β̃, β, and σ̄ such that
– If β ≥ β̃, then under uniform minimum privacy mandate σ̄ all platforms enter the market, and the user utility is higher than banning data sharing. – If β ≤ β, then irrespective of the minimum privacy mandate, only low-cost platforms enter the market. In this case, banning data sharing achieves a higher user utility than any uniform minimum privacy mandate. The first part is rather straightforward: if all platforms are low-cost, then they all enter the market and provide services to the user. Banning data sharing is user-optimal because it decreases the privacy loss of the user to zero while the user obtains the service gains from all platforms. The second part is more nuanced: here, if β is large enough, then all platforms enter the market. Now, there are two opposing forces in place. If we ban data sharing, only low-cost platforms enter the market, and user utility then comprises only the service gained from low-cost platforms, while the privacy loss becomes zero. Therefore, banning data sharing decreases the service gains but also decreases the privacy losses. If we do not ban data sharing, the user utility comprises the service gains from all platforms and the privacy loss incurred by the data sharing of all platforms with the buyer. Therefore, not banning data sharing increases the service gains but also increases the privacy losses. For a large enough minimum uniform privacy mandate, and when there is at least one high-cost platform, the service gains of the user utility dominate the privacy loss, and therefore, not banning data sharing becomes the user-optimal regulation. Finally, to understand the last part, we observe that for small enough β, only low-cost platforms enter the market, and therefore, the situation is effectively the same as the first part of Proposition 7. Notice that the assumption of large enough α and large/small enough β is adopted for the same reason as that of Theorem 1 so that an equilibrium exists. Non-uniform versus uniform minimum privacy mandate: As noted above, when all platforms are low-cost or when β is small enough so that high-cost platforms do not enter the market, then banning data sharing is optimal in the class of all (uniform or non-uniform) minimum privacy mandates. However, corresponding to the second part of Proposition 7, the user prefers a minimum privacy mandate to banning data sharing when there is at least one high-cost platform, and β is large enough. This is because if we ban data sharing, the high-cost platforms do not enter, while with the “right” choice of uniform minimum privacy mandate, they enter the market. In
this case, the user benefits from the services, while the privacy loss that they incur is small. However, with a uniform minimum privacy mandate, the low-cost platforms (that enter the market regardless of the minimum privacy mandate in place) also bring about privacy loss to the user. Therefore, a natural idea is to have a non-uniform minimum privacy mandate to help the user further. We next formalize this idea. Proposition 8. Suppose there is at least one high-cost platform and consider α ≥ ᾱ for ᾱ established in Theorem 1. There exists β̂ and σ̄ such that for β ≥ β̂ banning the low-cost platforms from data sharing and imposing minimum privacy mandate equal to σ̄ for all high-cost platforms generates a higher user utility than any non-uniform minimum privacy mandate. With the non-uniform minimum privacy mandate described above, the user obtains the service gain of the low-cost platforms and incurs zero privacy loss from them. Moreover, for large enough β, the high-cost platforms all enter the market. Therefore, the user gains from the highcost platforms’ services, and when σ̄ is large enough, it incurs a small privacy loss. Notice that, as established in Proposition 7, with the optimal uniform minimum privacy mandate, both the low-cost and high-cost platforms enter the market. We prove that if we impose the same minimum privacy mandate but only for high-cost platforms and ban the low-cost platforms, the user obtains the same service gain from all platforms but incurs a smaller privacy loss. Moreover, all platforms still find it optimal to enter the market. Proposition 7 and Proposition 8 establish that banning the data market is not necessarily useroptimal, especially when we have high-cost platforms (i.e., smaller platforms whose cost of providing the service is high). Moreover, a uniform minimum privacy mandate improves the user utility because it also incentivizes the high-cost platforms to enter the market to provide service to the user. Finally, a non-uniform minimum privacy mandate that bans the low-cost (i.e., large) platforms from data sharing and imposes a minimum privacy mandate on high-cost (i.e., small) platforms further improves the user utility. This is because this regulation not only incentivizes the high-cost platforms to enter the market to provide service to the user but also zeros out the privacy loss of the low-cost platforms. 7 conclusion In this paper, we study the intricate interplay between user privacy concerns and the dual incentives of online platforms: to safeguard user privacy and to monetize user data through sales to third-party buyers. To this end, we have constructed a multi-stage game model that captures the interactions between users, platforms, and data buyers. Our model delineates various scenarios where the interplay of platform service costs, the valuation of data, and privacy concerns dictate equilibrium outcomes. Additionally, we examine potential regulations designed to bolster user privacy and enhance market outcomes for users.