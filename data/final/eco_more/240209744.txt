We propose a new framework for assessing Granger causality in quantiles in unstable environments, for a fixed quantile or over a continuum of quantile levels. Our proposed test statistics are consistent against fixed alternatives, they have nontrivial power against local alternatives, and they are pivotal in certain important special cases. In addition, we show the validity of a bootstrap procedure when asymptotic distributions depend on nuisance parameters. Monte Carlo simulations reveal that the proposed test statistics have correct empirical size and high power, even in absence of structural breaks. Finally, two empirical applications in energy economics and macroeconomics highlight the applicability of our method as the new tests provide stronger evidence of Granger causality. 1 introduction The definition of Granger (1969) causality is a fundamental concept in time series econometrics. Accordingly, let zi denote a series contained within an information set that gathers all relevant information available up to time i, then zi is said to Granger-cause yi if zi provides information relevant to predicting yi. Although Granger causality is uncovered by the conditional distributions of yi, applied research focuses often on Granger causality in mean because it entails easily testable implications. However, by solely testing the significance of zi in a conditional mean regression of yi on zi, one runs the risk of neglecting possible tail relationships or nonlinearities. It is for this reason that more recent research is also concerned with Granger causality in quantiles, which allows for an equivalent characterization of Granger causality in distribution. This implies that the conditional quantile function of yi depends on zi for some quantiles of interest, given all the available information until time i. For instance, Lee and Yang (2012) found fragile evidence of Granger causality between augmenting monetary policies and national income at the conditional mean; nevertheless, the authors reported strong evidence of Granger causality at extreme quantiles of the distribution. One way to elicit potential evidence for Granger causality is by means of quantile regressions. Koenker and Machado (1999) developed a parametric significance test of quantile regression coefficients, which is frequently employed in empirical work to test for Granger causality in quantile regressions (see e.g. Chuang et al., 2009 or Yang et al., 2014). Troster (2018) extended the method of Koenker and Machado (1999) by providing a semiparametric omnibus test for Granger causality in quantiles that allows for nonlinear specifications of the quantile regressions under the null hypothesis of no Granger causality. On the other hand, Jeong et al. (2012), Taamouti et al. (2014) and Candelon and Tokpavi (2016) derived nonparametric tests for Granger causality in quantiles. Bouezmarni et al. (2024) proposed such a test for expectiles. What all these papers have in common, is, however, that they implicitly assume the pattern of Granger (non)causality to be stable over time. In this paper, we
therefore propose tests for Granger causality in quantiles that are robust against temporal instabilities. This is of importance because financial and macroeconomic data structures, where Granger causality is frequently tested, are subject to strong fluctuations and volatility (Clark and McCracken, 2006; Rossi, 2005, 2013; Rossi and Wang, 2019; Stock and Watson, 1996, 1999, 2003, 2006). Rossi (2006), for instance, provides evidence of failure of traditional Granger causality tests to detect Granger causality from certain macroeconomic fundamentals to exchange rate fluctuations due to parameter instabilities in the models over time. Chen et al. (2010), on the other hand, do report evidence of Granger causality from exchange rates to commodity prices, when applying Granger causality tests that allow for structural breaks. Caporin and Costola (2022) have made similar arguments. In addition, Giacomini and Rossi (2010), Rossi (2013), and Rossi (2021), among others, show that instabilities in the parameters of the models can affect the performance of Granger causality tests in different ways; hence, these authors recommend incorporating structural breaks in Granger causality tests rather than testing for instability in the parameters. Following this idea, it is important to apply methods that are robust to structural breaks or instabilities for correctly performing a Granger causality analysis in macroeconomic or financial time series. To address potential temporal instabilities, we resort to the work of Rossi (2005), who–by extending the earlier work by Sowell (1996)–developed tests for nested model selection with underlying parameter instability. Although the methods of Rossi (2005) and, in particular, Rossi and Wang (2019) can be used to test for Granger causality in mean between two time series, they fall short to capture Granger causality in the tails or other parts of the conditional distribution not captured by the mean. The same is true for the time-varying Granger causality in-mean tests like the one employed, for example, by Chen et al. (2010) or Caporin and Costola (2022). We thus extend the method of Rossi (2005) and Rossi and Wang (2019) in a consolidated way for testing for Granger causality in quantiles under structural instabilities. We do so by drawing from results on structural break testing in quantile regressions by Qu (2008) and Oka and Qu (2011). To our knowledge, no test for Granger causality in quantiles with structural instability has been developed so
far in the literature. More specifically, the main idea is to consider under the null the intersection of two sub-hypotheses: First, we hypothesize that the effect of the potential Grangercausing variate is constant over time and over quantiles. Second, we assume that this effect is zero. Likewise, the alternative in a local neighbourhood around the null consists of two parts: one that specifies local deviations from the null hypothesis of no Granger causality in quantiles and another that specifies local deviations from the null hypothesis of constant parameters (over all quantiles of the distribution). Thus, we construct our test statistics in such a way that ensure non-trivial local power against the union of these two alternative hypotheses. For this reason, we do not require a priori knowledge of whether any of the two alternative subhypotheses holds (or whether both hold). Finally, we propose tests that neither involve trimming over time nor require the specification of tuning parameters. This idea goes back to, inter alia, Sowell (1996) and Rossi (2005) who have developed similar test procedures in a general generalized method of moments (GMM) framework. Our extension is non-trivial. Unlike the GMM framework considered by Rossi (2005), we demonstrate, for example, that the limiting distribution might not be pivotal in certain cases. It is pivotal in certain important special cases such as homoskedasticity or conditional mean independence between regressors. In cases where the limiting distribution depends on nuisance parameters, we propose alternatives, including a new bootstrap procedure whose validity is established. This extends the semiparametric bootstrap used in Rothe and Wied (2013), where the estimated quantile functions are applied to uniformly distributed random variables. Therefore, we provide (bootstrap) test statistics with correct asymptotic size, which are consistent against fixed alternatives and possess nontrivial power against local alternative hypotheses. This is also corroborated by our Monte Carlo simulations; the finite-sample evidence shows that the test has appealing size and power properties in finite samples. In all cases (structural breaks and no structural breaks under the alternative), our tests are more powerful than the existing sup Wald test. We illustrate the applicability of our tests by performing two empirical applica-
tions. First, we revisit an analysis about the causal relationships between crude oil and stock returns from Ding et al. (2016), who consider the interplay between stock returns and crude oil returns. Further, following Stock and Watson (2001) and Rossi and Wang (2019), we investigate potential Granger causality between inflation, the unemployment rate, and the interest rate. In both applications, we find several scenarios which demonstrate the higher efficiency of the new test. The rest of the paper proceeds as follows. In Section 2, we propose our test statistics for jointly testing for Granger causality in quantiles and parameter instability. In Section 3, we derive the asymptotic distribution of our test statistics; we also propose and justify a bootstrap method for implementing our test statistics. In Section 4, we perform Monte Carlo simulations to validate the finite-sample performance of our test statistics. In Section 5, we present two empirical applications of our proposed tests. Finally, we conclude the paper in Section 6. Throughout the paper, we use the following notation: Bm(λ), λ ∈ [0, 1], is a vector of m independent Brownian motions, and BBm(λ) := Bm(λ) − λBm(1) is a vector of m independent Brownian bridges. For a positive definite matrix A, A−1/2 is defined as the Cholesky factor of its inverse A−1, so that A−1 = (A−1/2)′A−1/2. Notation “⇒” and “→d” indicates weak convergence and convergence in distribution, respectively. Notation T represents a closed interval such that T ⊂ [0, 1]. For an m× 1 vector z, we define ‖z‖∞ := max
1≤j≤m |zj |. 2 granger causality Suppose we suspect that the p×1 vector zi Granger causes the dependent variable yi, and, at the same time, we have reasons to question temporal stability. In other words, we expect Granger causality, but we are unsure whether its pattern persists over time. Within the framework of a linear quantile regression, these considerations amount to parameterise the τ quantile of yi via
Qyi (τ | xi) := x′iβi(τ), xi := (z′i, w′i)′, βi(τ) := (γi(τ)′, α(τ)′)′ ∈ Rm, (1)
where w is a k × 1 vector of additional controls so that m = p + k, γi(τ) 6= 0 for some τ ∈ [0, 1], and i ∈ {1, . . . , n} under Granger causality. For simplicity, we assume that all the available information up to time i can be represented by vector xi. Two important models, which lead to such a structure, are the locationscale model, yi = x ′ iδ + (x ′ iρ)εi, and the random coefficient model, yi = x ′ iβ(Ui), with a standard uniformly distributed random variable Ui that includes, among others, quantile autoregressive distributed lag models (see e.g. Koenker (2005) and Galvao et al., 2013). We formulate the following (joint) null hypothesis H0 := H0,1 ∩H0,2:
H0,1 := {γi(τ) = γ0(τ), ∀ i ∈ {1, . . . , n}, τ ∈ T } H0,2 := {γ0(τ) = 0p, ∀ τ ∈ T }
against the alternative hypothesis H1 := {¬H0,1} ∪ {¬H0,2}. More specifically, in a local neighbourhood around H0 in the direction of H1, the following sequence of local alternatives is investigated
γi,n(τ) := γ0,n(τ) + δ(τ)√ n g ( i n ) , γ0,n(τ) := ∆(τ)√ n , (2)
where τ 7→ ∆(τ) and τ 7→ δ(τ) are deterministic continuous vector-valued and scalar-valued functions, respectively, and v 7→ g(v) is a deterministic vector-valued Riemann–Stieltjes integrable function. Our setup is essentially similar to the approach of Rossi (2005) that extends the earlier procedure of Sowell (1996), in which the null hypothesis consists of two different restrictions. On the one hand, the parameter γi(τ) is constant over i and τ ; on the other hand, this constant is equal to 0. Analogously, the alternative hypothesis also consists of two parts. The alternative H1,1 := ¬H0,1 specifies local deviations from the null hypothesis of constant parameters, whereas the alternative H1,2 := ¬H0,2 specifies local deviations from the null hypothesis of no Granger causality in quantiles. Our tests are constructed in such a way that they have power against the union of these alternatives. For this purpose, it is not required to know a priori which of the two alternatives (or both) holds. 3 test statistics Consider the following sequential process based on the subgradient of the unconstrained quantile regression
Sn(λ, τ, t) := n −1/2
⌊λn⌋∑
i=1
xiψτ (yi − x′it), t ∈ Rm, (3)
where λ ∈ [0, 1] indexes the time fraction, and ψτ (u) := 1{u ≤ 0} − τ . Moreover, introduce the (constrained) estimator β̃n(τ) := (0, αn(τ) ′)′, where
αn(τ) := arg min α∈Rk
n∑
i=1
ρτ (yi − w′iα), (4)
where ρτ (u) := u(1{u ≤ 0} − τ). Our tests are based on the following process
Hn(λ, τ, t) := (X ′ nXn/n) −1/2Sn(λ, τ, t), λ, τ ∈ [0, 1], t ∈ Rm, (5)
where Xn := (x ′ 1, . . . , x ′ n) ′ is n × m. As pointed out by Qu (2008), the process in (5) is asymptotically pivotal when evaluated at the true parameter vector; see also Parzen et al. (1994) for a similar argument. This allows us to construct tests that do not require trimming over time. The main idea behind our test statistic is to combine two detectors that are respectively designed to find deviations from H0,1 and H0,2. More specifically, a CUSUM-type statistic
LM1(λ, τ) := ∥∥∥∆Hn(λ, τ, β̃n(τ)) ∥∥∥ ∞ ,
with
∆Hn(λ, τ, β̃n(τ)) := Hn(λ, τ, β̃n(τ)) − λHn(1, τ, β̃n(τ))
is used to test H0,1, while the restriction of H0,2 is verified using the LM (Lagrange Multiplier) statistic
LM2(τ) := ∥∥∥Hn(1, τ, β̃n(τ)) ∥∥∥ ∞ . Since LM1 has no power against constant deviations from the null, and LM2 lacks
power if Granger causality is unstable, our tests will be of the form
ϕ ( LM1 + LM2 ) , (6)
for some weighting function ϕ : [0, 1] × [0, 1] 7→ R specified below. In what follows, we distinguish between situations where our interest lies in detecting deviations from the null (i) at a given quantile or (ii) across various quantiles. To derive the properties of theses tests, we impose the following assumptions that are similar to those in Qu (2008) and Oka and Qu (2011). Assumption A Let ui,n(τ) := yi −βi,n(τ)′xi. Then 1{ui(τ) ≤ 0} − τ is a martingale difference array with respect to Fi−1 := σ({yj−1, xj : j ≤ i}) for any τ ∈ [0, 1]. Let fi(·), Fi(·) and F−1i (·) denote the conditional density, conditional distribution, and conditional quantile function, respectively, of yi given wi. Assumption B . B.1 The distribution functions Fi(·) are absolutely continuous, with continuous densities fi(·) satisfying 0 <
¯ u ≤ fi(F−1i (τ)) ≤ ū < ∞ for all i.
B.2 For any ǫ > 0, there exists a σ(ǫ) > 0 such that |fi(F−1i (τ)+s)−fi(F−1i (τ))| ≤ ǫ for all |s| < σ(ǫ) and all 1 ≤ i ≤ n.
Assumption C The regressors are assumed to satisfy: . C.1 The vector w contains a constant. C.2 plimn→∞ 1 n ∑⌊λn⌋ i=1 fi(F −1 i (τ))xix ′ i = λH(τ) uniformly in λ ∈ [0, 1], where H(τ)
is a m×m non-random positive definite matrix. C.3 There exists a > 0 and A < ∞ such that E[‖xi‖4+a] ≤ A.
C.4 There exists b > 0 and B < ∞ such that for any n:
1 n
n∑
i=1
E[‖xi‖3(1+b)] ∨ E[ 1
n
n∑
i=1
‖xi‖3]1+b ≤ B.
C.5 plimn→∞ 1 n ∑⌊λn⌋ i=1 xix ′ i = λJ uniformly in λ ∈ [0, 1], where J is a m× m non-
random positive definite matrix. These assumptions are standard in the context of tests for structural breaks in quantile models and of tests for Granger causality in quantiles. Assumption A restricts the dependence over time. Serial independence is not required, instead we have a martingale difference assumption on the innovations. Assumption B introduces positivity and smoothness assumptions on the conditional density of yi given xi. Assumption C imposes restrictions on the regressors xi, in particular on the existence of moments. This assumption rules out trends in the regressors, but it allows for heteroscedasticity. 3.1 granger causality at a given quantile Let β0(τ) := (0 ′ p, α0(τ) ′)′ be the true coefficient under the null, define
R :=   Ip 0k×p   , R̄ :=  0p×k Ik   , (7)
and set C(τ) := J−1/2H(τ). Note that C(τ) is a square root of the inverse of the variance-covariance matrix of the limiting distribution of the estimator that solves the unrestricted quantile regression problem (Koenker, 2005). Proposition 1 Assume that Assumptions A, B, and C hold. For a given τ ∈ T , it holds uniformly in λ ∈ [0, 1] that
Hn(λ, τ, β̃n(τ)) = J −1/2Sn(λ, τ, β0(τ)) − λP (τ)J−1/2Sn(1, τ, β0(τ)) + op(1)
for P (τ) := C(τ)R̄(R̄′C(τ)R̄)−1R̄′, with
h(τ)J−1/2Sn(λ, τ, β0(τ)) ⇒ Bm(λ) + h(τ)C(τ)R ( λ∆(τ) + δ(τ) ∫ λ
0 g(v)dv
) . where h2(τ) := 1/(τ(1 − τ)). From the result above, we can directly deduce the limiting distribution of the two test statistics as summarized by Corollary 1. Corollary 1 For a given τ ∈ T , it holds under the assumptions of Proposition 1 uniformly in λ ∈ [0, 1]
h(τ)R′∆Hn(λ, τ, β̃n(τ))
⇒ BBp(λ) + h(τ)δ(τ)R′C(τ)R ( (1 − λ) ∫ λ
0 g(v)dv − λ
∫ 1
λ g(v)dv
) =: Z(1)(λ, τ)
and
h(τ)R′Hn(1, τ, β̃n(τ))
⇒ B̃p(1, τ) + h(τ)R′T (τ)C(τ)R ( ∆(τ) + δ(τ) ∫ 1
0 g(v)dv
) =: Z(2)(τ)
where B̃m(λ, τ) := T (τ)Bm(λ), with T (τ) denoting the inverse of the m×m matrix of eigenvectors of I − P (τ). Interestingly, and contrary to the corresponding GMM result in Rossi (2005), the limiting distribution of the LM statistic Hn(1, τ, β̃n(τ)) is not pivotal because the projection matrix P (τ) is oblique (i.e. idempotent of rank k but not symmetric). An important exception is given if the following additional condition is satisfied:
Assumption D The p × k matrix Q(τ) := R′C(τ)R̄H−1α (τ)J1/2α is zero, where Hα(τ) and Jα denote the lower-right k × k sub-matrix of H(τ) and J, respectively, partitioned according the k × 1 subvector α(τ) of β(τ) = (γ(τ)′, α(τ)′)′. Assumption D ensures that the oblique projection matrix P (τ) defined in Proposition 1 is equal to the orthogonal projection R̄(R̄′R̄)−1R̄′ = R̄R̄′, which follows from observing that P (τ) decomposes into an orthogonal projection perturbed by a nilpotent matrix
P (τ) = C(τ)R̄(R̄′C(τ)R̄)−1R̄′ = R̄R̄′ +
 0p×p Q(τ)
0k×p 0k×k
  . (8)
A sufficient condition for Assumption D is Hc(τ) = J(τ) for some scalar c(τ) ∈ (0,∞), which holds under homoscedasticity. Alternatively, Assumption D is satisfied if w is just a constant or, more generally, under conditional mean independence of z with respect to w (i.e. E[z|w] = E[z]) as both of theses conditions ensure under
the null Q(τ) = 0p×k. Corollary 2 Under the null hypothesis and Assumptions A–D, we get for a given τ ∈ T and uniformly in λ ∈ [0, 1]
h(τ)Hn(τ, λ, β̃n(τ)) ⇒   Bp(λ) BBk(λ)   ,
where BBk(·) and Bp(·) are independent. The p-dimensional Brownian motion Bp and the k-dimensional Brownian bridges BBk arise due to the restricted and unrestricted components of the process towparameter process Hn(λ, τ, β(τ)), respectively. The limiting random variable under the null is independent of τ . While this is true if Assumption D holds, violations from this assumption introduce dependence on nuisance parameters (cf. Proposition 3). Based on the previous result, we will now introduce our first test statistic, suited to test H0 at a given quantile τ
LM(τ) := h(τ) ( sup
λ∈[0,1] LM1(λ, τ) + LM2(τ)
) . For fixed τ , the test statistic essentially consists of the sum of two individual test statistics, which reflect the two parts of the alternative hypothesis. Both statistics are based on the standardized subgradient of the unconstrained quantile regression through the process Hn(λ, τ, t) from (5). The first part, LM1(λ, τ), is the CUSUM part that detects structural breaks in the parameter γi(τ). Typically, for CUSUM statistics, one considers the supremum over the potential breakpoints λ ∈ [0, 1]. The second part, LM2(τ), is essentially the LM statistic for the hypothesis H0,2. Corollary 1 states why it makes sense to consider the sum of the two individual test statistics: The first statistic does have local power against structural breaks, but it has no power if there is Granger causality with constant parameters. The second part has power if there is Granger causality with constant parameters, but it has no power if ∆(τ) = 0 and ∫ 1
0 g(v)dv = 0. The interpretation of the latter
would be that there are structural breaks that lie in opposite directions over time. Corollary 3 For a given τ ∈ T , we get under the assumptions of Proposition 1
LM(τ) →d sup λ∈[0,1]
∥∥∥Z(1)(λ, τ) ∥∥∥ ∞ + ∥∥∥Z(2)(τ) ∥∥∥ ∞ ,
while under the null
LM(τ) →d sup λ∈[0,1]
‖BBp(λ)‖∞ + ∥∥∥B̃p(1, τ) ∥∥∥ ∞ . where BBp and B̃p(λ, τ) are independent. If Assumption D holds, then B̃p(λ, τ) = Bp(λ). Thus, unless Assumption D is satisfied, the limiting distribution is not pivotal due to the second element LM2 of our test statistic that induces dependence on the quantile level τ via Q(τ). More specifically, it can be shown that
LM2(τ) = ∥∥∥(I − P (τ))J−1/2Sn(1, τ, β0(τ)) ∥∥∥ ∞ + op(1),
where the oblique projection P (τ) causes quantile dependece because it cannot be diagonalized; cf. Eq. (8). The distribution of LM2 can be viewed as a maximum of p-scaled absolute standard normals, where–similar to the discussion in Hansen (2021)–the scaling differs in general from unity, thereby capturing deviations from Assumption D (e.g. from homoskedasticity to heteroskedasticity). 3.2 granger causality at all quantiles To avoid multiple testing issues when performing inference across various quantiles, we extend the test statistics from the previous section to allow uniform inference across both λ and τ . Following Andrews and Ploberger (1994) and Hansen (1996),
we consider the following test statistics:
supLM := sup τ∈T
( sup
λ∈[0,1] LM1(λ, τ) + LM2(τ)
) ,
expLM := ∫
T exp
[ 1
2
( sup
λ∈[0,1] LM1(λ, τ) + LM2(τ)
)] dτ. (9)
While both weighting schemes (over τ) direct power against relatively distantly located alternatives, expLM can be considered optimal (see also Rossi, 2005). Similar to Proposition 1, we first derive the properties of the process Eq. (5) that serves as the building block of our test statistics. Proposition 2 Assume that Assumptions A, B, and C hold uniformly in τ . Then, uniformly in (τ, λ) ∈ T × [0, 1], we have R′∆Hn(λ, τ, β̃n(τ)) ⇒ SSp(λ, τ) + δ(τ)R′C(τ)R ( (1 − λ) ∫ λ
0 g(v)dv − λ
∫ 1
λ g(v)dv
)
=: Y (1)(λ, τ)
and
R′Hn(1, τ, β̃n(τ)) ⇒ S̃p(1, τ) +R′T (τ)C(τ)R ( ∆(τ) + δ(τ) ∫ 1
0 g(v)dv
) =: Y (2)(τ),
where S̃m(τ, λ) := T (τ)Sm(τ, λ) for Sm(λ, τ) := (S1m(λ, τ), . . . ,Smm(λ, τ))′ is an m× 1 vector of independent Gaussian processes with
cov[Sim(λ1, τ1),Sim(λ2, τ2)] = (λ1 ∧ λ2)(τ1 ∧ τ2 − τ1τ2)
and SSm(λ, τ) := Sm(λ, τ) − λSm(1, τ) so that
cov[SS im(λ1, τ1),SS im(λ2, τ2)] = (λ1 ∧ λ2 − λ1λ2)(τ1 ∧ τ2 − τ1τ2). Again, the weak limit of Hn(1, τ, β̃(τ)) is affected by nuisance parameters unless Assumption D holds, in which case S̃p(λ, τ) = Sp(λ, τ). Moreover, note that S(1, τ) = B(τ), while the Gaussian process SS(λ, τ) is also referred to as a Brown-
ian pillow or a pinned Brownian sheet; see also Qu (2008, Sec 4). From the above, the limiting distribution of the test statistics follows readily by the continuous mapping theorem:
Corollary 4 Uniformly in (τ, λ) ∈ T × [0, 1], we have under the conditions of Proposition 2
supLM →d sup τ∈T
( sup
λ∈[0,1]
∥∥∥Y (1)(λ, τ) ∥∥∥ ∞ + ∥∥∥Y (2)(λ, τ) ∥∥∥ ∞
) ,
expLM →d ∫
T exp
[ 1
2
( sup
λ∈[0,1]
∥∥∥Y (1)(λ, τ) ∥∥∥ ∞ + ∥∥∥Y (2)(λ, τ) ∥∥∥ ∞
)] dτ,
while, under the null, Y (1)(λ, τ) = SSp(λ, τ) and Y (2)(λ, τ) = S̃p(1, τ). If Assumption D holds, then S̃p(λ, τ) = Sp(λ, τ). 3.3 practical implementation If Assumption D is satisfied, then it is easy to simulate the limiting distributions because they are free of unknown nuisance parameters (cf. Corollaries 3 an 4). More specifically, using numerical techniques we can arbitrarily well approximate the Brownian motion B(·) and the Brownian bridge BB(·) for the fixed-τ case or, if instead a continuum of quantiles is considered, the limiting processes S(·) and SS(·) (see the discussion in Andrews (1993) and Qu (2008) for details on the numerical computation). If Assumption D is violated, then we could still simulate the limiting distributions. But since the weak limits depend in this case on the characteristics of the dgp (cf. Corollaries 3 an 4), we need to tabulate critical values for each application separately. In principle, one could proceed as follows: Firstly, based on a consistent estimator Hn(τ), say, of H(τ), we estimate Q(τ) using Qn(τ) := J −1/2 n Hn(τ)Hn,α(τ)J 1/2 n,α, with Jn := X ′X/n, and where Hn,α(τ) and Jn,α denote, respectively, the sample analogues of Hα(τ) and Jα from Assumption D. For instance, a consistent estimator can be obtained via
Hn(τ) = 1
2ncn
n∑
i=1
1{ûi(τ) ≤ cn}xix′i,
where cn → 0, √ ncn → ∞ (see Powell, 1991 and Koenker, 2005, Sec 3.4). Secondly, we obtain from Qn(τ) and Eq. (8) the inverse matrix of eigenvectors Tn(τ), which, by the continuous mapping theorem, is a consistent estimator. Finally, we simulate the limiting stochastic processes similarly to the case where Assumption D is met, but we substitute B(·) (S(·)) with B̃(·) (S̃(·)). Clearly, this procedure becomes very time-consuming when testing at many quantiles. Nevertheless, an important exception is given for p = 1 < k,1 where proper scaling of the test statistics ensures a pivotal limiting distribution; e.g. for a given τ ∈ T
h(τ) LM2(τ)√
1 +Qn(τ)Qn(τ)′ →d |B1(1)| ≡
√ χ2(1). Unfortunately, a similar re-scaling does not work for other values p > 1. Therefore, we propose an additional resampling procedure that especially for the ‘many-τ ’ case is significantly less time consuming. In particular, we propose a bootstrap procedure which is inspired by Rothe and Wied (2013) and that is valid both in the ‘fixed-τ ’ case and the ‘many-τ ’ case. Note, however, that we actually need the bootstrap only in the former case because the computational burden of the procedure described above for the ‘fixed-τ ’ case is manageable. The algorithm for obtaining one bootstrap sample {(ŷi,b, xi,b), 1 ≤ i ≤ n}, b ∈ {1, . . . , B}, for a large value of B is as follows:
Step 1 Draw with replacement {xi,b, 1 ≤ i ≤ n} from the realized regressors {xi, 1 ≤ i ≤ n}
Step 2 For each 1 ≤ i ≤ n, set ŷi,b = αn(Ui,b) ′wi,b,
where {Ui,b, 1 ≤ i ≤ n} is a simulated IID sequence of standard uniformly distributed random variables on the interval (0, 1), αn is the restricted quantile estimator and xi,b = (z ′ i,b, w ′ i,b) ′ with the same dimensions as in the realized data. Step 3 Use the bootstrap data {(ŷi,b, xi,b), 1 ≤ i ≤ n} to obtain bootstrap esti1Note that the case k = 1 is trivial because then w = 1 and assumption D is automatically
satisfied. mates Hn,b(λ, τ, β̃n,b(τ)), say, of Hn(λ, τ, β̃n(τ)) and construct the corresponding test statistics for τ ∈ T . Step 4 Our tests reject if they exceed the corresponding bootstrap critical values
ĉ(α), say, for some α ∈ (0, 1). The algorithm above means that, for generating a bootstrap sample, we first draw with replacement from the regressors, where random sampling is justified by Assumption A (i.e. Corollary 3 and Corollary 4 are unaffected by the temporal dependence of xi). The corresponding y-values are obtained by applying the estimated quantile function on randomly chosen standard uniformly distributed random variables. Thus, it is ensured that, under the null hypothesis, we asymptotically generate data from the distribution of (y, x) with Qy(τ |x) = x′β(τ) so that, in Step 3, no centring of Hn,b(λ, τ, β̃n,b(τ)) is needed. Here, it is crucial to draw from a uniform distribution on the whole interval (0, 1) in Step 2 to get simulated data from the whole conditional distribution of y given x, although the interval T is a strict subset of (0, 1). So, the restriction is stronger than actually necessary, but the null distribution is still enforced. Under the alternative hypothesis, the critical values remain stochastically bounded as the validity of the null hypothesis is enforced within the generation of the bootstrap sample. These considerations are summarized in Proposition 3. For simplicity, consider the ‘many-τ ’ case and let us generically represent our test statistics in Eq. (9) as ϕ(LM1 + LM2) using the weighting function ϕ : [0, 1] × T 7→ R from (6). Proposition 3 . Let α ∈ (0, 1) and assume that Assumptions A, B, and C hold uniformly in τ ∈ T . (i) Under the null hypothesis
P(ϕ(LM1 + LM2) ≥ ĉ(α)) → α. (ii) Under fixed alternatives
P(ϕ(LM1 + LM2) ≥ ĉ(α)) → 1. 4 monte carlo simulations In the small sample simulations, we consider a location-scale model
yi =wi + γizi + (1 + αwi)εi,
where (w1, z1, ε1), . . . , (wn, zn, εn) are IID copies of
w ∼ χ2(3), z, ε ∼ N (0, 1), and ε ⊥ (w, z). First, we investigate the size properties setting γi = 0 for all i. We distinguish between homoscedasticity (α = 0) and heteroscedasticity (α = 3). In the latter case, Assumption D will only be satisfied if E[z|w] = E[z]. Therefore, we consider three scenarios: (1) α = 0 & z ⊥ w, (2) α = 3 & z ⊥ w, (3) α = 3 & cov[z, w] ≃ −3/4. Thus, it is only in scenario (3) where the asymptotic critical values based on the asymptotic approximation under Assumption D are wrong. We perform tests at five selected quantiles τ ∈ {0.05, 0.25, 0.50, 0.75, 0.95} as well as across the complete interval [0.05, 0.95]. We consider the case where test statistics are compared to critical values obtained under Assumption D (labelled ‘asy’). Alternatively, we adjust the statistics as explained in Section 3.3 when testing at a given τ or, when testing across all τ ∈ [0, 1], use the bootstrap (both labelled ‘adj’). For comparison, we compute also the supWald test of Koenker and Machado (1999) given by
supWald = sup τ∈T
nh2(τ)γn(τ) ′Ω−1n (τ)γn(τ) H0→d sup τ∈T h2(τ)BBp(τ)′BBp(τ) (10)
where we equip the statistic with (pairs) bootstrap standard errors Ωn(·) implemented using the quantreg package of R (Koenker et al., 2018). Critical values are easily obtained from a discrete approximation of the Bessel limiting process (see also Andrews (1993, Tab 1)). For all bootstrap procedures we use B = 499 replications. All test decision are carried out at the five per cent significance level. Table 1 contains the Monte Carlo results under the null hypothesis of Granger noncausality based on 2,000 Monte Carlo repetitions. As can be seen from panel a) and
b) of Table 1, size is controlled if n is moderately large irrespective of conditional homoscedasticity/heteroscedasticity because conditional mean independence and thus Assumption D is satisfied. As suggested by our theory, the performance of the tests using the asymptotic approximation derived under Assumption D deteriorates if cov[z, w] 6= 0 (cf. panel c) of Table 1). However, in this case the adjustment/bootstrap alternatives do their job by effectively keeping size. The empirical size of the supWald test is in all scenarios in line with the nominal significance level. Turning to the power properties, we consider the following three break scenarios:
A : γi =    γ i ≤ ⌊n/2⌋ −γ otherwise
B : γi =    0 i ≤ ⌊n/2⌋ γ otherwise
C : γi = γ. This means that, in Scenario A, we have a structural break in the Granger parameter and the parameters sum up to zero over time (i.e. ∫ 1
0 g(v)dv = 0). Also
in Scenario B, there is a structural break, but the sum over time is not zero. In Scenario C, the Granger parameter is constant and equal to γ (i.e. ∆(τ) 6= 0). For a better comparison, we focus on the dgp, where α = 0 and z ⊥ w (i.e. Assumption D is satisfied) and focus on the tests over the whole quantile interval [0.05, 0.95]. That is, we consider our two statistics supLM, expLM (bootstrapped version) and the supWald test. It is expected that our tests have power against all alternatives, which increases in n, while supWald has no power in Scenario A, also for large n because ∫ 1
0 g(v)dv = 0. This is indeed the empirical result. Somewhat
surprisingly, in all scenarios, the break-robust tests are more powerful than the supWald, in particular also in Scenario C, where no break is present. Among our new tests, the expLM test has more power than the supLM test. 5 empirical illustrations Illustration 1: Crude Oil and Returns
We revisit an analysis about the causal relationships between crude oil and stock returns from Ding et al. (2016) to illustrate the advantages of our new test. Ding et al. 18
(2016) consider the daily returns of West Texas Intermediate (WTI) and Dubai crude oil as well as five major (mainly Asian) stock index returns, S&P 500, Nikkei, Hang Seng, Shanghai, and KOSPI, from January 1, 1996, to October 12, 2012. One of their main findings is a considerable Granger influence in quantiles of the WTI returns on the stock returns, which is much stronger compared with the other direction (stocks on WTI). The application of our test supports this finding and, in particular, gives substantially stronger evidence for this kind of relationship. We consider the settings of their Table 4, where eight different quantile-level intervals are employed. Table 2 presents the p-values of our bootstrapped expLM and supLM tests, as well as the supWald test in Eq. (10) equipped with bootstrap standard errors, each computed over different quantile intervals using a step size of 0.01 for the grids. In simulations, these three bootstrap-based tests display best size and power properties. In particular, the latter test equipped with bootstrap standard errors outperforms the test equipped with a kernel based plug-in estimator for the asymptotic covariance matrix used by Ding et al. (2016), so that refrain from using that test. We consinder the same quantile autoregressive distributed lag model with the same number of lags (which is obtained by a sequential procedure and is different for the individual specifications; see Ding et al. (2016, Tab 4)). Out of 80 scenarios in total, the p-values of our test are smaller than or equal to these in Ding et al. (2016) in 68 times. The cases in which our p-values are higher, mostly concern the index KOSPI, where our p-values are larger seven out of 16 times. But this mainly concerns cases, where the p-values are large anyway. So, we have a robust finding that, if there is some evidence for Granger causality, our test strengthens this evidence. We corroborate our findings with an analysis about the structural stability of the correlation ρ(i) = corr[yi, zi−1] between the lagged WTI (z) and the stock index returns (y). An application of the test for constant correlations from Wied et al. (2012), whose assumptions are typically plausible in the context of (stock) returns, shows that all five p-values are small. For Hang Seng and Nikkei, they are substantially smaller than 0.001. For KOSPI, the p-value is larger (0.014), which fits to the observation in the previous paragraph that the advantage of our new test might be smaller in such cases. Illustration 2: Phillips Curve
Following Stock and Watson (2001) and Rossi and Wang (2019), we investigate potential Granger causality between inflation (πt), measured by the quarterly GDP deflator, the unemployment rate (ut), and federal funds rate (Rt). The quarterly data cover the time span from the first quarter in 1959 to the fourth quarter in 2000. Similarly as in Illustration 1, we consider a quantile autoregressive distributed lag
Test [.05;.95] [.05;.5] [.5;.95] [.05;.5] [.2;.4] [.4;.6] [.6;.8] [.8;.95]
Shanghai
expLM .026 .000 .046 .020 .000 .010 .028 .188 supLM .046 .012 .112 .008 .004 .014 .070 .080 supWald .288 .127 .379 .206 .066 .102 .038 .263
Hang Seng
expLM .000 .000 .000 .000 .000 .000 .000 .046 supLM .000 .000 .000 .000 .000 .000 .000 .046 supWald .002 .001 .235 .001 .000 .039 .140 .275
KOSPI
expLM .018 .004 .713 .002 .002 .056 .307 .669 supLM .028 .022 .447 .010 .006 .084 .431 .818 supWald .042 .015 .525 .005 .001 .465 .987 .367
Nikkei
expLM .000 .000 .000 .000 .000 .000 .000 .004 supLM .000 .000 .000 .000 .000 .000 .000 .004 supWald .000 .000 .045 .000 .000 .005 .056 .684
S&P 500
model and test for Granger causality separately with each one of the three variables as a dependent variable. Each of the other two variables is restricted separately, the lag length is 4 and we consider the same quantile levels as in Illustration 1. Table 3 displays the Granger causality test results. The overall picture is similar to that of Illustration 1, in most cases (90 out of 96 times), the p-values of the robust tests are equal or lower. In general, the p-values are lowest in the combination of R and u. This is an observation which is also made in Rossi and Wang (2019), who focus on Granger causality in mean. 6 conclusion We have proposed new tests for Granger causality that are robust against structural breaks and compete very well against existing tests.