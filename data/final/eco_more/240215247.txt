Vertical Federated Learning (VFL) has emerged as a popular machine learning paradigm, enabling model training across the data and the task parties with different features about the same user set while preserving data privacy. In production environment, VFL usually involves one task party and one data party. Fair and economically efficient feature trading is crucial to the commercialization of VFL, where the task party is considered as the data consumer who buys the data party’s features. However, current VFL feature trading practices often price the data party’s data as a whole and assume transactions occur prior to the performing VFL. Neglecting the performance gains resulting from traded features may lead to underpayment and overpayment issues. In this study, we propose a bargaining-based feature trading approach in VFL to encourage economically efficient transactions. Our model incorporates performance gain-based pricing, taking into account the revenue-based optimization objectives of both parties. We analyze the proposed bargaining model under perfect and imperfect performance information settings, proving the existence of an equilibrium that optimizes the parties’ objectives. Moreover, we develop performance gain estimation-based bargaining strategies for imperfect performance information scenarios and discuss potential security issues and solutions. Experiments on three real-world datasets demonstrate the effectiveness of the proposed bargaining model. 1 introduction Federated learning (FL) has become a popular machine learning paradigm for that it allows model training to happen across multiple devices or institutions, aka. clients, while keeping their data localized. Vertical Federated Learning (VFL) is a subcategory of FL that enables the training of clients’ datasets sharing the data from the same set of users while holding different features. The increasing demand for VFL is evident in recent industrial trends [1–4]. Organizations with limited or fragmented datasets are driven to partner with complementary data sources to amplify the training of machine learning models. Alongside, global concerns about data breaches and privacy violations have amplified the urgency for enhanced security measures. Consequently, a rise in privacy-focused VFL platforms and initiatives has been observed
[5–7]. While multi-party VFL is a subject of extensive academic research [8], insight from the China Academy of Information and Communications Technology’s (CAICT) White Paper on Federated Learning Scenario Applications1, [6], and [5], indicates that in practical applications or production environments, VFL is often implemented with a single task party and data party. Specifically, according to the white paper, this 1v1 VFL paradigm has been employed by commercial banks to amalgamate external data when constructing joint anti-fraud models, establish potential insurance users alongside insurance companies, as well as by advertisers to conduct user modeling with data of external media platforms. The commercial relevance and economic impact attributed to this 1v1 VFL model is steadily growing. Therefore, in this paper, we focus on the VFL setting characterized by a singular task party and a singular data party. In the current era, data has transformed into a valuable commodity, often considered as goods with specific prices [9–13]. This valuation is prominently seen in digital products, where information serves as both a resource and product, forming the backbone of modern services and technologies. The two key roles in VFL can also be considered as data consumer and the data provider: the “task party", responsible for labels and performing downstream tasks, and the “data party", supplying the essential feature data. Current works in VFL mostly concentrate on protecting the security and privacy of data or information transmission between the task party and the data party, ensuring that collaboration occurs without compromising the integrity and confidentiality of the involved parties. However, the intricate aspect of data valuation, which underpins many economic decisions in other contexts, has not been extensively explored or studied. In the current production environment, data trading in VFL is mostly conducted at party level. More specifically, the data party names a price for its feature, and when a task party is paired with it for VFL, the task party buys all features offered by the data party. However, this may lead to undesired outcomes: 1) for the task party, buying all data from the data party, it also pays for features that may not be useful in enhancing model performance, and 2) for the data party, as the utility of the data is contingent upon task parties’
1http://www.caict.ac.cn/kxyj/qwfb/ztbg/202202/P020220222528294962585.pdf
ar X
iv :2
40 2. 15 24
7v 1
[ cs
.L G
] 2
3 Fe
different application scenarios and production environments, it may under-estimate/over-estimate the value of the features. This indiscriminate and one-shot trading of all features between parties highlights the need for a more nuanced and economically efficient approach for feature trading in VFL. Bargaining has proven to be effective in various economic contexts where there are two players [14] participated, which permits parties to negotiate and agree upon the value of individual features or combinations of features, resulting in a more flexible and efficient allocation of resources. The iterative process where a party could revisit its offers also encourages the achieving of mutual benefit. Inspired by this, we here propose to introduce bargaining for the feature trading in VFL. Bargaining in the context of VFL diverges from traditional data asset markets in several key aspects, and this brings non-trivial challenges. First, in conventional one-to-one bargaining in data markets, the buyer seeks to obtain specific goods, such as datasets, from the seller [11]. The participants then negotiate the price of these goods. In contrast, within the setting of VFL, bargaining is result-oriented. For the task party, it targets to maximize the net profit of using the bought feature to perform VFL. For the data party, it aims at pricing the features with their utility considered and maximizing the payment of selling features. As a consequence, the pricing mechanism should take model performance gain into consideration. Second, in conventional one-one bargaining, the information advantage is clearer, i.e., the seller has more information about the value of goods, and, thus is in a better place to take the lead during the game [14]. While in VFL market, the value of features is hard to be known in advance to both the data party (seller) and the task party (buyer). This uncertainty arises primarily for two reasons: 1) a newly paired task party and data party have no information about the performance gain that their collaboration could result in until VFL is conducted; and 2) even if the performance gain is known in advance, the data party lacks insights about the task party’s model utility, which is related to the production environment and not revealed since they are proprietary business information belonging to the task party. Therefore, it is important to manage the information on the market and design fair bargaining model accordingly. To deal with these problems, we first define a performance gain related payment function to price the outcome of a VFL course, based on which we formulate the objectives of the participants in the form of revenues. A bargaining model with the key idea that the task party targets a certain performance gain, offering a quoted price to the data party and the data party responds with products, i.e., feature bundles, is proposed. The negotiation process continues until both parties agree on a feature bundle - payment matching (acceptance) or until they are unable to reach an agreement (breakdown). The task party is designated to take the lead during the game because it is more sensitive to the outcome of the VFL, as well as be aware of the budget and utility rate of its model. We analyze the bargaining under perfect performance information and imperfect performance information settings, distinguished by if the performance gain resulting from a feature bundle can be known in advance. The existence of an equilibrium under perfect performance information is proved theoretically. As bargaining is an iterative process with time cost, we further discuss the equilibrium by considering the cost factor. Further, bargaining strategies
Table 1: Notations and descriptions. Notations Descriptions 𝑇 The 𝑇 -th bargaining round 𝐹 ,F Feature bundle, a set of feature bundles Δ𝐺 Performance gain of the task party p = (𝑝, 𝑃0, 𝑃ℎ) Task party’s quoted price, composed of payment rate 𝑝 , base payment 𝑃0, and highest payment 𝑃ℎ (𝑝𝑙,𝑖 , 𝑃𝑙,𝑖 ) Data party’s reserved price of feature bundle 𝐹𝑖 , composed of reserved price of payment rate 𝑝𝑙,𝑖 , and reserved price of base payment 𝑃𝑙,𝑖 𝑢 Task party’s utility rate 𝑅𝑑 Revenue received by the data party 𝑅𝑡 Revenue received by the task party 𝑓 , 𝜃 𝑓 Task party’s performance gain estimation model, model weights 𝑔, 𝜃𝑔 Data party’s performance gain estimation model, model weights
are established in imperfect performance information setting based on learning-based estimation. Key contributions of this paper are summarized as follows. • We identify the need for an economically efficient approach for feature trading in VFL and propose to introduce bargaining in VFL market. • A bargaining model is designed with performance gain based pricing. We analyze the proposed bargaining model under perfect performance information setting with and without bargaining cost considered, proving the existence of an equilibrium that optimizes the objectives of the task party and the data party. • Performance gain estimation based bargaining strategies are proposed under the imperfect performance information setting for both parties. We further discuss possible security issues and solutions for the proposed VFL market. • We conduct extensive experiments on three real-world datasets, verifying the effectiveness of the proposed bargaining model. 2 preliminary Key notations and descriptions used in this paper are summarized in Table 1. We assume that both parties have 𝑛 aligned training samples. The task party locally maintains a dataset {𝑋𝑡 , 𝑌 } of the 𝑛 samples, where𝑋 ∈ R𝑛×𝑑𝑡 are𝑑𝑡 features and𝑌 ∈ R𝑛 are the labels. The data party locally maintains a dataset {𝑋𝑑 }, where𝑋𝑑 ∈ R𝑛×𝑑𝑑 are 𝑑𝑑 features of the n samples. We denote the performance of the model trained by the task party itself as 𝑀0 and the performance of a model trained after VFL as 𝑀 . The performance gain Δ𝐺 is calculated as the relative improvement of performance, i.e.,
Δ𝐺 = 𝑀 −𝑀0 𝑀0 . (1)
In the above formula, we assume the performance metric the higher the better. If not, the sign of Δ𝐺 needs to be reversed. Definition 2.1. Feature Bundle. Given the 𝑑𝑡 features of the data party, denoted as S, a feature bundle denoted as 𝐹 is a combination of individual features in S, i.e., 𝐹 ⊆ S. Denote the set of feature bundles as F . Feature bundles are the goods selling on the VFL market. Definition 2.2. Quoted Price. The task party quotes for a feature bundle of the data party by stating the payment rate 𝑝 , the base payment 𝑃0, and the highest payment 𝑃ℎ = 𝑃0 + 𝐶 , where 𝐶 ≥ 0. p = (𝑝, 𝑃0, 𝑃ℎ) is referred to as the quoted price. Definition 2.3. Payment. Given the performance gain Δ𝐺 in a VFL course, the payment received by the data party is calculated as:
min{max{𝑃0, 𝑃0 + 𝑝Δ𝐺}, 𝑃ℎ}. (2)
The payment function indicates that the data party can receive a payment of at least 𝑃0, at most 𝑃ℎ , and somewhere in between depending on 𝑝 and Δ𝐺 . Definition 2.4. Reserved Price. Given a feature bundle 𝐹𝑖 , the reserved price, denoted as (𝑝𝑙,𝑖 , 𝑃𝑙,𝑖 ), is a value privately maintained by the data party, which represents the pre-defined minimum base payment and minimum payment rate it expects to receive if offering the feature bundle to the task party. Note that the reserved price can be considered as cost-related. For example, a feature bundle of a larger number of features may have higher reserved price as the collecting cost of the feature bundle is higher than a feature bundle of a smaller number of features. 3 the bargaining-based vfl market  3.1 assumptions Before going deep into the proposed method, we first illustrate several essential assumptions of the VFL market. Assumption 3.1 (Individual Rationality). The data party and the task party are rational, seeking to maximize their revenues, respectively. Assumption 3.2 (Task Party Leads). The task party takes the lead during the game by offering the quoted price, and the data party reacts by offering the feature bundle. Assumption 3.3 (Benign Clients). The features offered by the data party and the performance gain reported by the task party are not manipulated. The intention of using Assumption 3.3 is to exclude potential adversary participants that attack the FL environment with malicious behaviors, such as submitting noise instead of real model performance, so as to focus on the design of the bargaining model. 3.2 objectives of participants Given the payment function defined in Section 2, the objectives of the task party and the data party can be formulated in the form of revenues. Typically, a higher-performing model generates greater utility for its owner. The task party enters the VFL market as a featured buyer, seeking to improve its model’s performance with minimal feature buying costs. Let 𝑢 denote the utility increase resulting from a unit of performance gain. The task party’s objective
Ph P0 p
G
P0
Ph
Pa ym
en t
(Ph P0p , Ph)
min{max{P0, P0 + p G}, Ph}
(a) The payment received by the data party as a function of Δ𝐺 . Ph P0 p
G
P0
Ph
Pa ym
en t
(Ph P0p , Ph)
min{max{P0, P0 + p G}, Ph}
(b) The net profit of the task party as a function of Δ𝐺 . Figure 1: Δ𝐺 v.s. the objective functions of the data party and the task party. is to determine the best quoted price that maximizes net profit. Denote the net profit it can receive as 𝑅𝑡 , the objective of the task party can be mathematically expressed as:
𝑅𝑡 = max 𝑝,𝑃0,𝑃ℎ 𝑢Δ𝐺 −min{max{𝑃0, 𝑃0 + 𝑝Δ𝐺}, 𝑃ℎ}. (3)
The data party, on the other hand, aims to maximize the monetary payment it receives. However, the highest payment the data party can receive is limited by 𝑃ℎ of the quoted price, which means that an overqualified feature bundle that achieves performance gain greater than (𝑃ℎ − 𝑃0)/𝑝 will not be fairly paid. Therefore, a reasonable strategy for the data party is to offer a feature bundle that achieves performance gain as close to (𝑃ℎ − 𝑃0)/𝑝 as possible. Mathematically, denote the payment it receives as 𝑅𝑑 , the objective of the data party can be formulated as:
𝑅𝑑 = min 𝐹 |𝑃ℎ −max{𝑃0, 𝑃0 + 𝑝Δ𝐺}|. (4) 3.3 iterative bargaining We design an interactive process where the feature trading operates inmultiple rounds of price-feature offering until certain termination conditions are met. For each full bargaining round, the workflow can be described as follows,
• Step 1. The task party initiates the process by announcing (𝑝, 𝑃0, 𝑃ℎ), which serves as a quote for features in the upcoming VFL course. • Step 2. The data party responds by determining a feature bundle 𝐹 to offer to the task party. • Step 3. The two parties proceed with VFL course on 𝐹 . In Step 1 and Step 2, there are termination conditions applied regarding the received Δ𝐺 in VFL course and their objectives. We next discuss the bargaining strategies, as well as termination conditions, of two parties in two settings: perfect performance information and imperfect performance information. We first analyze bargaining in the perfect information setting, where the the parties have more awareness of each other, and then extend the analysis to imperfect setting. In the perfect information setting, we consider that the two parties know in advance about the performance gain of conducting VFL on each feature bundle of the task party. And for imperfect information, we suppose the performance gain is not known in advance unless VFL is formed after a round of iteration. We assume that in both situations, the objective functions of the parties are known to each other. 3.4 perfect performance information For the data party, the perfect information setting refers to the fact that it is aware of the performance Δ𝐺𝑖 of any feature bundle 𝐹𝑖 it owns when paired with a data party for bargaining. In the context of the task party, the concept of perfect information entails its awareness of the performance gain associated with the feature bundles. To be more precise, it possesses knowledge of |F | values of Δ𝐺 , where F is the set of all feature bundles owned by the data party. Achieving this state of perfect information can be facilitated through the involvement of a trustworthy third party, such as a trading platform, which can conduct pre-bargaining training for both parties. It is important to clarify that this awareness does not extend to obtaining detailed information about the specific characteristics of individual feature bundles, as this would violate the privacy-preserving principles of FL. 3.4.1 Perfect Performance Information: Bargaining Analysis On The Data Party. We now delve into the bargaining strategy employed by the data party in the perfect performance information setting. Given a quoted price (𝑝, 𝑃0, 𝑃ℎ) presented by the task party, the data party’s objective is to choose the most optimal bundle within the confines of this price. The strategic approach of the data party is as follows. Initially, the data party compares the reserved prices of feature bundles with (𝑝, 𝑃0), and discards bundles whose reserved prices exceed this threshold. It then finds a feature bundle whose performance gain lies nearest to, but does not surpass, (𝑃ℎ − 𝑃0)/𝑝 . This ensures the generation of a performance gain that would yield the maximum permissible payment within the range of (𝑝, 𝑃0, 𝑃ℎ), eliminating undervaluation concerns. It’s important to highlight that, under the objective defined in Equation 4, the data party lacks the motivation to offer a suboptimal feature. This is rooted in the fact that its compensation is contingent on the performance gain realized by the task party. Furthermore, given that the task party takes the lead during bargaining, the reserved price plays an important role in protecting the interest of the data party. This is because the payment the data part could receive is a function of Δ𝐺 and upper bounded by 𝑃ℎ . As depicted in Figure 1(a), with a predetermined quoted price, the payment received by the data party is monotonically increasing to Δ𝐺 when Δ𝐺 ≤ (𝑃ℎ − 𝑃0)/𝑝 and holds as 𝑃ℎ when Δ𝐺 > (𝑃ℎ − 𝑃0)/𝑝 . In the meanwhile, according to the objective defined in Equation 3, the task party is driven to maximize its net profit. To this end, the task party seeks to depress both 𝑝 and 𝑃0 while providing a sufficiently enough 𝑃ℎ . This ensures that the data party, enticed by the proposed compensation, delivers the highest quality feature bundle, all while the task party incurs minimal expenses. The introduction of the reserved price acts as a countermeasure to this behavior. It guarantees that only those feature bundles conforming to the quoted price are considered in a given bargaining round. 3.4.2 perfect performance information: bargaining analysis on the Task Party. As defined in Equation 3, the primary goal of the task party revolves around maximizing the net profit derived from a VFL course. We assume that the utility rate is larger than the payment
rate due to self rationality of the task party, i.e.,𝑢 > 𝑝 . As illustrated in Figure 1(b), the net profit demonstrates a monotonic increase with respect to Δ𝐺 , yet it remains negative when the performance gain falls below 𝑃0/(𝑢−𝑝). To establish the pricing strategy adopted by the task party, we propose the following theorem. Let Δ𝐺𝑚𝑎𝑥 denote the highest achievable performance gain attainable through the feature bundles. Consider a negotiation round in which the task party has presented a specific quoted price (𝑝, 𝑃0, 𝑃ℎ), and subsequently, a feature bundle is selected, yielding a performance gain of Δ𝐺 after undergoing VFL. Denote the payment received by the data party as 𝑅𝑑 , where
𝑅𝑑 = 𝑃0 + 𝑝Δ𝐺, and the net profit received by the task party as 𝑅𝑡 , where
𝑅𝑡 = 𝑢Δ𝐺 − 𝑃0 − 𝑝Δ𝐺. We can formulate Theorem 3.1. Theorem 3.1. There exists a quoted price (𝑝∗, 𝑃∗0 , 𝑃 ∗ ℎ ) that leads to the same bargaining result as (𝑝, 𝑃0, 𝑃ℎ), i.e., the same offered feature bundle, the same performance gain, the same net profit for the task party and the same payment on the data party, while it satisfies (𝑃∗ ℎ − 𝑃∗0 )/𝑝 ∗ = Δ𝐺 . Proof. We consider two situations regardingwhen (𝑃ℎ−𝑃0)/𝑝 ≥ Δ𝐺𝑚𝑎𝑥 and (𝑃ℎ − 𝑃0)/𝑝 < Δ𝐺𝑚𝑎𝑥 . 1) Consider the scenario where (𝑃ℎ−𝑃0)/𝑝 ≥ Δ𝐺𝑚𝑎𝑥 . According to the data party’s offer strategy, the task party obtains a feature bundle that yields a performance gain of Δ𝐺 = Δ𝐺𝑚𝑎𝑥 . Consequently, the payment accrued by the data party becomes
𝑅𝑑 = 𝑃0 + 𝑝Δ𝐺𝑚𝑎𝑥 , while the task party’s net profit is given by
𝑅𝑡 = 𝑢Δ𝐺𝑚𝑎𝑥 − 𝑃0 − 𝑝Δ𝐺𝑚𝑎𝑥 . For this performance gain Δ𝐺𝑚𝑎𝑥 to be offered, the quoted price must satisfy the following criteria 1) 𝑝 ≥ 𝑝𝑙,𝑚𝑎𝑥 and 𝑃0 ≥ 𝑃𝑙,𝑚𝑎𝑥 , where (𝑝𝑙,𝑚𝑎𝑥 , 𝑃𝑙,𝑚𝑎𝑥 ) is the reserved price of the feature bundle that generates Δ𝐺𝑚𝑎𝑥 , 2) and (𝑃ℎ − 𝑃0)/𝑝 ≥ Δ𝐺𝑚𝑎𝑥 . Given these conditions, there exists a quoted price (𝑝∗, 𝑃∗0 , 𝑃 ∗ ℎ ), where
𝑝∗ = 𝑝, 𝑃∗0 = 𝑃0, 𝑃 ∗ ℎ = 𝑝Δ𝐺𝑚𝑎𝑥 + 𝑃0 ≤ 𝑃ℎ,
based on which the data party will provide the same feature bundle with the associated performance gain Δ𝐺𝑚𝑎𝑥 . The payment to the data party remains 𝑅𝑑 , i.e.,
𝑅∗ 𝑑 = 𝑃∗0 + 𝑝 ∗Δ𝐺𝑚𝑎𝑥 = 𝑃0 + 𝑝Δ𝐺𝑚𝑎𝑥 = 𝑅𝑑 , and the net profit of the data party continues to be 𝑅𝑡 , i.e.,
𝑅∗𝑡 = 𝑢Δ𝐺𝑚𝑎𝑥 − (𝑃∗0 + 𝑝 ∗Δ𝐺𝑚𝑎𝑥 )
= 𝑢Δ𝐺𝑚𝑎𝑥 − (𝑃0 + 𝑝Δ𝐺𝑚𝑎𝑥 ) = 𝑅𝑡 . 2) Consider the scenario where (𝑃ℎ − 𝑃0)/𝑝 < Δ𝐺𝑚𝑎𝑥 . Similarly, according to the data party’s offer strategy, the task party obtains a feature bundle that yields a performance gain of Δ𝐺 = Δ𝐺𝑖 . Consequently, the payment accrued by the data party becomes 𝑃0 + 𝑝Δ𝐺𝑖 , while the task party’s net profit is given by 𝑢Δ𝐺𝑖 − 𝑃0 − 𝑝 ∗ Δ𝐺𝑖 . For this performance gain Δ𝐺𝑖 to be offered, the quoted price must satisfy the following criteria 1) 𝑝 ≥ 𝑝𝑙,𝑖 and 𝑃0 ≥ 𝑃𝑙,𝑖 , where (𝑝𝑙,𝑖𝑢 , 𝑃𝑙,𝑖 ) is the reserved price of the feature
bundle that generates Δ𝐺𝑖 , 2) and (𝑃ℎ − 𝑃0)/𝑝 − Δ𝐺𝑖 ≤ 𝜖1. Given these conditions, there exists a quoted price (𝑝∗, 𝑃∗0 , 𝑃 ∗ ℎ ), where 𝑝∗ = 𝑝, 𝑃∗0 = 𝑃0, 𝑃 ∗ ℎ = 𝑝Δ𝐺𝑖 + 𝑃0 ≤ 𝑃ℎ , based on which the data party will provide the same feature bundle with the associated performance gain Δ𝐺𝑖 . The payment to the data party remains 𝑅𝑑 , i.e., 𝑅∗𝑑 = 𝑃 ∗ 0 + 𝑝
∗Δ𝐺𝑖 = 𝑃0 + 𝑝Δ𝐺𝑖 = 𝑅𝑑 and the net profit of the data party continues to be 𝑅∗𝑡 = 𝑢Δ𝐺𝑖 − (𝑃∗0 + 𝑝
∗Δ𝐺𝑖 ) = 𝑢Δ𝐺𝑖 − 𝑃0 − 𝑝Δ𝐺𝑖 = 𝑅𝑡 . □
Lemma 3.1. Under the condition of perfect information, presenting a quoted price (𝑝∗, 𝑃∗0 , 𝑃 ∗ ℎ ) such that (𝑃∗ ℎ − 𝑃∗0 )/𝑝
∗ = Δ𝐺 is a weakly dominant strategy for the task party to attain a performance gain of Δ𝐺 , where Δ𝐺 represents the performance improvement obtained by the task party in the current round. Proof. Let us assume that in order to achieve the current performance gain Δ𝐺 , there exists a set of quoted prices that the task party can offer, denoted as {(𝑝1, 𝑃10 , 𝑃 1 ℎ ), (𝑝2, 𝑃20 , 𝑃 2 ℎ ), ..., (𝑝𝑘 , 𝑃𝑘0 , 𝑃 𝑘 ℎ )}. Denote the corresponding net profits as {𝑅1𝑡 , 𝑅2𝑡 , ..., 𝑅𝑘𝑡 }. Among these, we identify the quoted price that yields the highest net profit as
(𝑝, 𝑃0, 𝑃ℎ) = max (𝑝𝑖 ,𝑃𝑖0,𝑃𝑖ℎ ),𝑖∈𝐾 𝑅𝑖𝑡 . According to Theorem 3.1, there exists a quoted price (𝑝∗, 𝑃∗0 , 𝑃 ∗ ℎ ), where 𝑝∗ = 𝑝 , 𝑃∗0 = 𝑃0, and 𝑃 ∗ ℎ = 𝑃0 + 𝑝Δ𝐺 that satisfies (𝑃∗ℎ − 𝑃∗0 )/𝑝 ∗ = Δ𝐺 , while also yielding net profit 𝑅𝑖𝑡 . This implies that (𝑝∗, 𝑃∗0 , 𝑃 ∗ ℎ ) weakly dominates other quoted prices within the set {(𝑝1, 𝑃10 , 𝑃 1 ℎ ), (𝑝2, 𝑃20 , 𝑃 2 ℎ ), · · · , (𝑝𝑘 , 𝑃𝑘0 , 𝑃 𝑘 ℎ )}. □
Utilizing Theorem 3.1 and Lemma 3.1, we can establish the existence of an equilibrium price in conditions of perfect performance information, which adheres to the criterion
𝑃ℎ − 𝑃0 𝑝 = Δ𝐺. (5)
This price demonstrates weak dominance over the income of both the task and data party. Therefore, a reasonable strategy for the task party is that it initially targets a specific performance gain value, and the bargaining process commences with an initial quoted price (𝑝, 𝑃0, 𝑃ℎ) that satisfies Equation 5. Should the transaction proceed without failure but yield a feature bundle with a performance gain below Δ𝐺 , the task party incrementally adjusts the price, as it indicates that the target feature bundle’s reserved price is higher than the current (𝑝, 𝑃0). Another quoted price should be offered, ensuring compliance with the prescribed constraints while maximizing the net profit of the task party among the rest of the candidate price offers. The process repeats until a feature offer is presented that best matches the price offer, i.e., reaching the condition where Equation 5 is satisfied. Given the task party leads the bargaining, the payment received by the data party is bound by both 𝑃ℎ and the task party’s target performance gain, Δ𝐺 , but it can also be maximized under such a quoted price, for which we refer to as the equilibrium price, as it leads to an outcome that both parties accept the bargaining. 3.4.3 Perfect Performance Information: Termination Conditions. Based on the above analysis, we design the following termination conditions to facilitate the reaching of the equilibrium price. Denote the quoted price offered by the task party as (𝑝, 𝑃0, 𝑃ℎ), the feature bundle selected by the data party as described in 3.4.1 as 𝐹𝑖 , the corresponding performance gain as Δ𝐺𝑖 , and after a round of bargaining, the performance gain produces by the task party as Δ𝐺 . The bargaining can be divided into the following cases. On the side of the data party, during Step 2,
• Case 1: If there is no feature bundle 𝐹𝑖 in F that satisfies 𝑝𝑙,𝑖 ≤ 𝑝 and 𝑃𝑙,𝑖 ≤ 𝑃0, the bargaining terminates by the data party with the transaction fails. • Case 2: If the selected 𝐹𝑖 satisfies 𝑝𝑙,𝑖 ≤ 𝑝 and 𝑃𝑙,𝑖 ≤ 𝑃0, and (𝑃ℎ − 𝑃0)/𝑝 − Δ𝐺𝑖 ≤ 𝜖𝑑 , the bargaining terminates by the data party with transaction successes and 𝐹𝑖 offered. • Case 3: If the selected 𝐹𝑖 satisfies 𝑝𝑙,𝑖 ≤ 𝑝 and 𝑃𝑙,𝑖 ≤ 𝑃0, while (𝑃ℎ − 𝑃0)/𝑝 − Δ𝐺𝑖 > 𝜖𝑑 , the bargaining proceeds with 𝐹𝑖 offered. On the side of the task party, during Step 1,
• Case 4: If the received Δ𝐺 satisfies Δ𝐺 < 𝑃0/(𝑢 − 𝑝), the bargaining terminates by the task party with transaction fails. • Case 5: If the received Δ𝐺 satisfies Δ𝐺 ≥ (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡 , the bargaining terminates by the task partywith transaction successes and the task party makes payments. • Case 6: If the received Δ𝐺 satisfies 𝑃0/(𝑢 − 𝑝) ≤ Δ𝐺 < (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡 , the bargaining proceeds with the task party generates a new price offer. In Case 3, by offering a feature bundle closest to (𝑃ℎ − 𝑃0)/𝑝 to proceed the bargaining, the data party can maximize its payment if the task party accepts the bundle due to payment is monotonic to Δ𝐺 . The existence of Case 4 eliminates the change of the data party deliberately offering less optimal bundles and waits for a higher quoted price of the task party. The bargaining process under perfect information setting is illustrated in Algorithm 1. 3.4.4 Perfect Performance Information: Bargaining Cost. Note that cost exists in the proposed bargaining model: the third party can charge for query fees when the two players request model performance information; the VFL-related communication and training cost accumulates as the bargaining round continues. Therefore, it is necessary to take into account bargaining costs when discussing bargaining results. We use a cost function to describe the bargaining cost on each party, denoted as𝐶𝑡 (𝑇 ) and𝐶𝑑 (𝑇 ), where𝐶𝑡 (·) is the cost function on the task party, and 𝐶𝑑 (·) is the cost function on the data party, which are of the bargaining round 𝑇 . We assume that the bargaining cost takes effect on the final revenue received by the corresponding party and can be formulated in an additive manner. More specifically, for the task party, the final revenue it receives can be expressed as:
𝑅𝑡 (𝑇 ) = 𝑢Δ𝐺 −min{max{𝑃0, 𝑃0 + 𝑝Δ𝐺}, 𝑃ℎ} −𝐶𝑡 (𝑇 ) . While for the data party, it is:
𝑅𝑑 (𝑇 ) = min{max{𝑃0, 𝑃0 + 𝑝Δ𝐺}, 𝑃ℎ} −𝐶𝑑 (𝑇 ). Algorithm 1 Perfect Performance Information Bargaining
Require: The feature bundle under sale of the data party: F ; The performance gain of 𝐹𝑖 ∈ F : {Δ𝐺𝑖 }
1: /*On the side of the task party*/ 2: Initialize: The task party targets a performance gain Δ𝐺∗;
Initialize a base quoted price (𝑝0, 𝑃00 , 𝑃 0 ℎ ) that satisfies (𝑃0 ℎ − 𝑃00 )/𝑝 = Δ𝐺 ∗, where 𝑝0 ≤ 𝑢 and 𝑃0 ℎ ≤ 𝐵; 𝑢 is the utility rate of
the task party; 𝐵 is the budget of the task party 3: while True do 4: /*On the side of both parties*/ 5: Initialize base model parameters on the task party and the data party 6: /*On the side of the task party*/ 7: if is the first round of bargaining then 8: (𝑝, 𝑃0, 𝑃ℎ) ← (𝑝0, 𝑃00 , 𝑃 0 ℎ )
9: else 10: Δ𝐺 ← conduct VFL with data party on the feature bundle 𝐹 11: if Case 4 in Section 3.4.3 then 12: return Transaction fails 13: else if Case 5 in Section 3.4.3 then 14: return Transaction successes 15: else 16: Sample a finite set of quoted prices 𝑃 =
{(𝑝𝑖 , 𝑃𝑖0, 𝑃 𝑖 ℎ )}, where 𝑝𝑖 ∈ (𝑝0, 𝑢], 𝑃𝑖 ℎ ∈ (𝑃0 ℎ , 𝐵], 𝑃𝑖0 = 𝑃 𝑖 ℎ − 𝑝𝑖Δ𝐺∗, and 𝑃 𝑗0 ≥ 𝑃 0 0
17: (𝑝, 𝑃0, 𝑃ℎ) ← (𝑝 𝑗 , 𝑃 𝑗 0 , 𝑃 𝑗 ℎ ) = minp𝑗 ∈𝑃 𝑃 𝑗 ℎ 18: /*On the side of the data party*/ 19: F ′ ← Filter out feature bundles in F with reserved price higher than (𝑝, 𝑃0) 20: if Case 1 in Section 3.4.3 then 21: return Transaction fails 22: else 23: 𝐹 ← min𝐹𝑖 ∈F (𝑃ℎ − 𝑃0)/𝑝 − Δ𝐺𝑖 while (𝑃ℎ − 𝑃0)/𝑝 − Δ𝐺𝑖 > 0 24: if Case 2 in Section 3.4.3 then 25: return Transaction successes
In a bargaining model with the above-defined costs, Theorem 3.1 and Lemma 3.1 still hold. This is because the cost revenue is independent of the bargaining result but only a function of the number of rounds. Therefore, the task party and the data party continue seeking tomaximize the obtained revenue during a specific round of bargaining. However, as the bargaining cost monotonically increases to bargaining rounds, late-reached agreements can lead to the situation that the increased revenue does not cover the increased cost of bargaining, which makes the continuation of bargaining not necessary. In this case, the player would tend to reach the optimal solution as early as possible and terminate the negotiation when it is not worth continuing. Denote the current bargaining round as𝑇 , and the current quoted price as (𝑝, 𝑃0, 𝑃ℎ). On the data party, denote that the performance gain of feature bundle 𝐹𝑖 as Δ𝐺𝑖 . Suppose after selecting, the feature bundle offered by the data party gives performance gain Δ𝐺 , while the feature bundle that gives performance gain (𝑃ℎ − 𝑃0)/𝑝 is 𝐹 𝑗 ,
i.e., Δ𝐺 𝑗 = (𝑃ℎ − 𝑃0)/𝑝 . We consider that the task party would accept the current offer instead of proceeding the bargaining if
𝑃0 + 𝑝Δ𝐺𝑖 −𝐶𝑑 (𝑇 ) ≥ max{𝑃0,𝑙 , 𝑃0} +max{𝑝𝑙 , 𝑝}Δ𝐺 𝑗 −𝐶𝑑 (𝑇 + 1) − 𝜖𝑑,𝑐 ,
(6)
where the left-hand-side (LHS) denotes the net revenue the data party can receive in the current round. As for the right-hand-side (RHS), max{𝑃0,𝑙 , 𝑃0} +max{𝑝𝑙 , 𝑝}Δ𝐺 𝑗 denotes the lowest payment the data party can receive in the next round if it offers the feature bundle 𝐹𝑖 . Equation 6 indicates that the data party should accept the current quoted price if a conservative estimation of the net revenue next round under is lower than the net revenue of the current round under tolerance 𝜖𝑑,𝑐 . On the task party, denote the performance gain of the current round as Δ𝐺 . We consider it would accept the current offer instead of proceeding the bargaining if
𝑢Δ𝐺 − (𝑃0 + 𝑝Δ𝐺) −𝐶𝑡 (𝑇 ) ≥
𝑢 𝑃ℎ − 𝑃0
𝑝 − 𝑃ℎ −𝐶𝑡 (𝑇 + 1) − 𝜖𝑡,𝑐 ,
(7)
where the LHS denotes the net profit of the current round. The RHS denotes the upper bound of revenue the task party can receive in the next round of bargaining. This can be derived from 1) as (𝑃ℎ − 𝑃0)/𝑝 is the target performance gain of the task party, we have (𝑃ℎ − 𝑃0)/𝑝 ≥ Δ𝐺 ; 2) since the quoted price of the next round should have a higher highest payment 𝑃 ′
ℎ to bargain for a
higher Δ𝐺 , we have 𝑃ℎ ≤ 𝑃 ′ℎ ; and 3) 𝐶𝑡 (𝑇 + 1) > 𝐶𝑡 (𝑇 ). 𝜖𝑡,𝑐 is a hyper-parameter controlling the tolerance of the gap. Equation 7 suggests that if the net profit of the current round is greater than the highest payment the task party could receive in the next round under tolerance 𝜖𝑡,𝑐 , it should accept the feature bundle. Based on the above two formulations, we can modify the termination condition with bargaining cost For the data party,
• Case 3 (with bargaining cost). If the select 𝐹𝑖 in F satisfies 𝑝𝑙,𝑖 ≤ 𝑝 and 𝑃𝑙,𝑖 ≤ 𝑃0, while (𝑃ℎ − 𝑃0)/𝑝 − Δ𝐺𝑖 > 𝜖𝑑 : 1) if Equation 6 holds, the bargaining terminates by the task party with transaction successes; 2) else, the bargaining proceeds with the data party offering the feature bundle. And for the task party, • Case 6 (with bargaining cost). If the received Δ𝐺 satisfies
𝑃0/(𝑢 − 𝑝) ≥ Δ𝐺 < (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡 : 1) if Equation 7 holds, the bargaining terminates by the task party with transaction successes; 2) else, the bargaining proceeds with the task party generates a new feature offer. The modified two cases take into account that the bargaining processes with cost. We further propose that the two cases can be considered as a generalization of transaction success condition in Case 2 and Case 5 of Section 3.4.3. Proposition 3.1. When the bargaining cost is a constant value, Equation 6 is a reformulation of (𝑃ℎ − 𝑃0)/𝑝 − Δ𝐺𝑖 > 𝜖𝑑 in Case 3 of Section 3.4.3. Proof. When the bargaining cost is constant, Equation 6 can be re-written as
𝑃0 + 𝑝Δ𝐺𝑖 ≥ max{𝑃0,𝑙 , 𝑃0} +max{𝑝𝑙 , 𝑝}Δ𝐺 𝑗 − 𝜖𝑑,𝑐 . For the RHS of the above formulation, we have
𝑅𝐻𝑆 ≥ 𝑃0 + 𝑝Δ𝐺 𝑗 − 𝜖𝑑,𝑐 = 𝑃0 + 𝑝 𝑃ℎ − 𝑃0
𝑝 − 𝜖𝑑,𝑐
= 𝑃ℎ − 𝜖𝑑,𝑐 . We can then re-formulate Equation 6 as
𝑃ℎ − 𝑃0 𝑝 − Δ𝐺𝑖 ≤ 𝜖𝑑 ,
where 𝜖𝑑 = ( 𝜖𝑑,𝑐 − (max{𝑃0,𝑙 , 𝑃0} +max{𝑝𝑙 , 𝑝}
𝑃ℎ − 𝑃0 𝑝
− (𝑃ℎ)) ) /𝑝. □
Proposition 3.2. When the bargaining cost is a constant value, Equation 7 is a reformulation of Δ𝐺 ≥ (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡 in Case 4 of Section 3.4.3. Proof. When the bargaining cost is constant, Equation 7 can be re-written as
𝑢Δ𝐺 − (𝑃0 + 𝑝Δ𝐺) ≥ 𝑢 𝑃ℎ − 𝑃0
𝑝 − 𝑃ℎ − 𝜖𝑡,𝑐 . Subtract 𝑃0 from both sides and combine terms with the same factors we have
(𝑢 − 𝑝)Δ𝐺 ≥ (𝑢 − 𝑝) 𝑃ℎ − 𝑃0 𝑝 − 𝜖𝑡,𝑐 . We can reformulate the above equation as
Δ𝐺 ≥ (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡 , where 𝜖𝑡 = 𝜖𝑡,𝑐/(𝑢 − 𝑝). □ 3.5 extending to imperfect performance information We then extend the bargaining to imperfect performance information setting, where the performance gain of a feature bundle is not known in advance to both parties due to possible reasons. In this situation, the bargaining offers should be made in an estimation fashion. 3.5.1 Performance Estimation. We suppose that there is an estimation function for each party. For the data party, we denote the estimation function as 𝑔, which takes feature bundles as input and predicts performance gain as output. Mathematically, the optimal parameters of the estimation function can be expressed as:
𝜃∗𝑔 = min 𝜃𝑔 L(𝑔(𝐹 ;𝜃𝑔),Δ𝐺), (8)
where 𝜃𝑔 is the model parameter of 𝑔, L evaluates the loss on the training instances, and Δ𝐺 is the groundtruth performance gain. While for the task party, we propose to estimate the performance gain of quoted price instead since feature bundle related information is preserved by the data party. Denote the performance estimation function as 𝑓 , it uses quoted price as input and predicts performance gain, meaning that the task party learns about how much performance gain it would obtain by offering a certain price. The objective of the network can be formulated as follows,
𝜃∗ 𝑓 = min
𝜃 𝑓 L(𝑓 (𝑝, 𝑃0, 𝑃ℎ ;𝜃 𝑓 ),Δ𝐺), (9)
where 𝜃 𝑓 is the model parameter of 𝑓 . Taking 𝑓 and 𝑔 as a whole, the learning process can be described as finding optimal < (𝑝, 𝑃0, 𝑃ℎ),Δ𝐺 > matching between the two parties, which is inconsistent with the perfect performance information setting. Accurate performance estimation is crucial for both the task and the data parties in such a situation, as it directly influences the net profit maximization of the task party and the monetary payoff optimization of the data party. However, the training of such a function faces several challenges. First, training while bargaining. The obtaining of 𝜃∗𝑔 and 𝜃∗𝑓 requires a set of ((𝑝, 𝑃0, 𝑃ℎ), 𝐹 , Δ𝐺) samples, which do not exist until VFL is performed between the two parties, while VFL courses only happen when bargaining happens between the two parties. It is important to simultaneously achieve both effective bargaining and effective training. Second, simultaneous update. Once a task party and a data party are paired for VFL, they both need to train their estimation functions so as to fit the current partner. Such a simultaneous training can introduce dynamics and may lead to convergence problems if there is no mutual understanding shared. To solve these problems, we propose the following offer-generating strategies on the side of the data party and the task party. 3.5.2 imperfect performance information: bargaining analysis on The Data Party. Similar to the perfect performance information setting, the task party’s feature bundle offer should be made based on the given quoted price received from the task party. Denoted as (𝑝, 𝑃0, 𝑃ℎ), the maximum revenue that could be received by the data party is 𝑃ℎ . The data party’s goal is to identify a feature bundle whose predicted performance gain is as close as possible to, but does not exceed, the quantity (𝑃ℎ−𝑃0)/𝑝 . Similar to the setting of perfect performance information, this ensures that the selected bundle generates a performance gain that maximizes the payment within the price range of (𝑃0, 𝑃ℎ). However, in the imperfect performance information setting, the data party does not know which feature bundle satisfies such a condition. Its bargaining strategy should thus be made based on estimation. The data party first filters out feature bundles that have higher reserved prices than the given (𝑝, 𝑃0). Then, for the rest of the bundles, it makes predictions on the performance gain of each bundle based on 𝑔. With the estimated performance, the data party selects the feature bundle that is expected to have the closest performance gain to (𝑃ℎ −𝑃0)/𝑝 as the bargaining offer. The estimation function is updated after VFL is performed between the two parties and the real performance gain is calculated. 3.5.3 imperfect performance information: bargaining analysis on The Task Party. For the task party, we propose the following bargaining strategy. Initially, the task party targets certain performance gain and generates a large enough set of quoted prices that conform to the constraints outlined in Equation 5, while taking into account the budget and the utility rate, similar to in the perfect performance information setting. Subsequently, it employs 𝑔 to predict the performance gain associated with each sampled price in the set. When making a bargaining offer, the task party filters out prices whose predicted performance gain is no greater than or equal to (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡
and selects the one with the highest net profit to offer. If the filtered set is empty, it selects the one with the highest net profit. It’s noteworthy that the task party’s estimation function specifically considers quoted prices that conform to the constraints outlined in Equation 5. Consequently, it focuses the attention on prices that are consistent with the equilibrium price specified in Theorem 3.1 and Lemma 3.1 when updating the performance estimation function. After the feature bundle offer is selected from the data party, the two parties perform VFL, and the obtained real performance gain is used to update the performance estimation function 𝑔. 3.5.4 imperfect performance information: termination conditions. We denote the data party’s estimated performance gain of feature bundle 𝐹𝑖 as 𝑔(𝐹𝑖 ), the quoted price offered by the task party as (𝑝, 𝑃0, 𝑃ℎ), and the estimated performance gain as 𝑓 (𝑝, 𝑃0, 𝑃ℎ), and the real performance gain received by the task party as Δ𝐺 . The bargaining under imperfect information condition can be divided into the following cases. On the side of the data party, • Case I: If there is no feature bundle 𝐹𝑖 in F that satisfies
𝑝𝑙,𝑖 ≤ 𝑝 and 𝑃𝑙,𝑖 ≤ 𝑃0, the bargaining terminates by the data party with the transaction fails, unless Case VII is met. • Case II: If the selected 𝐹𝑖 satisfies 𝑝𝑙,𝑖 ≤ 𝑝 and 𝑃𝑙,𝑖 ≤ 𝑃0, and 1) (𝑃ℎ−𝑃0)/𝑝−𝑔(𝐹𝑖 ) ≤ 𝜖𝑑 , or 2) (𝑃ℎ−𝑃0)/𝑝 > max {𝑔(𝐹𝑖 )}, or 3) (𝑃ℎ − 𝑃0)/𝑝 < min {𝑔(𝐹𝑖 )}, the bargaining terminates by the data party with transaction successes and 1) 𝐹𝑖 , or 2) 𝐹𝑚𝑎𝑥 , or 3) 𝐹𝑚𝑖𝑛 offered, unless Case VII is met. • Case III: If the selected 𝐹𝑖 satisfies 𝑝𝑙,𝑖 ≤ 𝑝 and 𝑃𝑙,𝑖 ≤ 𝑃0, while Case II is not met, the bargaining proceeds with 𝐹𝑖 offered. On the side of the task party, • Case IV: If the received Δ𝐺 satisfies Δ𝐺 < 𝑃0/(𝑢 − 𝑝), the
bargaining terminates by the task partywith the transaction fails, unless Case VII is met. • Case V: If the received Δ𝐺 satisfies Δ𝐺 ≥ (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡 , the bargaining terminates by the task partywith transaction successes, unless Case VII is met. • Case VI: If the received Δ𝐺 satisfies 𝑃0/(𝑢 − 𝑝) ≤ Δ𝐺 < (𝑃ℎ − 𝑃0)/𝑝 − 𝜖𝑡 , the bargaining proceeds with the task party generates a new price offer. On the side of both parties, • Case VII: If the bargaining is within the initial 𝑁 rounds,
the bargaining proceeds with the data party operates on Case III, and the task party operates on Case VI. The key difference between the termination condition of imperfect and perfect performance information settings includes 1) the action taken by the data party is based on estimated performance gain; 2) the transaction failing conditions, i.e., Case 1 and Case 3 in Section 3.4.3, are relaxed in the first 𝑁 rounds of bargaining due to the estimation functions of the two parties are not well trained. Note that for the task party, the performance gain estimation function takes effect on price offer generating stage, while the termination conditions are based on the calculated real performance gain after receiving feature bundle and performing VFL. Moreover, despite in the setting of imperfect performance information, the task party lacks prior knowledge of the potential
range of performance gains that could be offered by the data party, the practice of targeting a specific performance gain, as done in the case of perfect performance information, becomes still doable by introducing Case II. 3.6 security analysis In federated learning, there is a risk of malicious participants trying to manipulate the model or extract information from the training process. This risk is especially of concern in the context of VFL as it often requires direct communication between two parties without a server [8]. Consequently, defenses and attacks are widely studied in the literature [15–18]. We here analyze possible threat models of the VFL market from two perspectives: 1) VFL training and inference and 2) the bargaining. FL Training and Inference. The proposed VFL market is FL protocol-agnostic since it only takes the output (performance gain) of a VFL course as intermediate information for subsequent bargaining but does not affect and is not affected by the specific training protocol of VFL. This makes it adaptable to any security-related VFL training protocols and does not introduce a new threat model during the training and inference phase. Bargaining. As performance gain is exchanged between the two parties, a party can access this information and conduct possible inference attacks on the other party’s data. To eliminate this risk, encryption methods such as Homomorphic Encryption (HE) [19] and Secure Multi-party Computation (SMC) [20] can be adopted for multiplication or comparing related operations. As the detailed design of security-preserving approaches is out of the scope of the paper, we omit it here. 4 experiment  4.1 experiment setup All experiments are implemented on 2 Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz and 8 NVIDIA A100. 4.1.1 Datasets and Metrics. We evaluate the proposed bargaining model on three real-world tabular datasets. Titanic 2: The Titanic dataset contains information about passengers aboard the RMS Titanic, including 11 features such as age, sex, passenger class, and ticket fare. The dataset is commonly used for binary classification tasks, predicting whether a passenger survived or not based on the provided features. Credit 3: The dataset contains credit card client data from Taiwan between April 2005 and September 2005. It includes 25 variables such as ID, credit limit, gender, education, marital status, age, repayment status, bill statement amounts, and previous payment
2https://www.kaggle.com/competitions/titanic/data 3https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset
amounts. The prediction task is to classify if a client will default on his/her payment in the next month. Adult 4: The Adult dataset, aka. the “Census Income" dataset, contains demographic and income-related information about individuals. It includes 14 features such as age, education level, marital status, and occupation. The goal is to predict whether an individual earns more than $50,000 per year. We convert the multi-class categorical features in the original datasets into indicator features and then split the features into taskparty-owned and data-party-owned. Note that indicator features of the same original feature are on the same party. A summarization of the original and preprocessed datasets is listed in Table 2. For the three datasets, we calculate Accuracy as the performance of the base model. 4.1.2 Implementation Details. For the VFL-based prediction task, we evaluate two types of base model implementations: tree-based and deep neural network (DNN) based models. For the tree-based models, we consider the two parties together training a Random Forest model, with gini index as the splitting metric. For the DNNbased model, we consider the two parties collaboratively training a 3-layer multi-layer perception (MLP), with embedding dimensions
4https://archive.ics.uci.edu/dataset/2/adult
64 and 32. For the 3-layer MLP, the learning rate is set as 1e-2, and the batch size is set as 128 for the Titanic dataset, and 512 for the Credit dataset and the Adult dataset. In the isolated training of the task party, we set the number of epochs as 200, which ensures convergence. The maximum number of bargaining rounds is set as 500, and the bargaining is considered as terminated with transaction fails if it exceeds the threshold. Other key parameters regarding bargaining are empirically studied in subsequent sections. 4.2 main results In order to study the effectiveness of the proposed bargainingmodel, we conduct experiments by comparing with two non-strategic variants of the model, named Increase Price and Random Bundle. In Increase Price, the task party does not follow the criterion in Equation 5 but arbitrarily increases the quoted price in each round. In Random Bundle, the data party filters out feature bundles that have a higher reserved price than the quoted price, and then arbitrarily offers one feature bundle to the task party. We set the initial status, i.e., the initial quoted price and target Δ𝐺 on the task party side, as the same for the three models and run the bargaining 100 times. The results of mean and 95% confidence interval of net profit received by the task party, revenue reward received by the data party (aka. the payment made by the task party, denoted as Payment in the
figures), and the Δ𝐺 over bargaining rounds are depicted in the left three columns of Figure 2 and Figure 3, in which Figure 2 the base model for VFL is Random Forest and that in Figure 3 is 3-layer MLP. In the right two columns of Figure 2 and Figure 3, we present the density functions that describe the distribution of the final quoted prices when the bargaining terminates compared with the reserved price of the data party. The proposed bargaining model is denoted as Strategic. The left three columns of the figures show that the proposed model outperforms the non-strategic variants in terms of net profit received by the task party and realized Δ𝐺 , while the reward received by the task party is comparable or reasonable lower than the Increase Price, indicating that the model is more effective in achieving a win-win outcome for both parties. It is worth mentioning that the two parties reach agreements faster under the proposed approach compared with the Increase Price method, with a more robust trend, which suggests that targeting the turning point of the payment and net profit function is an effective strategy for reaching equilibrium. Moreover, the Random Bundle method performs poorly in almost all cases, with early terminations that result from unsuccessful transactions. This is due to the fact that feature bundles with low performance gain can be offered by the task party, in which case the task party terminates the bargaining for the violation of Case 4 in Section 3.4.3. From the right two columns of the figures, we can observe that the proposed model achieves a better alignment between the final quoted prices and the reserved price of the data party, indicating that the proposed model is more effective in achieving an outcome that is acceptable by both parties. While for Increase Price, as there is no constraint on the price offer, there are cases that the task party over-pays a feature bundle, i.e., higher than the reserved price of the data party. 4.3 effect of bargaining cost In this section, we study how the bargaining cost affects the results of the proposed approach.We are interested in two situations: when the cost is linear to the bargaining rounds andwhen it is exponential to the bargaining rounds, i.e.,𝐶 (𝑇 ) = 𝑎𝑇 and 2)𝐶 (𝑇 ) = 𝑎𝑇 . We vary the cost factor 𝑎 and termination condition related hyper-parameter 𝜖 in Section 3.4.3 to further analyze the effect of bargaining cost. For simplicity, we set 10 ∗ 𝐶𝑡 (𝑇 ) = 10 ∗ 𝐶𝑑 (𝑇 ) = 𝐶 (𝑇 ) for the Credit and Adult dataset. We use 𝜖𝑑 = 𝜖𝑡 = 𝜖 for both datasets. We employ different 𝜖 on different datasets, the one underlined is set as the default value. We run the bargaining 100 times and report the mean and standard deviation of the net profit, payment, and cost of the final bargaining state. Note that the net profit and payment are calculated as the revenue before minus cost. The results under Random Forest base model are illustrated in Table 3, and those of the original perfect performance information setting are also
included for comparison. The initial states of the current evaluation are the same for all runs. Table 3 shows that when cost is introduced to the bargaining model, the net profit, payment, and realized Δ𝐺 are all generally smaller compared to the No Cost version, which indicates the two parties tend to reach a less optimal equilibrium. Such a trend is more significant when the cost increases faster (i.e., larger 𝑎), which makes long-term negotiation less tolerable. 𝜖 also plays an important role in determining the final state of bargaining. It can be observed that a smaller 𝜖 generally leads to higher revenue for both parties, as it indicates the final realized Δ𝐺 is closer to the target one. However, this also leads to higher bargaining costs, which might offset the advantage of increased revenue. Therefore, as a player, it is important to consider the trade-off between bargaining efficiency and better equilibrium during decision making in the feature bargaining. 4.4 imperfect performance information bargaining analysis In this section, we conduct experiments under imperfect performance information setting. For the task party, a 3-layer MLP with embedding dimensions 64, 32, 16 are used for the estimation of Δ𝐺 . For the data party, we first embed each singular feature with the nn.Embedding layer 5 in PyTorch and then take the average of each feature variable’s embedding as the representation of the whole feature bundle, which is then used as input of the performance gain estimation network. The estimation network on the task party follows the same structure as the task party. We set the initial 100
5https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html
rounds as the exploration rounds of bargaining, i.e.,𝑁 = 100, during which the bargaining will not fail under any cases. 4.4.1 Comparison with Bargaining with Perfect Performance Information. To evaluate if the bargaining under imperfect performance information is effective, we compare the bargaining-related final and intermediate variables with the perfect performance information setting and obtain the results in Table 4. Δ𝑝 and Δ𝑃0 denote the difference value of 𝑝 − 𝑝𝑙 and 𝑃0 − 𝑃𝑙 , where 𝑝𝑙 and 𝑃𝑙 are the reserved prices of the task party’s target feature bundle. For the bargaining termination conditions, we set 𝜖𝑑 = 𝜖𝑡 = 5𝑒 − 2 on the Titanic dataset, 1𝑒 − 3 on the Credit dataset and 5𝑒 − 3 on the Adult
dataset. Due to limited space, we only report the results on Credit and Adult dataset. The initial state of the bargaining is set as the same for the two settings. We run the bargaining 100 times and report the mean and std values. We record that the corresponding values are negative infinitely small if the bargaining terminates with the transaction fails. We can conclude from the table that the bargaining model under imperfect performance information is effective and comparable to the perfect performance information setting in most cases, as the final Δ𝐺 , net profit and payment are usually of reasonable magnitudes. Moreover, the std values demonstrate that the variability in the results is also relatively low with no infinitely large values, indicating that the bargaining process is consistent and stable across multiple runs, even under imperfect performance information. This highlights the robustness of the bargaining model and its potential applicability in real-world scenarios where perfect information may not always be available. 4.4.2 Δ𝐺 Estimation Convergence. It can be found in Figure 4 that the convergence of the estimation networks on both parties over the course of the bargaining rounds. The estimation networks converge quickly within the first 20-30 rounds, and the accuracy of the estimation improves gradually with more rounds of bargaining. At
around 100, the estimation is precious enough to conduct the true bargaining, which verifies the effectiveness of the estimation while bargaining approach. 5 relatedwork Federated Learning. FL approaches ensure data privacy as raw data never leaves its original location. According how data is partitioned in the sample and feature space , FL can be broadly classified into three main categories: horizontal federated learning (HFL) [21–23], vertical federated learning (VFL) [8, 24, 25], and Federated Transfer Learning (FTL) [26]. HFL allows collaborative training on clients with different data samples but the same features space. VFL enables training of clients’ datasets sharing the same samples while holding different features. FTL deals with the scenario where clients’ datasets differ in both sample and feature space. Besides importing FL models’ effectiveness and efficiency, the commercialization of FL has attracted increasing attention. Most current works focus on evaluating the contribution of participants [27–29] or proposing incentive mechanism to facilitate participation of data owners [30–32], while the model/data trading and pricing in FL has only limited studied [33]. Data Pricing and Valuation. There is a growing amount of literature on data valuation, data trading, and pricing mechanisms in data markets, particularly in the context of digital products and services [10, 34, 35]. Researchers have proposed various approaches to determine the value of data, such as market-based approaches, costbased approaches, and income-based approaches. Market-based approaches rely on supply and demand dynamics to determine the value of data [36–38], while cost-based approaches consider the cost of acquiring, storing, and processing data [33, 39, 40]. Incomebased approaches, on the other hand, look at the potential revenue generated from the use of data/models [41]. Our bargaining model falls into income-based approach. In terms of pricing mechanisms, subscription-based [42], and auction-based [43–46] pricing models have been proposed and used in data markets. In the VFL market, we choose to use one-one bargaining-based solution for that VFL is usually conducted between one task party and one data party and the iterative process of bargaining allows for the probability of reaching mutual-beneficial outcomes. 6 conclusions and futurework In this paper, we have identified the need for an economically efficient approach to feature trading in VFL and proposed a bargainingbased model to address this issue. Our model incorporates performance gain-based pricing and analyzes the bargaining process under perfect and imperfect performance information settings. We have demonstrated the existence of an equilibrium that optimizes the objectives of both the task party and the data party in perfect performance information setting. Additionally, we extend the result to imperfect performance information scenarios and propose performance gain estimation-based bargaining strategies. We also discuss potential security issues and solutions. Experiments on real-world datasets have verified the effectiveness of the proposed bargaining model. However, the proposed bargaining model has several limitations. 1) It does not provide protection if the participants manipulate the
goods or information when terminate the game. For example, the task party may accept a feature bundle with high performance gain but only report a lower value to reduce its payment. A possible solution for this is to involve of a trustworthy third party for evaluation. 2) The sampling-evaluation based quoted pricing choosing strategy is straightforward but not efficient and the task party can employ automatic bargaining offer strategy, such as learning based, to optimize the efficient of offer generating. Nevertheless, we maintain a positive view of the impact of this paper and hope it serves as a foundational work on FL markets and inspires future research.