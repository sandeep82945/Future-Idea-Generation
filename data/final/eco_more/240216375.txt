The demand for voluntary insurance against low-probability, high-impact risks is lower than expected. To assess the magnitude of the demand, we conduct a meta-analysis of contingent valuation studies using a dataset of experimentally elicited and survey-based estimates. We find that the average stated willingness to pay (WTP) for insurance is 87% of expected losses. We perform a meta-regression analysis to examine the heterogeneity in aggregate WTP across these studies. The meta-regression reveals that information about loss probability and probability levels positively influence relative willingness to pay, whereas respondents’ average income and age have a negative effect. Moreover, we identify cultural sub-factors, such as power distance and uncertainty avoidance, that provided additional explanations for differences in WTP across international samples. Methodological factors related to the sampling and data collection process significantly influence the stated WTP. Our results, robust to model specification and publication bias, are relevant to current debates on stated preferences for low-probability risks management. 1. introduction Low-probability, high-impact (LPHI) adverse events challenge our understanding of the interplay
between individuals’ risk perception and risk-coping behaviors (Kunreuther et al., 2013, 2021). Natural
disasters and extreme weather events, as a salient case, can have a significant cost in terms of human lives
and physical damages. These events exert substantial pressure on both individuals and society and
exacerbate existing inequalities, particularly when their impacts are unevenly distributed (Klomp and
Valckx, 2014, Botzen et al., 2020). To mitigate the economic impacts of natural disasters, policymakers
provide financial assistance and promote insurance programs as a financing mechanism to smooth individuals’ consumption against income shocks.2 Paradoxically, the demand for non-mandatory insurance
against low-probability risks is relatively low even when it is provided at prices below actuarially fair values,
(Baillon et al. 2022). Conventional models based on expected utility theory (EUT) posit that the main factor influencing the
insurance decision is the agents' attitude towards risk (Arrow, 1971). However, numerous observations
show that insurance take-up is much lower for events with low-probability and high-consequences than
for those with higher probability and lower consequences. From an EUT perspective, this evidence
therefore seems puzzling, as it calls into question the rationality hypothesis (Sydnor, 2010). Behavioral
economics experiments show that people do not always make decisions consistent with the normative
EUT benchmark, which casts doubt on the adequacy of this model to explain the low demand for LPHI
insurance. Prospect theory (PT), rank-dependent utility (RDU), and cumulative prospect theory (CPT),
formulated respectively by Kahneman and Tversky (1979), Quiggin (1982), and Tversky and Kahneman
(1992), provide the most promising alternative to the EUT model. These descriptive models incorporate
additional components of risk preferences, such as reference-dependent behavior, probability weighting,
and loss aversion. One particular facet of the demand disparity between LPHI and HPLI– the difficulty in understanding
small probabilities – has become the focus of intense investigation over the past years. Some research even
goes further, suggesting that people often confuse low-probability with zero-probability events
(Kunreuther et al. 2001). Due to the complexity of analyzing low-probability events in real-world settings
and the inherent challenges in establishing causal effects for fundamental factors, research in the past two
decades has increasingly turned towards stated preference methods and willingness to pay (WTP)
estimation. These methods offer a more flexible framework for measuring the demand curve, taking
various conditions into account, providing further evidence of the “demand puzzle” (Jaspersen, 2016;
Robinson and Botzen, 2019). Additional explanations using stated preference techniques have been proposed from the psychological
and behavioral economic literature to explain why individuals underestimate these risks (Friedl et al., 2014,
Browne et al., 2015, Fehr-Duda and Fehr, 2016). Low demand for insurance can be caused by search costs
associated with gathering information about insurance premiums, coverage, and underlying probabilities
of loss (Kunreuther and Pauly, 2004). Lack of loss experience has also been shown to be consistently
related to low insurance demand, which is perhaps driven by low perceptions of risk (Robinson and
Botzen, 2019). It has been shown that these methods of communicating risk can have a positive effect on
demand for risk reduction and can increase the sensitivity of demand to probability changes (Botzen and
Van Den Bergh, 2012). Similarly, the willingness to pay for insurance is significantly lower for correlated
than for idiosyncratic risks. Friedl et al. (2014) claim that insurance is less attractive for correlated risks, a
premise that they theoretically exposed in a model with a social reference point. Risk perception for small probability events is subject to cognitive biases and judgment-distorting
heuristics (Botzen and Bergh 2009; Gallagher 2014). A relatively recent strand of literature related to stated
2 By providing a timely post-loss financial payout, insurance is also linked to more positive psychosocial and emotional outcomes for affected people (Farrell and Greig 2018; McKnight 2019). The insurance industry may similarly support public risk management policies by promoting preventive measures and by providing relevant information to the public. Hudson et al. (2017) show that insured populations are more likely to undertake disaster preparations and preventive actions than the non-insured. preferences focuses on these behavioral frictions as local drivers of underinsurance. Pitthan and De Witte
(2021) summarize the moderating effect of these factors on the relationship between extreme risk attributes, risk perception, and insurance demand.3
Despite these non-market data methods’ effectiveness in measuring the demand curve, the literature documents, however, high variability in stated WTP.4 Experience-based studies provide relatively high
average WTP compared to expected loss, pointing to significant upward bias attributable to the data collection method (Leblois et al., 2020).5 For instance, Zimmer et al. (2018) conduct a laboratory
experiment to examine probabilistic insurance demand for low-probability risks using real rewards applied
in an incentive‐compatible framework. In the absence of default risk, the average WTP for insurance is
higher than expected losses. In framed field experiments conducted with farmers, Serfilippi et al. (2020)
analyze the micro-insurance demand to explain low take-up rates. The average WTP for a virtual insurance
contract under a standard frame also exceeds the expected loss. In the same vein, Robinson et Botzen
(2019) explore the flood insurance demand through an online experiment conducted with a sample of
Dutch homeowners. They find that individuals inclined to purchase insurance are willing to pay a
significant mark-up over expected losses. Some factors related to data collection methods and elicitation mechanisms can accentuate hypothetical
biases or strategic behavior (e.g. Balistreri et al., 2001; Harrison and Rutström, 2008, Entem et al., 2022). This variability is further exacerbated by the high degree of heterogeneity between studies conducted in
different contexts (e.g., periods, regions, risk types, insured assets, etc.). All these factors may limit the
ability to answer some relevant questions about the true elicited insurance demand for low-probability
risks, including: 1) How can all the estimated average WTP results reported in the literature be aggregated? 2) Is there publication bias in the literature? 3) How low is the stated demand for insurance? While the focus has been on local factors affecting demand at the individual level, little attention has been
paid to assessing, at the study level, the cumulative effects of risk attributes, socio-economic characteristics,
and methodological factors on the gap between expected loss and average WTP estimates. As the number
of studies on insurance demand against low portability risks is expected to keep growing in the coming
years, particularly with climate change, disentangling fundamental and measurement effects on aggregate
stated WTP estimates is highly needed. In this paper, we present a meta-analysis of contingent valuation studies focusing on low-probability risk insurance.6 The main goal of our study is to explain variations in the average stated willingness to pay
(WTP) across studies, rather than delving into the individual factors influencing the demand for insurance. Although these two objectives may initially appear similar, they hold distinct significance within our
research context. We specifically rely on available aggregated data, recognizing that factors that exert
influence at the individual level may not hold the same relevance at the aggregate level (Schmid et al.,
2020). Moreover, we introduce new meta-factors, such as data collection strategies and survey designs,
which may not directly impact individually stated WTP. 3 For instance, Kunreuther (2021) describes six cognitive biases in the context of the US flood insurance market: myopia, amnesia, optimism, inertia, simplification, and herding. Another example of behavior anomaly, to name but one, assumes a specific type of narrow framing that views insurance as an investment, underestimating its primary purpose as a way to manage risks and protect against unexpected extreme losses (Platteau et al., 2017). 4 Contingent valuation methods may suffer from several limitations attributed mainly to the hypothetical nature of the survey that tends to overestimate the true willingness to pay. For example, individuals might not be able to judge the value of the goods they have to evaluate, due to a lack of understanding; or they might have difficulty envisioning their income constraints in the proposed hypothetical setting (Diamond et al., 1994). These limitations may dramatically reduce external validity (Haghani et al., 2021). 5 Leblois et al. (2020) note a high take-up of insurance giving as examples the following studies (Petraud et al., 2015; Norton et al., 2014; Serfilippi et al., 2020). They explain such discrepancy by the presence of seasonal liquidity constraints and distrust in insurance providers. 6 Our analysis is specifically designed to study insurance-related decision-making about material losses and natural hazard damages, deliberately excluding health risks. Although health insurance is an important area of research in its own right, it is governed by distinct regulatory frameworks and involves unique risk assessment methodologies and psychological influences on decisionmaking behavior. Based on a sample of 38 primary studies (65 observations after removing outliers) experimentally elicited
and survey-based measures spanning 17 years of research, we find a meta-analytic average WTP, before
heterogeneity treatment of 87% of expected losses. WTP estimates vary considerably across observational
and experimental studies. To explore the sources of heterogeneity, we perform a meta-regression analysis
(MRA hereafter) controlling for a range of moderators and applying several estimation methods. As a
robustness check, we use the Bayesian Model Averaging approach (BMA) to account for model uncertainty and covariate selection.7
Our main finding is related to the conditions under which the willingness to pay for insurance may deviate
from trend values. Moderators such as information about loss probability provision and very small
probability levels influence positively relative WTP, whereas respondents’ socio-demographic
characteristics such as income and age have a negative effect. Laboratory-based estimates, show-up fees,
and within-subject design appear to report significantly higher values for relative WTP than other methods. We identify other interesting determinants that affect the relative WTP through different causal channels. None of the two moderators linked to this aspect (i.e. incentive-based elicitation and questions format) is
robustly significant. Our results provide no direct support for hypothetical bias traditionally associated
with contingent valuation methods. The relative WTP estimates seem to be geographically dependent, showing smaller levels in China
compared to Germany and the Netherlands. This finding is highly consistent with previous empirical
studies conducted in developing countries. To gain insight into these results and search for a possible
explanation of large differences across these countries, we explore the impact of national culture using
Hofstede’s cultural dimensions. We find that relative WTP is positively (negatively) related to “Uncertainty
avoidance” (“Power distance”) dimensions. Culture proxies thus provide statistically robust drivers of
insurance demand supporting previous results of Chui and Kwok (2008) and Park and Lemaire (2012). We perform various robustness checks to assess the sensitivity of the results to various modeling choices. Our main results are robust to alternative estimation specifications and publication bias issues. To our knowledge, this meta-analysis is the first to focus on the underinsurance issue from this angle and
extends, with a new quantitative perspective, previous surveys of literature (e.g. Jaspersen, 2016; Robinson
and Botzen, 2019; Harrison et al., 2019; Lucas, 2021). The current study provides new results on the effect
of fundamental and methodological factors on WTP. It also allows for testing the literature for potential
publication bias, a goal that cannot be achieved at the individual study level (Stanley et al., 2012). Additionally, it allows us to revisit how different cultural dimensions may have distinct conceptions of
resilience at the organizational or community level that may persistently influence insurance demand. Finally, this study contributes to examining the presence of hypothetical bias for various WTP elicitation
designs (Lusk and Schroeder, 2004; Miller et al., 2011; Schmidt and Bijmolt, 2020). The rest of the paper is structured as follows. Section 2 presents briefly the general theoretical framework
underpinning the willingness to pay for insurance. Section 3 describes the meta-dataset and discusses the
metric construction. Section 4 examines publication bias. Section 5 investigates heterogeneity and presents
the MRA results. In this section, we further check the robustness of the obtained results. The last section
concludes. 2. theoretical background As a conventional measure of the change in welfare, compensating variation is defined as the maximum amount an individual would be willing to pay (WTP) to secure a change (i.e. restore the original welfare
level) (Hanemann, 1991). For insurance contracts without deductibles or other cost-sharing limits, the
7 Our empirical analyses are performed according to meta-analysis guidelines (e.g. Havranek et al., 2020; Steel et al., 2021). willingness to pay (WTP) is implied from the following agent indifference condition between insurance
and non-insurance decisions:
1 0 1U y WTP p q Z U y p q Z− =
where U describes the agent’s indirect utility (value) function8, y represents the individual’s wealth
(income), p is a vector of costs that the individual faces, qi (with i=0, 1 and q0 <q1) reflects the safety value, and Z is a vector of personal characteristics (e.g. past loss experience, financial literacy age, gender, etc.). Parameters q0 and q1 describe different levels of the safety measure qi. Parameter q1 is associated with a measure that provides a higher level of safety compared with q0 (Entorf and Jensen, 2020). Differences in insurance demand at the individual level could be attributed to several fundamental factors,
which can be derived from various risk preference models. According to the static (EUT) framework,
WTP would equal the certainty equivalent of the expected utility over final wealth states without insurance. The difference between the fair premium and the theoretical WTP corresponds to the standard risk premium, which is a function of the risk aversion level and the probability distribution of losses.9 However,
in practice, the disparity between EUT predictions and stated WTP calls for more extra risk premiums. Baillon et al., (2022) introduce a behavioral decomposition of the gap between stated willingness to pay
(WTP) and fair insurance price inspired by the prospect theory (PT) model:
2b u wWTP     − = + +
They consider three behavioral deviations from the fair price arising from subjective beliefs b ,convex utility in the loss domain u , and probability weighting w . A residual term  is also considered to absorb
all influences on WTP that are not captured by the model. In both EUT and PT models, the loss
probability plays a major role in insurance decisions. In practice, two distinct behaviors may be observed
depending on the probability level. When people deem the probability of loss below their level of concern,
they generally neglect risk and choose not to undertake protective actions (Kunreuther and Pauly, 2004;
Kunreuther et al., 1978). In contrast, when they attribute a subjective likelihood of loss that is far higher
than the actual probability, they become highly risk-aware and seek out mitigation strategies (e.g., Brouwer
et al., 2014). Furthermore, Abito and Salant (2019) find that the provision of information on a loss
probability reduces both the subjective probability and WTP. Other models, based on the dynamic
consumption utility framework, posit that WTP primarily depends on expected losses, wealth, annual
income, market interest rates, and risk attitudes (Hansen et al., 2016). As the agent's risk preferences are
unobservable and challenging to measure objectively, it is of relevance to get insight into observable factors
that moderate risk attitude determinants and structurally impact demand. These factors can be globally
grouped into three categories: demand-side, supply-side, and extreme risk nature (Leblois et al., 2020). In line with the goal of the study, we rely solely on available aggregated data related to study-level
covariates. This is crucial given the inherent complexities in determining an agent's true WTP. Since WTP
is unobservable and there is no widely acknowledged elicitation method (Völckner, 2006), methodological
choices may influence final results. Carson et al. (2001) give some guidance in this area and outline two
important aspects of the elicitation methodology. The first consideration is whether the elicitation process
is based on price generation (i.e., an open-ended question format) or price selection tasks (i.e., a
dichotomous choice question format) (Hofstetter et al., 2021). The dichotomous choice typically
overstates WTP relative to open-ended (Balistreri et al., 2001) and payment card formats (Ready et al., 1996; Welsh and Poe, 1998).10. Incentive-compatibility conditions in the elicitation process may also
8 See Barseghyan et al. (2018) for a summary of risk preference models. 9 Under EUT, a risk-averse agent will buy full insurance if and only if the premium is fair, i.e. equal to expected losses, (Mossin, 1968). For small probability risks, the demand for full insurance at unfair premiums or less than full insurance at fair premiums contradicts the EUT (Schlesinger, 1997). 10 When asking agents directly about their WTP, they are more likely to dwell on the price or attempt to respond strategically if they believe their responses will affect future pricing (Breidert et al., 2006, Jedidi and Jagpal, 2009). Moreover, simulating real
prevent strategic behavior in the sense that the dominant strategy for respondents is to bid truthfully
(Wertenbroch and Skiera, 2002). WTP estimated in the laboratory could be subject to hypothetical bias,
strategic behaviors, or social desirability bias pushing respondents to overstate their WTP to be more
socially acceptable (Lusk and Norwood, 2009; Carlsson et al., 2010; Paulhus, 1991). Leggett et al. (2003)
show that WTP values derived from face-to-face interviews could be as much as 23%–29% higher relative
to self-administered surveys. We discuss additional moderating variables, which are detailed in section 5. 3. The Meta Dataset
3.1 Search Strategy and Inclusion Criteria
The first stage in the meta-analysis method consists of selecting the primary studies. To this end, we follow the reporting guidelines and the PRISMA statement outlined in Havranek et al. (2020). We search for empirical studies published in the Web of Science and Google Scholar databases using a combination of the following keywords: “Insurance”, “willingness to pay”, “low probability”, “contingent valuation”, “climate risk” and “natural disasters” over the period from 2005 to 2021.11 We also reviewed the bibliographies of the retrieved papers for more empirical research. Data searches were performed on Harzing's Publish and Perish software to collect primary documents information. To determine which primary studies to include, a list of selection criteria is established. These criteria are necessary to ensure that the final dataset contains studies with a reasonable degree of heterogeneity while still allowing for meaningful comparison. The details of PRISMA steps and results are provided in Figure 1. The identification stage included 15,664 articles identified by the database search (see Appendix B).12 We remove duplicates and screen articles based on title (1,057 articles). Four main exclusion criteria were applied during the selection phase:
(i) Risk Type: We specifically focused on the nature of risk associated with material losses and damages stemming from idiosyncratic or natural hazards. We exclude studies that primarily dealt with health or life risks, highlighting our dataset on material and financial impacts. (ii) Loss Probability Threshold: We established a loss probability threshold for inclusion in the study. Specifically, we only included instances where the loss probability was stated was 5% or less. (iii) Valuation Methodology: We include studies that use contingent valuation-based empirical research for the determination of willingness to pay (WTP). Studies deriving WTP from theoretical modeling or discrete choice experiments were not considered, as our methodology required direct empirical valuation.13
(iv) Protection Mechanism: Our focus was on studies that exclusively considered insurance as a protection mechanism against losses. Consequently, we excluded studies that evaluated other forms of financial protection or risk mitigation, such as loans of self-insurance. For the eligibility step, we included studies that report information about the mean WTP estimates and their corresponding standard errors or variance (standard deviations) estimates.14 A second important
purchasing experiences demands less mental effort than asking respondents to indicate their WTP (Brown et al., 1996). There are also limitations to indirect elicitation approaches that might affect the hypothetical bias. Following Smith et al. (2019) respondents could be more uncertain about their preferences which leads to different responses depending on the question format. 11 There are two main reasons why we select 2005 as a starting date for the dataset. We try to ensure an adequate representation of the three forms of insurance against low-probability risks i.e. market, micro, and index insurance. Results before 2005 obtained using inclusion/exclusion criteria were very sparse with no studies on micro or index insurance. The second reason pertains to the entry into force of the Kyoto Protocol, which became legally binding on its 128 signatories on February 16, 2005. 12 We initially conducted separate searches in both Web of Science and Google Scholar. However, after comparing the results from both databases, we found that Google Scholar provided a broader range of articles, including all of the articles identified from Web of Science and additional ones as well. These reported values are related to Google Scholar results. 13 We acknowledge the importance of discrete choice experiments (DCE) studies, but the decision not to include these studies came about because of data availability and coherence issues. DCE studies indirectly calculate WTP for insurance schemes for specific attributes (e.g., nature of the supplier, deductible amount, coverage level, premium frequency, contract duration, etc.). Because each DCE research has its unique set of attributes, many moderators’ observations would be missing, posing a considerable problem for the MRA. The second issue is related to the difficulty of finding reliable information on expected loss for each choice set (with specific attribute levels). 14 The limitation of obtaining raw data constrained our capacity to compute the WTP and its standard error. Consequently, we resorted to extracting these statistics directly from the included studies, which, resulted in a reduction in the size of our dataset. criterion is the presence of information to allow the measurement of expected loss, the average historical cost of annual losses or, alternativity the actuarially fair premium. We included peer-reviewed articles published in English or Chinese.15 To identify additional studies, we reviewed the reference list of retrieved articles. We included 38 studies in our meta-analysis, which led to 74 data points as some studies included multiple observations (see Appendix C for further information).vThe final dataset includes average WTP estimated either from observational or experimental studies. Three separate instances are covered by observational studies. WTP may be elicited using: (1) hypothetical/actual scenarios with information on probability and loss, (2) actual scenarios with no probability information, and (3) no scenario at all with no information (see Appendix D). However, experimental studies encompass two cases. The first estimates the WTP for different levels of probabilities and/or losses. The context description is neutral and the insurance contract is without default risk. For the second type of studies, the WTP is elicited by the manipulation of additional factors (e.g. framing, default probability, etc.) other than probability or losses that are fixed and known throughout the experiment. For these studies, we select only the average WTP elicited from the control group, where the scenario description is neutral and the insurance contract is without default risk.16, 17 3.2 effect size As a natural measure of low-probability insurance elicited value, the average willingness to pay denoted by
WTP would be the most obvious. Expressed in real or experimental monetary units across studies, this
metric needs to be normalized. A first concern of such conversion is that the final metric will poorly
represent the potential underinsurance dynamics against low probability risks. Furthermore, it may also
introduce additional noise into the WTP estimates due to unobserved heterogeneity related, for instance,
to variation in risk characteristics, relative cost of insurance or cultural risk and insurance perception, etc. As this kind of heterogeneity would be under-captured by the meta-regression analysis, baseline
conversion would not be optimal.18 To get more comparable outcomes and overcome these particular
issues, we define the average willingness to pay per monetary unit of expected loss. We then refer to this
metric as relative willingness to pay (RWTP), defined as19:
2i i
i
WTP RWTP
EL =
where ELi denotes the expected loss for the study (i). We assume that expected loss can be either (1)
estimated from historical average losses, (2) calculated from known loss distributions or (3) measured from
publicly available information on actuarially fair premium. The expected loss information is manually
collected from included studies (see Appendix C for details). Adjusting the average willingness to pay with
expected loss, as an alternative to statistical rescaling, produces a unitless index of insurance value with
one as a reference level. If WTP substantially marks up expected loss levels, this may suggest a high value
placed on insurance, and vice versa. Figure 2 illustrates the zero-truncated distribution of RWTP across
all studies included in our meta-analysis. We note that the distribution is bimodal right-skewed, with 70.6
% of observations less than one, and 13.8% more than two. The standard error of the metric varies considerably in our dataset, raising concerns about outliers that
could distort the validity and robustness of the meta-analysis conclusions (Viechtbauer and Cheung, 2010). To alleviate this problem, we trim the RWTP and standard error at the top of the 5% level, resulting in a final dataset of 65 observations.20 Table 1 presents the mean RWTP values for different sub-groups.21 The
first column reports the unweighted means, while the second reports the weighted means. The meta-
analytic mean of RWTP weighted by the inverse of the number of reported observations is about 0.875. At this level, the overall average value should be interpreted with caution because of potential publication
bias and heterogeneity examined in the next section. It is interesting to note that experimental-based
studies report higher values for RWTP than observational survey studies. Similarly, studies related to
idiosyncratic risks appear to report higher values for RWTP than correlated risks. The difference between
China, on the one hand, and Germany and the Netherlands, on the other, is significant. Finally, laboratory-
elicited RWTP shows the highest values. In our analysis of publication bias and meta-regression analysis, we use logarithmic transformation for RWTP.22 We define the effect size by the standardized willingness to pay (Henceforth SWPT) as follows:23
3i i
i
WTP SWTP
EL    =    
The standard error of SWTP:24
2
2 4i i
i i
SD SE RR
n WTP
=
where SDi denotes the standard deviation of the WTP for study (i) and ni is the sample size. 20 Winsorization is an alternative method to apply in the meta-analysis (Lipsey and Wilson, 2001). It substitutes the extreme values with the highest values in given percentiles. 21 Appendix D reports the relative frequencies of the included studies, using bar diagrams, according to different subgroups (continent, year, country, coverage type, elicitation method, insurance type, risk type, and number of studies). 22 Logarithm transformation linearizes the RWTP metric so that deviations in the numerator and denominator have the same impact (Hedges et al., 1999). Additionally, the moderating variables coefficients in the meta-regression would be easier to interpret. Third, the distribution of the logarithm of response ratios is approximately normally distributed (Hedges et al., 1999). The absence of such normalization has a minor impact on the estimates of meta-regression coefficients discussed in section 5. 23 The sample mean, as a measure of central tendency, does not quantify a causal relationship between two variables of interest, and thus there is no "effect”, Borenstein et al. (2011). For convenience, we will use the terms “metric” and “effect size” interchangeably to represent mean WTP adjusted by the expected loss for the insured risk. 24 See Appendix A for the derivation of equations 3 et 4. 4. Publication Bias
Publication bias is a perennial concern that may distort the estimation of the average overall effect and the
conclusions drawn. The studies included in the current meta-analysis are observational and non-
comparative, so the interpretation of outcomes would not be contingent on the null hypothesis
significance test (Maulik et al., 2011). In practice, studies reporting low WTP are equally likely to be
published as those with very high WTP, provided they meet rigorous standards. It is not uncommon, that
for willingness to pay (WTP) elicitation to lack rigor or to take insufficient account of hypothetical biases
or strategic behaviors. These methodological shortcomings could reduce a study's chances of publication,
even if realistic WTP values are obtained from a reasonable sample size. Similarly, studies with lower WTP
variance may be less likely to be published because of the greater difficulty in accurately predicting WTP. A starting point to get some insight into the presence of publication bias is a visual inspection of the funnel
plot, which presents SWPT on the horizontal axis and the precision of the estimates (1/SE) on the vertical
axis. If the distribution of standard errors is symmetrically distributed around the mean line, there is no
publication bias. Figure 3 shows the funnel plot for the assessment of publication bias. The shape of the
funnel plot did not reveal any evidence of apparent visual asymmetry. A more formal and accurate way to
detect publication bias is the “Funnel Asymmetry Test”-“Precision Effect Test” (FAT-PET) proposed by
Stanley (2008). This test assumes that publication selection induces a correlation between the estimated
effect size and their standard errors. The FAT-PET is implemented by testing the slope of the regression
of SWTP on its standard error:
0 1i i i SWTP SE SWTP  = + +
where SWTP is the ith standardized WTP estimated in study s and SE(SWTP) is the corresponding standard
error, α0 is the true effect after correcting for publication effect and α1 is a measure of the importance of publication bias. Testing for α0= 0 is a precision effect test (PET) for a genuine empirical effect net of publication bias, whilst testing for α1 = 0 is the funnel asymmetry test (FAT) for publication selection. The statistical significance of the estimate of α1 is an indicator of the presence of publication bias. Since the empirical studies in our dataset use different data collection methods and sample sizes, 𝜀𝑖 are likely to be heteroscedastic. Equation 5 is thus estimated using the weighted least square (WLS) method25 using Fixed
effects (FE) and Random effects (RE) models. The fixed-effects model assumes that the effect sizes of the studies are deterministic and different. The
random effects model assumes, however, that true effects can differ across studies so that the variation in
estimated effects is composed of two parts: heterogeneity (between studies) in the true effect and sampling
error. The weight is thus 2 21 i SE + where τ2 measures the variance of the true effect in the population (often referred to as the amount of ‘heterogeneity’ in the true outcomes).26
Columns 1 to 3 of Table 2 present the results of three specifications based on equation (5): simple OLS,
WLS-RE and WLS-FE. To accommodate within-study correlation of estimates for each specification, we
report cluster-robust standard errors with clustering by study. Moreover, two weighting schemes are used
for each specification: equal weights for each estimate (weight 1) and equal weights for each study (weight
2). The second weighting scheme allows the consideration of multiple effect-size estimates reported by
primary studies.27 For all specifications, we do not reject the null hypothesis for 𝛼1, which indicates the absence of publication bias: (α1 = 0 at the 10% significance level). Stanley (2008) argues that the publication bias-corrected estimates of the mean true effect (𝛼0 in Equation (1)) may be biased downward when the null hypothesis is rejected. While the null hypothesis is not rejected, we follow the procedure proposed by
Stanley and Doucouliagos (2014) that consists of replacing the standard error with its squared term
(quadratic specification), i.e., the variance. The meta-regression is called in this case the Precision Effect
Estimate with Standard Error (PEESE). Columns 4 to 6 of Table 2 display the PEESE results. We find
the same results as columns 1 to 3, that is there is no publication bias in all specifications (OLS and WLSRE in the two-weighting scheme).28 5. heterogeneity analysis  5.1 variables description The average RWTP varies considerably across studies, as shown in Figure 2. The null hypothesis of Cochran's Q test reported in Appendix E indicates a large level of heterogeneity between studies (I2 >
75%). To deal with heterogeneity and to identify the most effective factors that would explain differences
between RWTP, we define several moderating variables (binary, multinomial, and numeric) as covariates
in the meta-regression. As a second objective, we define two synthetic study profiles that simulate an
average RWTP using all estimates, but overweighting those that are better identified. We separate the moderators into the following categories: WTP elicitation design, risk specificities,
exposed assets, insurance features, sample respondents’ characteristics, spatial-temporal variations, and
publication characteristics. Table 3 presents the definition and summary statistics of all variables included
for heterogeneity analysis. In the first category, we consider moderators that focus on the survey design
and measurement characteristics of WTP. As reported in Table 2, this first category represents an
important source of heterogeneity. We distinguish observational surveys 62% of our dataset from
controlled experiments 38%, which breaks down to 25% for online experiments, 12% for laboratory
experiments, and 1% for field experiments. For some studies, there are several scenarios where authors
use between-subjects or within-subjects designs. For the WTP measurement methods, we describe the prevalence of compatible incentive mechanisms by
a binary variable with an average value of 18%. We also consider the fact that WTP is measured using a
price generation approach (e.g., an open-ended question) as opposed to a price selection approach (simple
or double dichotomy method). Hypothetical bias mitigation correction is modeled by a binary variable
that indicates whether researchers employ bias mitigation strategies (e.g. cheap talk, consequential script,
follow-up question, etc.). The participation fees binary variable indicates whether participants received
monetary compensation for their participation in the study. We encoded the variability of the risks by considering the difference between idiosyncratic risks (21.5%)
and correlated risks (78.5%). For the second category, we specify different subclasses (flood 61%, various
climatic risks 9%, and earthquake 1%). For the risk characteristics, we define a first numeric variable equal
to the descriptive probability provided and a second binary variable that describes the studies in which the
implicit probability of loss is below the 5% threshold. When the probability information is not provided
(68% of the cases), we estimate it from the fair premium or the average loss. Regarding the third category,
we note that assets exposed to small probability risks are disparate. We define two main classes of assets:
crops and property (house and contents), which account for 40% and 32% of our sample, respectively. Regarding insurance contracts, 60% (40%) are indemnity-based (index-based), whereas 29% have a
subsidized premium. Sample and data characteristics include a set of dummy variables to indicate whether
the estimates are related to the entire population or from targeting populations at risk (51% of the dataset). We also code two binary moderators for studies that distinguish between “protest” and “true zero” WTP. We create a set of variables related to the main countries of study, which are China, Germany, and the
Netherlands with the presence frequencies of 40%, 20%; and 18% respectively, as depicted in Figure 4. The year of data collection is included, with the distribution of this data depicted in Figure 5. We introduce
two variables related to average age and average annual income converted to US dollars using the
corresponding exchange rates. The last category of moderators contains publication characteristics and relies on four variables. The first
one is the number of citations to account for study quality. A second variable indicates whether the study
was published in an international academic journal recognized by the French National Research Center
(CNRS). We also denote by a binary variable the studies with low citations (less or equal to one). Finally,
we perform a diagnostic test for multi-collinearity on all variables. The values of the variance-inflation
(VIF) factors for all variables are lower than 9, with an average VIF of less than 5 (see Appendix F). Variable Description Mean Std. dev. Weighted
Mean
Exposure assets and insurance characteristics
House =1 if the exposed asset is a property (house/contents), 0 otherwise 0.323 0.471 0.232 Crop =1 if the exposed asset is a crop, 0 otherwise 0.4 0.493 0.438 Indemnity insurance =1 if the study considers indemnity insurance, 0 otherwise 0.6 0.493 0.561
Presence of subsidy =1 if there is an insurance premium subsidy, 0 otherwise 0.292 0.458 0.246 Sample characteristics
Subject pool =1 if the WTP is estimated from the general population, 0 otherwise 0.293 0.458 0.256 Random sample =1 if the WTP is estimated from a random sample, 0 otherwise 0.923 0.268 0.89 Sample size Number of observations of the study 348.18 369.4 382.82 Protest zeros WTP =1 if the study accounts for protest zeros WTP, 0 otherwise 0.415 0.496 0.401
Regions and study year
China =1 if the study is realized in China, 0 otherwise 0.323 0.471 0.301 Germany =1 if the study is realized in Germany, 0 otherwise 0.200 0.400 0.132 Netherlands =1 if the study is realized in the Netherlands, 0 otherwise 0.180 0.391 0.113 Year The year the study was conducted 2011.7 4.6 2012.67
Control variables
Annual income The logarithm of sample annual income in U.S. dollars (inflation-adjusted) 0.311 0.54 0.357 Average age Sample average age in years 43.72 8.357 44.69
Publication characteristics
Article type =1 if the study is published, 0 if it is a working paper 0.953 0.211 0.972
Top-ranked academic journal
=1 if the study is published in an acknowledged academic journal, 0 otherwise 0.323 0.471 0.324
Low number of citations =1 if the average number of citations per year is less than one, 0 otherwise 0.261 0.442 0.246
Notes: The third column corresponds to the mean weighted by the inverse of the number of estimates per study. 5.2 meta-regression model We investigate potential sources of heterogeneity by completing the model provided in equation (5) with
additional study-level characteristics. We intend to estimate the "True" SWTP level after accounting for
the potential effect of moderating variables. The baseline meta-regression model is then formulated as
follows:
0 1i s i s i s i s SWTP SE SWTP  = + + +X β
With SWTPi the logarithm of the mean WTP divided by expected loss, X a vector of variables (moderating
variables) to capture study-specific characteristics associated with the estimate s from study i, 𝛃 a vector
of coefficients and 𝛆i the sampling error of the regression. The intercept term of the meta-regression, 𝛂0,
measures the true level of SWTP after controlling for publication bias and heterogeneity, Xue et al. (2021). A statistically insignificant intercept means that the observed estimates are driven mainly by the
characteristics of the primary studies. Conversely, a statistically significant intercept may suggest an
intrinsic perceived value of insurance irrespective of the potential effect of moderating variables. Unlike conventional econometric models, we cannot assume that the estimation errors of the meta-
regression model are independent and identically distributed. First, dependence is likely to arise, especially
when there are multiple estimates from a unique study (Stanley and Doucouliagos, 2014). In such a case,
this study’s results might dominate the overall effect. Second, heteroscedasticity, i.e. non-constant variance
of SWTP estimates, could also be present due to primary studies using different sample sizes, sample
randomness, and sampling method (Nelson and Kennedy, 2009). Therefore, estimating a meta-regression
with the OLS method might lead to inconsistent estimates, though unbiased. For these reasons, we
estimate meta-regression with the Weighted-least squares (WLS) method. We perform meta-regression
using three estimators: (1) a cluster-robust ordinary least squares (OLS) estimator; (2) a cluster-robust
random effects model (Unweighted RE) (3) a weighted random effects model by the inverse of the standard error (Weighted RE).29 The choice between the two models depends on how the individual
studies are collected. If the effect size is identical across the studies a fixed-effects model can be used
(Hedges & Vevea, 1998). When there is significant heterogeneity among the studies included in the meta-
analysis a random-effects model is preferred. The high heterogeneity of our dataset in terms of research
design, time of publication, data collection, and national context lead us to prefer a random-effects model (see the Q statistic Appendix E). For robustness reasons, we run analyses using other models.30
Meta-regression faces the so-called "model uncertainty" problem, which implies that the true model
cannot be identified in advance, Brada et al. (2021) and Kocenda and Iwasaki (2022). Having the wrong
variables in the regression model leads to misspecification bias and invalid inference. To address this
problem, we estimated our models using the Bayesian model averaging (BMA). The objective of this
method is to define the best possible approximation of the distribution of regression parameters. BMA
analysis provides three basic statistics for each parameter: the posterior mean, the posterior variance, and
29 The random-effect (RE) model is more appropriate in the presence of high heterogeneity. RE model weights correspond to 1/(τ2+𝑆𝐸𝑖 2). When heterogeneity is high, 𝑆𝐸𝑖 2 would be negligible compared to τ2 so that all data points would have the same weight≈1/τ2, which can be problematic in the presence of publication bias. We weight the dataset by 1/𝑆𝐸𝑖 2 before using the RE model. 30 We estimate the random/fixed effects model using the R package “metaphor” (rma, REML). The Bayesian Model Average
is estimated with R package “bms” and the unweighted OLS with R package “Robustbase” (lmrob). the posterior inclusion probability. The likelihood of each model is reflected by the model's posterior
probabilities. The posterior means are then calculated as the estimated coefficients weighted across all
models by their posterior model probability. We follow Jeffreys (1961) to interpret the posterior inclusion
probabilities (PIPs) of BMA means, who characterizes evidence of an effect as "weak" for a PIP between
0.5 and 0.75, "substantial" for a PIP between 0.75 and 0.95, "strong" for a PIP between 0.95 and 0.99, and
"decisive" for a PIP above 0.99.31 5.3 results Table 4 reports the meta-regression analysis (MRA) obtained from different estimation methods after checking for multi-collinearity. Consistent with the previous results presented in Table 2, coefficients associated with publication bias are not statistically significant in all estimated models. A first view of results is provided in Figure 6 which depicts a visual representation of the BMA analysis. We note that 14 moderating variables are relevant to explain the observed heterogeneity across studies with a PIP higher than 0.5.32 From Table 4, estimated coefficients vary relatively little across the different models showing very small differences between the weighted (1 & 2) and unweighted (3) estimation methods.33 Following a series of preliminary analyses, a total of 23 moderating variables have been retained in MRA to mitigate concerns regarding overfitting.34
Following the MRA, we focus on moderators for which we have the strongest effect on the SWTP i.e. the highest posterior inclusion probability in BMA analysis. The absence of probability of loss information provision is linked to lower SWTP. When loss probability is not provided, individuals tend to form their estimations through sampling (Barron and Erev 2003; Hertwig et al., 2004; Weber et al. 2004, Bakkensen and Barrage, 2021). Due to small experienced samples, losses will be seldom, implying an underweighted chance of losses and a consequently low insurance demand. Krawczyk et al. (2017) highlight a persistent underestimation of small probability risks, even when subjects learn about the risk over time. On the other hand, when probabilities are provided, we find that a small decrease can have a significant positive effect on SWTP. All else being equal, a 1% downward variation of the provided probability tends to increase SWTP by 0.26, suggesting that the decay rate of WTP, for a small probability decrease, is less than the expected loss. This result seems to contradict the probability neglect idea, suggesting that provided small probabilities are above the threshold of concern. A similar result was found for stated WTP for insurance, with very small provided probabilities, in Schade et al., (2012). This result is remarkably consistent with the description-experience decision gap, where behavioral implications vary depending on whether uncertain choices are made from experience or description (Hertwig et al., 2009). For description-based prospects, people seem to be risk averse for gains and risk seeking for losses. However, for an experiencebased setting, they become risk-seeking for gains and risk-averse for losses (Kudryavtsev and Pavlodsky, 2012). Decisions from description (DFD), where an explicit and precise description of the loss probability distribution is provided to agents, are more subject to small probability distortion. 31 BMA requires explicit priors on the model (model prior) and regression coefficients (g-prior). As suggested by Eicher et al. (2011), we use the uniform model prior and the unitary g-prior information. 32 The vertical axis lists all our moderating variables sorted by the posterior inclusion probability (PIP) in descending order and the horizontal axis refers to the posterior model probability (PMP) of each model sorted in ascending order. The blue and red colors indicate positive and negative signs of moderatos, respectively. The blank cells suggest that the parameters associated with these variables are not significantly different from zero for most models. 33 We estimate the random effects model using the R package “metaphor” (rma, REML) without and with weighting by (1/𝑆𝐸𝑖 2). The Bayesian Model Average is estimated with R package “bms” and the unweighted OLS with R package “Robustbase” (lmrob). 34 The debate related to the number of studies per covariate remains unresolved between the traditional rules of thumb used to minimize the risk of overfitting and the new findings. We draw on the work of Austin et al. and Steyerberg (2015), who suggest that the number of observations required per covariate may be lower than often assumed. They suggest that as few as two studies per variable might suffice for a reasonable estimation of regression coefficients. This result also seems consistent with the inverse S-shaped probability weighting heuristic and, in particular, with the local condition that extremely low probabilities are more overweighed relative to their base value than small probabilities (Jaspersen et al., 2023).35
While our results provide no direct support for hypothetical bias, additional factors related to data collection design seem to impact the SWTP. For instance, the laboratory-based elicitation method shows a remarkably positive effect on the outcome variable, in contrast to online experiments and surveys. Laboratory-based methods often involve a hypothetical purchase decision of hypothetical/real insurance products without monetary consequences. Estimated WTP could be subject to hypothetical bias, strategic behaviors, or social desirability bias that may push respondents to overstate their WTP to be more socially acceptable (Lusk and Norwood, 2009; Carlsson et al., 2010; Paulhus, 1991). MRA does not provide evidence on the influence of incentive-based elicitation settings, and the relative effects of direct versus indirect elicitation methods. Such variables are generally considered proxies for hypothetical biases and strategic behaviors. These results are in line with Kesternich et al. (2013) who find no difference between market data and hypothetical choice experiments when estimating Medicare insurance demand. Similarly, Cole et al. (2020) provide no support for hypothetical bias when estimating demand with different elicitation mechanisms.36 Other moderators such as participation (show-up) fees and multiple WTP estimates based on within-subject design report significant positive effects on SWTP. Within-subject design can be more prone to the potential correlation of treatment effects and to other systematic behavioral patterns such as learning, subject fatigue, wealth effects, etc., (Landry, 2017). Our results do not show evidence that correlated risks are related to low WTP as opposed to the claim of Friedl et al. (2014) who show that social comparisons make insurance less attractive when risks are correlated because of subjects’ aversion to unequal payoffs.37 To further investigate the effect of correlated
35 This outcome is particularly reconcilable with the Jaspersen et al. (2023) model and their new local condition of the probability weighting function, the decreasing relative overweight (DRO). 36 All these results are in line with the earlier Loomis (2011) findings where hypothetical bias is less severe for WTP elicited for private goods. However, Robinson and Botzen (2018) find some evidence for hypothetical bias in their results related to the insurance context. 37 One possible explanation of this stylized fact may lie in the difficulty of indemnifying concomitant and correlated losses, resulting in fat tails loss distribution which might threaten the solvency of insurers and their ability to fulfill their contractual commitments to policyholders (Biener et al., 2019). risks, we analyze the potential effect of various sub-categories of correlated risks observed in our dataset such as climate, flood, snow and earthquake. It turns out the SWTP for earthquakes is significantly positive. Average sample incomes are negatively associated with SWTP supporting the view of insurance as an inferior good. This result may suggest that wealthier individuals would face lower costs to self-insure, an activity that substitutes for market insurance (Ehrlich and Becker, 1972). A theoretical justification for this finding is also related to the decreasing absolute risk aversion for wealth leading to consider insurance as an inferior good. Age is negatively related to the outcome variable in the sense that samples with a high average age exhibited the lowest SWTP. This result confirms the finding of Browne et al. (2015) related to revealed preference analysis for purchasing flood versus bicycle theft insurance. Their results show that demand for both types of coverage decreases with age.38
Our results also show that the SWTP tends to decrease with time, a result that echoes persistent underinsurance behavior reported in the literature. This finding might also be indicative of a gradual decrease in attention to low-probability risks or disinterest for market insurance. It is plausible to think that people seem to steadily accept this perception and the consequences of LPHI risks such as climate change. Such conclusions would point in the direction of two antagonist behaviors, the search for alternative cost-effective solutions in which they would have a more proactive role or the acceptance of some degree of vulnerability (Leiserowitz et al., 2019 and Wagner, 2022).39The MRA results also show that the relative WTP are geographically dependent with a first notable difference between Germany and the Netherlands. Seifert et al. (2013) compared insurance demand in Europe using data from these two countries and found that WTP is higher in Germany. The charity hazard resulting from the disparity in disaster insurance systems is a possible explanation for this gap (Browne and Hoyt, 2000). Post-disaster public funding as in the Netherlands may encourage individuals to expect to receive contributions from public relief money in the event of a major disaster (Yan and Faure, 2021). Second, we find that the relative WTP is smaller in China than in Europe, mainly in Germany and the Netherlands. This finding is consistent with several empirical results of studies conducted in developing countries. After controlling for the income effect, one plausible explanation is that for a collectivityoriented society as in China, post-loss financing may rely on informal family and community solidarity more than on formal market insurance products. Therefore, private insurance may play a smaller role as a risk management mechanism. To reinforce this result, we conduct a complementary analysis using national culture as an additional determinant of perceived costs and benefits of insurance. To capture national culture, we use Hofstede's cultural factors.40 Holding other factors constant, we find that relative WTP is positively (negatively) related to “Uncertainty avoidance” (“Power distance”). In countries with high “Power distance”, people tend to accept inequalities more easily, reflecting a high degree of centralization of authority. This may also imply an increased reliance on an autocratic social order to manage the post-loss consequences in case of extreme losses, thus reducing the demand for insurance. Countries with high uncertainty avoidance, such as Germany and the Netherlands, are well organized to manage risks through developed insurance markets. In these countries, the willingness to pay to reduce risk through insurance is more significant.41 Chui and Kwok (2008) and Park and Lemaire (2012) report similar results related to the demand for life and non-life insurance, respectively. We perform an additional analysis using general-to-specific stepwise regression for further robustness checks. As shown in Table 5, after accounting progressively for key moderators derived from the BMA,
38 For stated preference surveys, age may have a significant influence on protest responses. Mental abilities decline with age and cognitive effort needed for making decisions in hypothetical scenarios may lead to more protest responses. Accordingly, younger individuals may be more likely to accept hypothetical scenarios than older individuals. 39  40 Hofstede cultural proxies are related to the “Power distance index” (PDI), “Individualism versus Collectivism” (IDV), “Masculinity versus Feminity” (MAS), “Uncertainty avoidance index” (UAI), “Long-term Orientation versus Short-term Orientation” (Ltowvs), and “Indulgence Versus Restraint” (IVR). 41 Related to the effect of research quality, we find that top-ranked journals seem to report smaller relative WTP. remain largely significant.42 Note that our results remained consistent even when outliers were not excluded, as shown in Appendix L.
The structural heterogeneity of our dataset allows us to define two different study profiles. The first one is related to survey-based studies with no information on the probability of loss, a subject pool representative of the population with no (small) participation fees. Such studies are expected to provide low RWTP. On the contrary, the second profile is related to studies with information about probabilities of losses, laboratory-based with participation fees, within-design, and young subjects with low income. For this second profile, we expect to observe a large RWTP. 42 The overall average metric as an estimate of the true willingness to pay to insure LPHI risks is not different from the expected losses. This result may suggest no a priori global underestimation of tail losses nor a systematic rejection of insurance that might be considered by households, under a narrow framing context, as a poor financial investment (Gottlieb and Smetters, 2020). However, this result has to be viewed with caution and should be confirmed with further investigations including more populations. This result should however be interpreted with caution due to the small sample size or the possibility to be an artifact of econometric assumptions or RWTP metric definition.  5.4. robustness checks We estimate additional regression models to check the robustness of the results obtained in Table 4. First, we
perform BMA analysis with a weight equal to the inverse of the number of data points per study and then without
weighting. The results given in Table 6 corroborate previous findings, where the magnitude and the sign of the
moderators exhibit little variation. To further investigate heterogeneity, we apply a three-level structure to the meta-regression model which allows
for examining differences in outcomes within studies (i.e., within-study heterogeneity) as well as differences between studies (i.e., between-study heterogeneity).43 Unlike other models, we do not need to know correlations
between outcomes reported within primary studies since the second level accounts for sampling covariation (Van
den Noortgate et al., 2013). Note that the random effects hierarchical method that we use for estimation allows
coefficients to vary randomly across studies (Ugur et al. 2016; Neves and Sequeira, 2018). We test different
candidate variables as third level such as article Id, country, survey-based, risk type, and coverage type. The results
do not change from previous findings, confirming the absence of correlation between SWTP within studies and therefore the appropriateness of the two-level model used to analyze heterogeneity.44 None of the third-level
candidate variables can explain more of the variability between studies. As a fourth robustness check, we conduct outlier analyses by first examining extreme SWTP with confidence
intervals that did not overlap with the confidence interval of the pooled effect. We perform influence analyses via
a “leave-one-out” method, in which effect size is recalculated when a single study is left out of the analysis
(Viechtbauer and Cheung, 2010). We identified three observations as potential outliers or influential outcomes
with the leave-one-out analysis and the Baujat plot displayed in Figure 7. After progressively excluding these three data points, we further reduce heterogeneity while confirming the obtained estimation results.45 Finally, as a last
robustness check we estimate a meta-regression model using conditional SWTP (excluding zeros WTP) as effect size. The estimation results are quite similar to those reported in Table 4.46
This table reports additional meta-regression results from BMA without weighting and with a weight equal to the inverse of the number of data points per study. The dependent variable of regression is the standardized willingness to pay (SWTP). Explanatory variables are defined in Table 3. For the precision (publication bias) variable, the posterior standard error in the unweighted(weighted) model is not available. As such, we recommend interpreting PIP values with caution. Notes: Variables with PIP above 0.5 are shown in bold. SD = standard deviation. SE = standard error. PIP= posterior inclusion probability. N.A. = not available. Number of observations: 65. 6. conclusion We present a meta-analysis of contingent valuation studies for low-probability risk insurance. Consistent with the few observed market-based data, the meta-analytic average willingness to pay found is lower than expected losses. Survey-based studies exhibited a particularly low weighted mean of 64%. Normalized WTP levels vary considerably across studies allowing meta-regression capturing different sources of heterogeneity. The main finding is that the variability of stated WTP is structurally dependent on risk characteristics, fundamental and methodological factors. Some of these factors have a strong theoretical basis to explain low insurance demand at the individual level. Our results provide evidence of exogenous determinants that may affect the relative WTP variability at the study level. Moderators such as information about probabilities and very small probability levels appear to positively influence relative WTP, whereas some respondents’ sociodemographic characteristics such as income and age show a negative effect. Laboratory-based estimates, appear also to report significantly higher values for relative WTP than alternative data collection methods. These factors are likely to accentuate cognitive biases and judgment errors, particularly in the presence of several WTP elicitation tasks. Similarly, cultural factors related to power distance and uncertainty avoidance bring further explanations for discrepancies in insurance WTP across international samples. Our results also document a consistent downward trend of average WTPs over time, a finding that may be indicative of an increasing inattention to low-probability risks driven in part by the increasing acceptance of climate change perspectives and physical risk damages, especially in the absence of comprehensive information on the probability of losses. Unweighted BMA
Weighted BMA (number of data points per study)
Post Mean Post SE PIP Post Mean Post SE PIP 𝛂0 (Precision) 0.1469 NA 1 -0.0004 0.1541 0.14031 𝛂1 (Pub. bias) - - - -0.0195 NA 1 Std. error -0.0160 0.1307 0.1528 -0.0167 0.0806 0.1492 Lab 1.2467 0.2291 1 1.2161 0.1587 1 Online 0.0752 0.1706 0.2788 0.0709 0.1827 0.2490 Within_design 0.4964 0.1464 0.9870 0.5225 0.1590 0.9873 Showup 1.3927 0.1893 1 1.2912 0.1477 1 Incentive_compatible -0.0370 0.1408 0.1834 -0.0838 0.1527 0.3263 Elicit_method 0.0078 0.0425 0.1615 0.0008 0.0271 0.1381 Probability_level -33.928 4.6663 1 -31.8202 4.8846 1 Implicit_prob -0.3060 0.1923 0.8160 -0.4661 0.0982 0.9996 Idiosync_risk 0.0315 0.1245 0.1654 0.0103 0.0662 0.1285 Earthquake 1.9184 0.4919 0.9925 2.0572 0.2786 1 Sample_size 0.0001 0.0001 0.4193 0.0000 0.0001 0.2633 China -1.2403 0.1636 1 -1.2151 0.0995 1 Year -0.0695 0.0147 0.9998 -0.0736 0.0105 1 Germany 0.1960 0.2563 0.4812 0.2546 0.2367 0.6421 Netherlands -0.5309 0.2450 0.9306 -0.4813 0.2116 0.9498 Protest 0.1178 0.1552 0.4699 0.0243 0.0637 0.2179 Random_sample 0.7529 0.2169 0.9863 0.7594 0.1458 0.9998 Inverse_income 0.1916 0.1087 0.8539 0.2534 0.0518 0.9998 Age -0.0226 0.0101 0.9283 -0.0164 0.0045 0.9859 Top_ranked -0.6349 0.1480 0.9993 -0.6617 0.1208 0.9999 Low_citations -0.1513 0.1619 0.5712 -0.1209 0.1233 0.5907
To ensure the long-term viability of non-mandatory coverage, outreach efforts are required through insurance education and promotion actions to guarantee a sufficient pool of policyholders, taking mandatory insurance systems with very low premiums and no adverse selection as a boundary model. Furthermore, policymakers should continue to support individual vulnerability reduction measures, which seem to be effective in reducing the severity of losses and less subject to individuals’ biases and heuristics. However, achieving these two essential objectives may prove more difficult for certain social groups with low financial capacity, for whom insurance may seem the primary safety net. One way to ease the budget constraint is to combine insurance mechanism with other flexible financial instruments such as credit access. For example, access to emergency loans may reduce the initial cash payment of premiums and lessen the liquidity constraint. Such a solution, consistent with the principle of discontinuity of preferences, would reflect the preference for more flexible risk management vehicles. For non-price factors affecting demand, we still need more empirical evidence on the interactions between risk preferences and behavior biases, on the one hand, and insurance characteristics on the other. 