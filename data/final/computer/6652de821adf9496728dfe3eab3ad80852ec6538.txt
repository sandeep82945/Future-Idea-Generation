With the development of artificial intelligence technology, an increasing number of human action recognition (HAR) methods are being applied to tennis training action analysis. The HAR methods based on skeletal points have been extensively researched and applied due to their superior action expression capabilities. In order to enhance the HAR ability of tennis players and effectively capture the detailed features in training actions, this paper proposes a tennis training action analysis model based on graph convolutional neural networks. Firstly, this paper establishes the limb vectors of humans in threedimensional spatial coordinates and extracts the features of tennis error techniques based on the distances between the skeletal joints of five parts of the human body. Secondly, the data's time frames are segmented to extract attention and improve the model's ability to capture detailed features. Additionally, the attention mechanism is introduced to embed the position information into the attention map, enhancing the model's generalization ability. Experiments conducted on several action datasets demonstrate that the proposed model in this paper achieves higher HAR accuracy and better recognition results compared to most current methods. INDEX TERMS Human action recognition; tennis; attention mechanism; graph convolutional neural network iii. method In this section, we propose a GCN-based model for tennis training action analysis. Firstly, we establish the limb vector and extract the technical action features related to tennis training. Secondly, we segment the time frames of the data to extract attention. Additionally, we introduce an attention mechanism to incorporate location information into the attention map. As depicted in Figure 3, we divide the human body into four parts: the torso, the left arm, the right arm, and the left leg. A tennis player's overall action can be categorized into primary action and secondary action. The primary action reflects the global state of the movement pattern, while the secondary action reflects the local state of the movement pattern. To accurately represent the action, it is essential to combine the characteristics of both primary and secondary
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/
Author Name: Preparation of Papers for IEEE Access (February 2017)
VOLUME XX, 2017 7
actions. For each of the five major human body parts, the respective limb vectors are as follows:
         1 , 2 , 3 , 4 , 5P t P t P t P t P t And the angular velocity is      1t t t     The distance from each part of the tennis player to the joint point is
       2 2 21 2 1 2 1 2, ,id x y z x x y y z z     
    1 , , , ,
n
i i
i
d x y z d x y z n   
Further, we establishe ST-GCN. Input the skeleton sequence diagram, divide according to the distance relationship between the joint point and the center point, and divide it into the current node, the point adjacent to the current node and close to the center of gravity, and the point adjacent to the current node and far away from the center of gravity, a total of three sub-points Set, and set three weight vectors. The specific expression formula is:
  0,if 1,if
0,if
i j
ti ti i j
i j
r r
w k r r
r r
      
where tik represents the characteristics of different nodes, t is the node of different frames, and i is the joint point of the different human body. The average distance between the node and the center of gravity is denoted by r. This method of division improves the difference information of the joint points, which can represent the centripetal and centrifugal motions of the joint points, which is more consistent with the actual situation of human activities, and has enhanced action modeling capabilities. The structure of the space-time graph is shown in Figure 4. The input data is  /h T h N  , where h is the number of segments in the time frame, N is the size of the attention matrix, and T is the dimension of the frame. And the average operation in each time period eliminates the influence of channel C. The rules for constructing the spatio-temporal diagram are as follows: 1) Within a single frame, follow the natural skeleton connection relationship of the human body to construct the spatial graph. 2) Connecting the same nodes in two adjacent frames to form a temporal edge. 3) The nodes in all frames form a node-set. The skeletal data contains valuable information within the connections between joint points. In this paper, we represent all bones as vectors, considering the central joint point in the human skeleton data as the source joint point. The length of each bone segment is reflected by the magnitude of its corresponding vector. Furthermore, the direction of the bone vector indicates the orientation of the bone, originating from the closest node to the source joint point and extending towards the farthest node. In our approach, both the skeletal node data and the skeleton data are processed through the same network to yield distinct outcomes. The final score is determined by employing a two-stream fusion method that combines the results obtained from the two data streams. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/
Author Name: Preparation of Papers for IEEE Access (February 2017)
VOLUME XX, 2017 7
The method in this paper is based on GCN as a whole, which integrates the attention mechanism and ST-GCN, and divides the human skeleton into five parts. The flow of our algorithm is as follows:
The flow of the method in this paper
Input: Tennis training data set
Output: Action type
1. Built a human limb vector in 3D spatial coordinates;
2. Calculate the distance between the skeletal joints of the five parts of the human body; 3. Extract the technical movement characteristics of tennis errors;
4. Segment the time frames of the data to extract attention;
5. Embed the position information into the attention map;
6. Input the extracted feature information into ST-GCN;
7. Output of the identified tennis action type through the full connection layer. The data is first regularized, further, fed into a network containing a double-layer AM and ST-GCN, and finally passed through a fully connected layer. The overall structure is shown in Figure 5. iv. results In this section, we evaluate the proposed approach for tennis training action detection. All of the experiments in this paper use two Nvidia RTX3070 GPUs, an Intel Core l9-10850K CPU, and 64 GB memory. A. DATASETS This article utilizes the NTU-RGB+D 60 and Kinetics datasets [23, 26]. The NTU-RGB+D 60 dataset is specifically designed for HAR and includes joint annotations. It comprises 56,880 action samples, each consisting of videos, sequences of depth maps, 3D skeleton data, and infrared data. The dataset was captured using three Microsoft Kinect v2 cameras, with the 3D skeleton data providing the positions of 25 body joints per frame. Each sample consists of 300 frames, and for samples with
fewer frames, the sequence is repeated to reach a total of 300 frames. The dataset includes X-Sub and X-View segmentation methods. On the other hand, the Kinetics dataset is a large-scale dataset for HAR extracted from YouTube. It encompasses 600 categories of human actions, with each category containing at least 600 videos. In total, there are 300,000 video fragments in this dataset. Unlike the NTU-RGBD dataset, Kinetics only provides RGB videos. Therefore, we utilize the OpenPose toolbox to obtain skeleton data for specific pixels. Each skeleton in this dataset consists of 18 body nodes, and each sample consists of 300 frames. The NTU-RGB+D 120 dataset is an extension of the NTURGB+D 60 dataset, containing a more extensive collection of human action recognition skeleton data. It consists of 11,480 sequences performed by 106 subjects, covering 120 action categories. The NTU-RGB+D 120 dataset also includes X-Sub and X-View segmentation methods. In data preprocessing, we follow the approaches used in previous works such as references 7, 13, and 15. B. PARAMETER DETERMINATION To determine the optimal number of time frame segments, a series of experiments were conducted with varying segment counts. Using the same method of segmentation on the same dataset. In this paper, we seek the optimal number of segments using only skeletal point single-stream data without dual-stream fusion on NTU-RGB+D 60, as shown in Table 2. Table 2 Comparison of HAR accuracy of different segmented AM
Parameter X-View X-Sub Kinectics ST-GCN+AM-0 92.17 88.64 35.41 ST-GCN+AM-2 93.14 88.99 36.71 ST-GCN+AM-4 94.15 89.13 36.89 ST-GCN+AM-6 94.26 89.28 37.21 ST-GCN+AM-8 94.23 88.75 37.03 ST-GCN+AM-10 93.89 88.12 36.55 The inflection point occurs when there are four segments. When there are fewer than six segments, there is a noticeable correlation between the number of segments and an increase in the accuracy of the model. However, when there are more than six segments, the correlation between the model's accuracy and the increase in the number of segments tends to diminish. Analyzing the results, we observe that segmenting an entire action frame allows us to extract attention within each segment. Generally, the attention position at the beginning and end of a complete action differs. Therefore, increasing the number of segments can significantly enhance the model's final score. The reason why the model score doesn't show significant improvement beyond six segments is that a complete action
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/
Author Name: Preparation of Papers for IEEE Access (February 2017)
VOLUME XX, 2017 7
can be adequately represented by dividing it into three to six segments. Adding more segments only escalates the computational effort of the model without substantially enhancing its score. C. RESULTS AND ANYALYSIS In this paper, ST-GCN is selected as the baseline, and 2sAGCN, T-Conv, ST-LSTM, and ST-RNN are selected as the comparison algorithms to verify the effectiveness of the proposed method. Without modifying the number of network layers and the same hyperparameters as ST-GCN, we conduct multiple experiments, taking the accuracy of Top-1 and Top-5 as the test standard, as shown in Table 3, Table 4, and Figure 6. Table 3. Comparison of HAR accuracy of different methods on X-View
Methods Top-1 Top-5 ST-GCN [20] 84.37 - 2s-AGCN [23] 84.49 - T-Conv [24] 77.63 - ST-LSTM [11] 79.37 - ST-RNN [13] 67.45 -
OUR 85.58 95.69
Table 4. Comparison of HAR accuracy of different methods on X-Sub
Methods Top-1 Top-5 ST-GCN 83.54 - 2s-AGCN 84.89 - T-Conv 75.37 - ST-LSTM 76.49 - ST-RNN 73.52 - OUR 85.06 96.59
Figure 6. Comparison of HAR accuracy of different methods on Kinectics
In comparison to the unimproved ST-GCN, the addition of segmented AM and joint block modules resulted in improved recognition accuracy for the model. This improvement was consistent across large datasets as well. The network model with the two added modules exhibited an improvement rate of approximately 1.52% on X-Sub Top-1 and approximately 1.21% on X-View Top-1, compared to ST-GCN. On the Kinetics dataset, there was
an improvement rate of about 1.07% on Top-1 and about 1.45% on Top-5. Furthermore, we compared the performance of different methods on the larger dataset NTU-RGB+D 120, we also increased the comparison algorithms, as shown in Table 5. It can be observed that due to the increase in data volume and the complexity of actions, the HAR accuracy of different methods has slightly decreased. However, the performance of our proposed method remains significantly better than other algorithms. Table 5. Comparison of Top-1 of different methods
Methods NTU-RGB+D 120X-View X-Sub ST-GCN 79.53 78.87 2s-AGCN 80.33 81.27 T-Conv 76.34 75.37 ST-LSTM 78.33 77.65
AS-GCN [26] 80.21 81.37 STV-GCN [28] 82.37 81.55 ST-GRU [13] 78.97 79.11 ST-RNN 75.59 74.12 OUR 82.33 83.17
D. Segment time comparison The proposed method solely includes the segmental time AM module, in contrast to the 2s-AGCN and other recent methods, which introduce dual-stream fusion. As a result, the proposed method has a lower time complexity. The paper compared the running time of different methods to demonstrate the efficiency of the proposed method, and the results are depicted in Figure 7. It can be observed that the algorithm of the proposed method takes less time and has a lower time complexity than 2s-AGCN, T-Conv, ST-LSTM, and ST-RNN. E. Ablation experiments Finally, we conducted ablation experiments to validate the effectiveness of the GAN-based tennis training action analysis model proposed in this paper. The core modules of our algorithm are tennis technique feature extraction (TFE), data temporal frame segmentation (TFS), and AM. We
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/
Author Name: Preparation of Papers for IEEE Access (February 2017)
VOLUME XX, 2017 7
validated the effectiveness of each module on the X-View of the NTU-RGB+D 60 dataset, with ST-LSTM as the baseline algorithm. The experimental results are shown in
Table 7. Table 6. Comparison of HAR accuracy of different modules
Methods Top-1 ST-LSTM 76.49 ST-LSTM+TFE 79.63 ST-LSTM+TFS 77.56 ST-LSTM+AM 82.13
ST-LSTM+TFE+TFS+AM 85.06
It can be observed that all three modules can improve the performance of ST-LSTM to some extent, with the data temporal frame segmentation module providing the smallest improvement and the AM module providing the largest improvement. Effective extraction of tennis technique features contributes to enhancing HAR (Human Action Recognition) accuracy. v. conclusion In this paper, a tennis training action analysis model based on GCN is proposed to enhance the HAR accuracy of tennis moves and assist players in effective training. The paper first establishes limb vectors in three-dimensional spatial coordinates and extracts the technical action characteristics of tennis errors based on the distance between the five skeletal joints of the human body. Secondly, the temporal frames of the data are segmented to extract attention, thereby improving the model's ability to capture specific attributes. Additionally, an attention mechanism is developed to incorporate position information into the attention graph, enhancing the model's generalization capability. Experimental results on multiple action datasets demonstrate that the proposed model achieves higher HAR accuracy and better recognition results compared to existing approaches. One limitation of this paper is the absence of a coordinated attention structure to capture cross-channel information.