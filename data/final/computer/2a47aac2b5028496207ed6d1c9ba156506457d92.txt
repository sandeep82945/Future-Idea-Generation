Motivation: Relation extraction (RE) is a crucial process to deal with the amount of text published daily, e.g. to find missing associations in a database. RE is a text mining task for which the state-of-the-art approaches use bidirectional encoders, namely, BERT. However, state-of-the-art performance may be limited by the lack of efficient external knowledge injection approaches, with a larger impact in the biomedical area given the widespread usage and high quality of biomedical ontologies. This knowledge can propel these systems forward by aiding them in predicting more explainable biomedical associations. With this in mind, we developed K-RET, a novel, knowledgeable biomedical RE system that, for the first time, injects knowledge by handling different types of associations, multiple sources and where to apply it, and multi-token entities. Results: We tested K-RET on three independent and open-access corpora (DDI, BC5CDR, and PGR) using four biomedical ontologies handling different entities. K-RET improved state-of-the-art results by 2.68% on average, with the DDI Corpus yielding the most significant boost in performance, from 79.30% to 87.19% in F-measure, representing a P-value of 2:91 10 . Availability and implementation: https://github.com/lasigeBioTM/K-RET. 1 introduction With the exponential increase in the number of research articles published in the last decades, researchers find it hard to keep up with all relevant information for their respective fields. The overwhelming number of research papers, particularly in the biomedical field, frequently makes it impossible for researchers and clinicians to be aware of all established entity associations and dissociations. This unawareness often leads to experimental repetition to prove or disprove hypotheses already studied. Further, even if the hypothesis is unique or new, the same inference could often be retrieved from knowledge about experiments done on similar entities. Automated biomedical relation extraction (RE) is a fundamental step toward aiding these researchers and clinicians in saving time and focusing their work on genuinely novel associations. Through the years, several approaches have been employed to tackle biomedical RE, from straightforward rule-based approaches (Rinaldi et al. 2007, Kilicoglu et al. 2020) to entire machine learning dedicated systems (Abdelkader et al. 2021, Houssein et al. 2021), in which deep learning played a significant role (Dash et al. 2020). Successively, these approaches became more specialized in targeting multiple types of biomedical associations from protein–protein relations (Kim et al. 2006) to human phenotype-gene causality (Song et al. 2019, Sousa and Couto 2022). BERT (Kenton and Toutanova
2019) and their domain derivatives, such as BioBERT (Lee et al. 2020), SciBERT (Beltagy et al. 2019), and PubMedBERT (Gu et al. 2022) are the current state-of-the-art employed solutions. They not only successfully extract multiple types of relations from the text but can also, using their pretrained models, be easily integrated into newer systems targeting different Natural Language Processing tasks, such as Named-Entity Recognition (Nasar et al. 2022), Named-Entity Linking or Normalization (Ruas and Couto 2022), and Question Answering (Do and Phan 2022). However, there are some caveats for most biomedical RE systems. The first limitation is their focus and specialization on one specific type of association (Hu et al. 2021), with some notable exceptions that are flexible to target more than one type (Song et al. 2019, Sousa and Couto 2020, 2022). The second limitation is that systems’ results frequently lack an explanation. One can not easily understand how a relation was found and what inferences a particular model made to reach an output. Finally, in close connection with making systems explainable, the third more relevant limitation is their general disregard for the vast repertoire of biomedical dedicated knowledge bases, particularly in the form of ontologies. This multitude of organized biomedical knowledge is freely available, but most systems still rely only on the information from the training data. Some exemptions recently made some strides into using knowledge in the general domain (Liu et al. 2020) and the biomedical/ vc the author(s) 2023. published by oxford university press. 1 this is an open access article distributed under the terms of the creative commons attribution license (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. ic.oup.com /bioinform atics/article/39/4/btad174/7108769 by Indian Institute of Technology Patna user on 10 January 2024
clinical domain (Hao et al. 2020). However, these are still limited in the domain’s specificity and inflexible to adding different or more structured knowledge. Some of the most notary examples of organized biomedical knowledge are the Gene Ontology (GO; Ashburner et al. 2000, The Gene Ontology Consortium 2019), the Human Phenotype Ontology (HPO; Köhler et al. 2021), the Human Disease Ontology (DO; Schriml et al. 2022), the Chemical Entities of Biological Interest (ChEBI; Degtyarenko et al. 2008), and the Unified Medical Language System (UMLS; Bodenreider 2004). Respectively, these organized resources described connections between gene function descriptors, human phenotypes, human diseases, chemicals of biological interest, and clinical entities. The work of Liu et al. (2020) is a recent and successful attempt for knowledge incorporation into multiple open and specificdomain tasks. Their K-BERT system was able to incorporate domain knowledge without creating a heterogeneous embedding space. The novelty in their approach is the creation of a knowledge layer that injects knowledge directly into the sentence. Then, they perform sentence tree re-arrangement before the embedding layer, with the addition of a soft-position embedding and a visible matrix to target possible readability problems from the re-arrangement. Also, it does not require pretraining of the BERT models it supports, making it suitable for users with limited computational resources (Zhao et al. 2019). However, their system has some major constrictions. First, the authors do not apply their approach to the RE task for the open or biomedical-specific domains. Second, the knowledge injection can only be used for single tokens within the sentence tree, making it miss knowledge associated with multi-token entities that are most prevalent in the biomedical domain. Third, the application of their system only allows for the injection of knowledge from one knowledge source, constraining data that intersects one or more domains (e.g. patient case reports that mention both the procedures done and the phenotypes associated with the patients). Finally, there is no possibility of injecting target knowledge into the entities of interest; one must always apply knowledge to all possible sentence tokens. In this work, we designed a new approach to knowledge injection that is able to address the challenges stated in the last paragraph to create K-RET, a knowledgeable biomedical RE BERT-based system. K-RET is a flexible biomedical RE system, allowing for the use of any pretrained BERT-based system (e.g. SciBERT and BioBERT) to inject knowledge in the form of knowledge bases from a single source or multiple sources simultaneously. This knowledge can be applied to various contextualizing tokens or just to the tokens of the candidate relation for single and multi-token entities. K-RET effectively improves the performance of baseline biomedical BERT-based models by an average of 2.68% on all datasets (DDI; Herrero-Zazo et al. 2013, Segura-Bedmar et al. 2014), BC5CDR (Li et al. 2016), and PGR-crowd (Sousa et al. 2019, 2020; Corpora). The most successful configuration is applying contextualized knowledge by adding two knowledge base entities per possible domain entity within each sentence tree (i.e. DDI Corpus plus ChEBI). This work resulted in the following main contributions:
• K-RET, a knowledgeable biomedical RE system that allows for the integration of any pre-trained BERT-based system. • Approach to flexible injection of knowledge with multi-options: 1. association of knowledge to single or multi-token entities in
the sentence tree;
2. add more than one knowledge source to inject knowledge of
different domains;
3. injection of knowledge into targeted or multiple contextual-
izing tokens in a sentence tree. In Section 2, we describe K-RET, formally presenting the main architectural features. In Section 3, we describe the resources used (datasets and knowledge bases), parameters, training details, and the main results of different system configurations. These configurations are the baseline (i.e. without knowledge) and the use of target versus contextualized knowledge within three different biomedical
RE datasets. Sections 4 and 5 discuss the previous results with targeted ablation studies and present the main conclusions and future work. 2 system and methods In this section, we will present our system K-RET, represented in Fig. 1. We will describe each new system component and how they differ from the implementations from both BERT (Kenton and Toutanova 2019) and K-BERT (Liu et al. 2020), which was built using the UER platform (Zhao et al. 2019), starting by defining the general Notation and then detailing our additions in Architecture. 2.1 notation We define a sentence s as a sequence of tokens ti, with length n:
s ¼ ft0; t1; t2; . . . ; tng (1)
Each token can represent one or more words that are included in the vocabulary V, ti 2 V. The Knowledge Base, K, consists of a collection of triples, e:
e ¼ ðti; rj; tkÞ (2)
where ti and tk are the descriptors of the entities, rj the relation between them, rj 2 V, and e 2 K. 2.2 architecture The model architecture of K-RET is divided into four modules. The first module, a Knowledge layer, injects knowledge from the knowledge base in triples, expanding the original sentence into a knowledgeable sentence tree. The sentence tree is fed into simultaneously the Embedding layer (second module) and the Seeing layer (third module). Then, it is converted to token-level embedding representation and a visible matrix, as presented in Fig. 1. This matrix acts as a control to prevent the injected knowledge from altering the meaning of the original sentence with excessive knowledge. The embedding representation can then be fed into the Mask-transformer (fourth module). K-BERT created a knowledge layer that injects knowledge and performs sentence tree conversion. On the other hand, our new knowledge layer was designed to address the three previously mentioned challenges. We detail how we tackled those limitations in the next sections: Multi-token entities, Multiple knowledge bases, and Contextual and targeted knowledge. Beyond the knowledge layer, we made changes to the original predictive pipeline by allowing the addition of class weights, a new type of data format, and the inclusion of any BERTbased pretrained model using the UER framework. 2.2.1 multi-token entities For multi-token entities, we first considered all combinations of single tokens to generate all possible multi-tokens in the same input sentence. Thus, if a sentence has a number of tokens of 10, the number of combinations possible would be 55. This number can vary if the sentence has punctuation or other special characters. Then, through a lookup table, we can add knowledge to all combinations we can match in the chosen knowledge base, keeping the longest combinations of tokens (with increased specificity) when there is overlap. Finally, we reconstruct the sentence tree through a sliding window that goes through all the combinations with and without knowledge. We introduced a multi-token entities option to address the limitation of only using one token, both in the sentence itself and in the knowledge to be injected. As it stands, the model did not allow associating knowledge to more than one token [e.g. ‘aralkylamino compound’ (original sentence tokens) is_a organic amino compound (added knowledgeable token)] nor associate multiple word knowledge to one or more words in the original sentence [e.g., dopamine (original sentence token) is_a ‘aralkylamino compound’ (added knowledgeable tokens)]. D ow nloaded from https://academ ic.oup.com /bioinform atics/article/39/4/btad174/7108769 by Indian Institute of Technology Patna user on 10 January 2024 2.2.2 multiple knowledge bases To accommodate multiple knowledge bases, we expanded the number of lookup tables mentioned in the previous section. Thus, if we use more than one knowledge base, K-RET will look at the sentence a number of times corresponding to the number of knowledge bases. If there is complete or partial overlap between two or more competing knowledgeable tokens associated with an entity sentence and the number of association tokens surpasses the number of maximum tokens defined at the start, we keep the ones with the highest information content. The multiple knowledge bases option resolves the limitation of using only one knowledge base at a time. Therefore if we have, as in the biomedical domain, knowledge bases targeting different types of entities, we have to choose which one we want to use to inject knowledge into the original sentence. 2.2.3 contextual and targeted knowledge Finally, we decided to add the possibility of only injecting knowledge into the entities in consideration for relation assessment, maintaining the native option of adding knowledge to all entities present in the sentence. To define the targeted entities, we used the tags < e > and </e > to delimit the entities in the candidate relation. The tags allowed injecting knowledge directly into the candidate entities. K-RET ignores those tags when using contextual knowledge for knowledge injection, adding knowledge to entities as described previously. Hence, as a result of the three additions, given an input sentence s ¼ ft0; t1; t2; . . . ; tng and one or more knowledge bases, our knowledge layer outputs a sentence tree:
st ¼ ft0; t1; t2; . . . ; tifðri0; ti0Þ; . . . ; ðrik; tikÞg; . . . ; tng (3)
which results from (i) querying all entity names involved in the sentence s, independently from their length and selecting correspondent triples from K, and (ii) adding the triples to their correspondent position. Figure 1 illustrates the structure of the sentence tree st and an example retrieved from our data. While the sentence tree can have multiple branches, the depth is fixed to 1, not deriving branches iteratively to better preserve the original sentence meaning. 3 implementation In this article, we used three openly available RE datasets to train KRET: DDI Corpus (Herrero-Zazo et al. 2013, Segura-Bedmar et al. 2014; drug–drug interactions), PGR-crowd Corpus (Sousa et al. 2019, 2020; human phenotype–gene interactions), and BC5CDR Corpus (Li et al. 2016; chemical–disease associations). Along with the written information in these RE datasets, we used four knowledge bases related to the four types of entities identified within those datasets to add extra entity information to the K-RET system. These knowledge bases are HPO (Köhler et al. 2021), DO (Schriml et al. 2022), CHEBI (Degtyarenko et al. 2008), and GO (Ashburner et al. 2000, The Gene Ontology Consortium 2019). In this section, we present the different experiments made to access our system using the aforementioned datasets and knowledge bases, with parameters and training details tuned for the specificities of each dataset. We also explore and present the results for the usage of full knowledge or just entity knowledge, as described in the previous section. 3.1 datasets Table 1 represents the relations types and counts for each dataset. The no_relation label accounts for entities present in the same sentence but that do not share a relation. The commonly used DDI Corpus presents four types of relations: effect to describe an effect or pharmacodynamics mechanism, mechanism to describe a
Figure 1. The structured layer representation of K-RET. In the pipeline, we retrieved a sentence from a biomedical relation extraction dataset with delimited target entities: venlafaxine and seizure. We added a Knowledge layer to these entities from associations made with their respective domain ontologies, the ChEBI and the Human DO. In the Embedding layer, the tokens are flattened into a sequence for token embedding. Then, the soft-position embedding is used along with the token embedding, and the tokens are tagged with A for segment embedding. The orange circles correspond to visible tokens in the Seeing layer, whereas the gray circles correspond to invisible ones. For instance, in row five venlafaxine (5) is visible to all tokens except the last two: is_a (15) and abnormal nervous system physiology (16). Finally, both layers, Embedding and Seeing, are fed to the Mask-transformer, corresponding to a stack of multiple mask-self-attention blocks. This last layer is masked to prevent the transformer from receiving structural information of the sentence tree. The sentence was simplified for readability purposes
D ow nloaded from https://academ ic.oup.com /bioinform atics/article/39/4/btad174/7108769 by Indian Institute of Technology Patna user on 10 January 2024
pharmacokinetic mechanism, advice to describe semantic relations between drugs regarding recommendation, and int for relations where there is no further information. Both the PGR-crowd and BC5CDR Corpora are binary in terms of relation classification. These two datasets only classify if the relation is present (true) or not (false). Figure 2 presents an example sentence for each dataset. We applied class weights to all datasets to normalize the different types of relations and distributions. Additionally, to train and evaluate all models on the same cross-validation splits, we split each dataset into training (60%), validation (10%), and test (30%) sets. Also, our metrics presented below are displayed considering the weighted average for each type of relation to further account for the datasets’ imbalances. 3.2 knowledge bases Several knowledge bases target biomedical entities, expanding on our information about them and their inherent relationships. Some of the knowledge bases or ontologies we can link to our target entities were mentioned above and are characterized in Table 2. With few code adjustments, one can easily integrate more knowledge into K-RET in the form of other knowledge bases and has the flexibility to test different combinations swiftly. 3.3 parameters and training details For each dataset, we empirically determined the best set of parameters. K-RET used a batch size of 32 for all datasets. The number of epochs ranged from 30 for DDI Corpus to 20 for PGR-crowd and BC5CDR Corpora (due to differences in dataset size). All other parameter settings were maintained from the original BERT model. The added knowledge only played a role in the fine-tuning and prediction stage. For the added knowledge, we varied the number of knowledge base entities allowed to link to each dataset entity in a candidate relation (or not). This variation ranged from two to five knowledge base entities per dataset entity. Our baseline represents the performance of the BERT-based systems without any added knowledge. When we refer to targeted knowledge, we mean just adding knowledge to entities in a candidate relation versus contextual knowledge, where we can add knowledge to all entities in the dataset. Figure 3 further elucidates the differences in the addition of knowledge. For the DDI Corpus, we used the ChEBI ontology; for the PGR-, we used the HPO and the GO ontologies; and for the BC5CDR Corpus, we used the DO and ChEBI ontologies, as represented in Fig. 2. All models were trained on three Tesla M10 GPUs, taking, on average for each model, 24 h (DDI Corpus), 1 h (PGR-crowd Corpus), and 2 h (BC5CDR Corpus). Each result presented in the following sections represents the averaged metrics for three runs except when it explicitly says otherwise, and each metric represents the weighted-averaged of the different labels. 3.4 results As mentioned in the previous sections, we divided our K-RET experiments into baseline, where we ran the BERT-based models
without additional knowledge, targeted knowledge added to the entities in the candidate relation, and contextual knowledge added to all relevant entities in the sentence. We considered an entity relevant if present in the chosen knowledge source (i.e., a part of the domain knowledge considered). 3.4.1 baseline To choose the best-performing BERT-based biomedical model for each of the three datasets, we used four of the most widely used systems: BERT (Kenton and Toutanova 2019), BioBERT (Lee et al. 2020), SciBERT (Beltagy et al. 2019), and PubMedBERT (Gu et al. 2022) integrated into K-BERT (Liu et al. 2020) modified to perform RE. Table 3 reports the main results of testing the three datasets over the different BERT-based systems. For all three datasets, SciBERT is the best-performing system. Therefore, in our following experiments, we used SciBERT as the baseline system to which we added a knowledge layer. 3.4.2 targeted knowledge For targeted knowledge, we added from two to five knowledge base entities to each entity in the candidate relation, as shown previously in Example 1 (Fig. 3). Although we define the number of knowledge base entities to add, we are always limited by how many entities each entity is linked to in the knowledge base itself. Figure 4 presents the performance of the three datasets from no added knowledge (baseline) to five added entities per entity in the candidate relation. Figure 4 shows that none of the K-RET models trained performs better than the baseline at any number of knowledge base-added entities. For all datasets, there is a slight decrease in performance, with the BC5CDR Corpus having a small increase in performance when the number of added knowledge base entities equals three. 3.4.3 contextual knowledge We followed the same configuration mentioned above for contextual knowledge from two to five knowledge base entities added to each relevant entity in the sentence. Figure 5 presents the performance of the three datasets from no added knowledge (baseline) to five added entities per relevant entity. Figure 5 shows a performance increase from baseline to K-RET on the DDI and BC5CDR Corpora. For the PGR-crowd Corpus, while the performance is better than for targeted knowledge, the baseline performance still outperforms K-RET. Similarly, the BC5CDR’s best performance is when the number of added knowledge base entities equals three, but this time surpasses the baseline. Table 4 presents the best results for each main model configuration (targeted and contextual), including the contextual knowledge configuration over 10 runs to determine the statistical significance of the best configuration accurately and the corresponding baseline considered previously and regarding the majority label. The baselineML represents the results if we assign the same label (majority label) to all the test relations. The results show that the contextual knowledge configuration over three runs prevails as the best model in two datasets (DDI and BC5CDR), with the targeted knowledge configuration not surpassing the baseline for any dataset. However, the BC5CDR Corpus presents a p-value of 0.8108 for F-measure and 0.8681 for accuracy (a ¼ .05), demonstrating a lack of significant difference between the means of Baseline and CK-RET10. Nonetheless, the DDI Corpus presents a p-value of 2:91 10 12 for F-measure and 1:44 10 12 for accuracy (a ¼ .05), validating a significant difference between the means of Baseline and CK-RET10. The P-values were determined using a one-tailed t-test. Table 5 reflects the specific performance of the DDI Corpus per type of relation (effect, advice, mechanism, int, and false) for each main model configuration. Supplementary Tables SA1 and SA2 present the same results for PGR-crowd and BC5CDR Corpora. For the DDI Corpus, we also performed ablation regarding multi-token entities by limiting the association of knowledge to the first entity
D ow nloaded from https://academ ic.oup.com /bioinform atics/article/39/4/btad174/7108769 by Indian Institute of Technology Patna user on 10 January 2024
within the multi-token considered. We obtained an F-measure of 0.8663 and an accuracy of 0.8732. 4 discussion From the experiences conducted throughout the previous section, we can infer that adding knowledge can significantly improve the state-of-the-art performance of one of the most used biomedical RE datasets, mainly when using contextual knowledge. However, there is a difference in how significantly we can improve performance, from nothing (PGR-crowd Corpus) to over 0.076 percentage points (DDI Corpus). Several factors can explain the differences in performance for the different datasets, such as dataset size and label distribution, knowledge base size and coverage of the dataset entities, or the average number of knowledge base entities that can be linked to each dataset entity. For the PGR-crowd Corpus, while all entities are linked to one of two knowledge bases, the HPO or the GO, the linking to the GO is already second handed. In the PGR-crowd Corpus, the authors recognized gene entities and posteriorly linked them to their most representative GO term. We do not use their gene identifiers directly because these biomedical entities are not directly represented in any hierarchic knowledge base. Thus, we used the GO terms to add further information and, consequently, distanced ourselves from the original gene entity. However, what made the most significant impact in the lack of increase in performance is the distribution of labels being predominantly true. Identifying undetected true relations is more challenging than if the dataset was more balanced (e.g. the BC5CDR Corpus) or with the inverse distribution (e.g. the DDI Corpus). Also, for the specific case of PGR-crowd Corpus, there could be ambiguity if an acronym describes a human phenotype or a gene since these can often overlap. This ambiguity is an open problem, and in this work, we opted not to consider human phenotype
Table 2. The main characteristics of the following knowledge bases: HPO, DO, ChEBI, and GO. All types of relations are transitive.a
Knowledge bases Number of concepts Type of relations Specific characteristics
HPO 15 670 is-a Five sub-ontologies, from which phenotypic abnormal-
ity is the most prevalent
DO 13 355 is-a Human-specific ChEBI 153 795 is-a Refers to small molecular entities
has-part
is-conjugate-base-of is-conjugate-acid-of is-tautomer-of
is-enantiomer-of has-functional-parent
has-parent-hydride is-substituent-group-from has-role
GO 43 613 is-a Three subontologies, molecular function, biological
process, and cellular componentpart-of
has-part regulates negatively-regulates
positively-regulates
aAll knowledge bases were consulted on 20 April 2022. Figure 3. Novelties of K-RET’s knowledge injection layer. Example 1 presents a modality where we only add knowledge to entities in the candidate relation (targeted knowledge) and limit the number of knowledge base entities assigned to each entity (maximum number of Entities 3). In Example 2, we present the same sentence with the option of adding knowledge to all entities regardless if they are in the candidate relation (contextual knowledge) and limit the number of knowledge base entities assigned to each entity to two (maximum number of Entities 2). From Examples 1 to 2, we add a third knowledgeable entity (terodiline) and remove one of the knowledge base entities added (aromatic compound). The first entity can only be linked to one knowledge entity because (ventricular arrhythmia) no other association is established in the knowledge base
D ow nloaded from https://academ ic.oup.com /bioinform atics/article/39/4/btad174/7108769 by Indian Institute of Technology Patna user on 10 January 2024
entities acronyms for contextual knowledge, which could be made us lose valuable information. With the BC5CDR Corpus, K-RET only surpassed the baseline when adding contextual knowledge by slightly over 1% in both Fmeasure and accuracy and was unsuccessful at demonstrating a significant difference between the baseline and the best-performing configuration. Although the impact on performance is not preeminent, the fact that this dataset is denser in the number of relevant entities per sentence and more evenly distributed than the PGRcrowd Corpus increases the impact of the addition of knowledge. This behavior occurs when knowledge is added directly to the candidate relation’s target entities and peripherally to other relevant entities. The DDI Corpus is unbalanced in favor of no_relation/false labels. Therefore, finding true relations is more challenging. This dataset’s distribution of labels is ideal for increasing the impact of
adding knowledge. The label distribution, the highly dense text in relevant entities, and the ampler size of the knowledge base used, ChEBI, all contribute to the rise in performance by adding contextual knowledge. The improvements from baseline were 7.60% for contextual knowledge in F-measure. We also verified that adding knowledge made a bigger impact on system performance than using multi-token entities by contributing to an average improvement of 0.0704 data points in F-measure and 0.0756 in accuracy. K-RET was able to design a more efficient and flexible knowledge layer than the previous attempt in the work of Liu et al. (2020) by applying knowledge injection to the biomedical RE task. Table 3. The baseline performance of the four models for each dataset.a
Dataset Model Precision Recall F-measure Accuracy
PGR-crowd BERT 0.7247 0.7766 0.7332 0.7765
SciBERT 0.7680 0.8002 0.7462 0.7999
BioBERT 0.6224 0.7888 0.6957 0.7888
PubMedBERT 0.7201 0.7834 0.7191 0.7833
DDI BERT 0.7764 0.7798 0.7775 0.7796
SciBERT 0.7906 0.7964 0.7930 0.7960
BioBERT 0.7796 0.7648 0.7680 0.7647
PubMedBERT 0.7801 0.7227 0.7473 0.7227
BC5CDR BERT 0.5804 0.5614 0.5670 0.5615
SciBERT 0.6266 0.6364 0.6289 0.6363
BioBERT 0.6150 0.6132 0.6142 0.6131
PubMedBERT 0.6091 0.6218 0.6113 0.6217
aThe specific models used were bert-base-uncased (BERT), scibert_scivoca-
b_uncased (SciBERT), biobert-base-cased-v1.2 (BioBERT), and BiomedNLP-
PubMedBERT-base-uncased-abstract-fulltext (PubMedBERT). The highest scores for each metric are presented in bold. Figure 5. The performance of the contextual knowledge K-RET configuration for the three datasets n Accuracy and F-Measure (top and bottom graphs, respectively) regarding the different number of added knowledge base entities
Table 4. The final K-RET performance results.a
Dataset Model Precision Recall F-measure Accuracy
PGR-crowd BaselineML 0.6222 0.7888 0.6957 0.7888
Baseline 0.7680 0.8002 0.7462 0.7999
TK-RET 0.7891 0.7914 0.7100 0.7917
CK-RET 0.7614 0.7960 0.7367 0.7962
CK-RET10 0.7441 0.7933 0.7206 0.7934
DDI BaselineML 0.7267 0.8525 0.7846 0.8525
Baseline 0.7906 0.7964 0.7930 0.7960
TK-RET 0.8132 0.7820 0.7930 0.7823
CK-RET 0.8674 0.8791 0.8690 0.8788
CK-RET10 0.8704 0.8805 0.8719 0.8804
BC5CDR BaselineML 0.3803 0.6167 0.4705 0.6167
Baseline 0.6266 0.6364 0.6289 0.6363
TK-RET 0.5838 0.5977 0.5816 0.5980
CK-RET 0.6412 0.6499 0.6428 0.6498
CK-RET10 0.6317 0.6348 0.6309 0.6347
aThe best-performing models for each dataset concerning baseline consid-
ering the majority label, baseline, targeted knowledge, contextual knowledge,
and contextual knowledge over ten runs. To facilitate table readability, we
results. The highest scores for each metric are presented in bold. D ow nloaded from https://academ ic.oup.com /bioinform atics/article/39/4/btad174/7108769 by Indian Institute of Technology Patna user on 10 January 2024
First, by proving the utility of contextualizing tokens, with substantial improvements in one of the three datasets described above from targeted to contextual token usage. Second is the possibility of adding more than one knowledge source to cover the domains of all relevant entities mentioned in the training data. Third, by incorporating the option of adding knowledge to multi-token entities instead of only single token. We determined experimentally for the DDI Corpus the multi-token approach to be more thorough, which can be explained by those entities constituting the majority of biomedical entities described in the datasets used for testing. 5 conclusion This article proposed a new biomedical RE system, K-RET, that incorporates knowledge in the form of ontologies into BERT-based systems to enrich and complement the data used for training. KRET is a flexible system that can handle different associations, integrate knowledge from multiple sources, define where to apply the knowledge, and deal with multi-token entities. We used three independent and open-access RE datasets to test our system concerning different types of biomedical entities with different characteristics (i.e. label distribution). Allied with the three datasets, we used four knowledge bases to inject knowledge according to the type of entities involved in the candidate relations. The best-performing dataset was the DDI Corpus allied with the ChEBI knowledge base, with significant average improvements compared with the baseline in the order of 7.60% and 8.28% for F-measure and accuracy, respectively. For the BC5CDR Corpus, we also had modest improvements (an average of 1.39% and 1.35% for F-measure and accuracy), even though we did not find these results significant. Differently, for the PGR-crowd Corpus, there was no significant change in performance from the addition of knowledge. Thus, we concluded that the label distribution and relevant entity density within the training data significantly affect how our system performs. Nevertheless, we successfully demonstrated the power of adding external knowledge to training data and how to accommodate it to different domain data. In a nutshell, the K-RET system successfully added contextual knowledge, more than one knowledge source, and knowledge to multi-token entities. Supplementary data
Supplementary data is available at Bioinformatics online. Conflict of interest: None declared. Funding