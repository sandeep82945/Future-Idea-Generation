Various types of vehicle automation is increasingly used in a variety of environments including road vehicles such as cars or automated shuttles, confined areas such as mines or harbours, or in agriculture and forestry. In many use cases, the benefits are greater if several automated vehicles (AVs) cooperate to aid each other reach their goals more efficiently, or collaborate to complete a common task. Taxonomies and definitions create a common framework that helps researchers and practitioners advance the field. However, most existing work focus on road vehicles. In this paper, we review and extend taxonomies and definitions to encompass individually acting as well as cooperative and collaborative AVs for both on-road and off-road use cases. In particular, we introduce classes of collaborative vehicles not defined in existing literature, and define levels of automation suitable for vehicles where automation applies to additional functions in addition to the driving task. INDEX TERMS Automated vehicles, automated driving systems, cooperative driving automation, collaborative driving automation, operational design domain, mixed traffic, dynamic operational task, levels of vehicle automation. a. basic terminology for automated vehicles Many of the well established terms in the AV domain originates from the SAE J3016 standard [3], which has been published in several editions, the first in 2014 [5] and the latest, at the time of writing this paper, in 2021 [4]. J3016 has also been used as the base for ISO PAS 22736:2021 [6], which uses the same basic terminology. These standards define a system that has some automation pertaining to the driving task as a driving automation system, and for more advanced automation, the system is called an automated driving system (ADS). Automation levels are further discussed in Section II-B. Automation with cooperative capabilities are defined in SAE J3216 [4] as cooperative driving automation (CDA), and an ADS with CDA capabilities is called a cooperative ADS (C-ADS). Machine interaction is further discussed in Section II-C.
Key defining characteristics for a driving automation system are the operational design domain (ODD), which defines the operating conditions for which a specific driving automation feature is designed to handle. Over the years, several frameworks for describing these operational conditions have been proposed. At the time of writing, an international standard, ISO 34503 [7], is close to completion. Even though not explicitly discussed in J3016, the ODD is also regarded as a key concept for safety assurance, as it defines the limits of the capability of the automated function. This is discussed e.g., by Gyllenhammar et al. [8] and ISO TR 4804 [9] which discusses how to approach safety and security for an ADS. Another important concept is the dynamic driving task (DDT), which consists of the sub-tasks of motion control (managing steering, brake, acceleration) and object and event detection and response (OEDR), i.e. monitoring the surroundings and reacting to events external to the vehicle such as pedestrians and the actions of other vehicles. Furthermore, it is recognized that AVs may experience problems preventing them from completing their user defined strategic mission. This may happen either if the ADS experiences a performance-critical failure, or the vehicle is close to exiting its ODD. In these cases, the AV is expected to be able to come to a stable stopped state called a minimal risk condition (MRC), with the purpose to reduce the risk of a crash. Gyllenhammar et al. [10] refine the definition to say that it should be a position with an acceptable risk, and that this will depend on (i) the risk of the selected position, (ii) the frequency to enter MRC, and (iii) the rate of recovery (how long the vehicle remains in a position which may not be sufficiently safe in the long term). The maneuver necessary to transition from the original mission to the MRC is called the minimal risk maneuver (MRM) in ISO TR 4804 [9] and DDT fallback in J3016 [3]. These and some other key terms are summarized in Table 1, and are important for the understanding of the
rest of the paper. B. HUMAN-SYSTEM RELATIONSHIP The primary way of describing and classifying vehicle automation has been by focusing on the division of responsibility between human users and the driving automation system using different levels or dimensions
to create classes of vehicles with different automation characteristics. The most known classification is arguably the SAE levels of driving automation first defined in the standard SAE J3016:2014 [5] and still used in the latest revision J3016:2021 [3]. This standard defines automation levels 0 (no automation) to 5 (full driving automation) as described in Table 2. Figure 1 visually illustrates the difference between the levels in terms of the user control and the ODD. While the SAE taxonomy has been useful when discussing AVs, it has also been criticised for ambiguities and misuse, partly depending on having an engineering-centric view rather than a usercentric view [11], [12] and other drawbacks [13] making it less useful when it comes to describing the capabilities of actual products. Attempts to introduce different definitions have been made to stem the confusion, however, at the time of
writing, none of these are yet as widely accepted as the SAE levels. Koopman [11] proposes four operational modes according to Table 3. In his view, the category supervised automation should be rather limited, at least considering today’s technology. Taking into account the capabilities of ordinary drivers to act as a back-up, it would limit the use to lane keeping and speed control on highways, as manoeuvres such as turning at an intersection would be too dangerous. He also specifically includes a category for test purposes, where the human user is a trained safety driver expected to be more able than the average driver to handle automation failures. The proposal from AV technology provider Mobileye has similarities to Koopman’s proposal, but is based on four dimensions: hands-on/hands-off (steering wheel), eyes-on/eyes-off (the road), driver/no driver, and MRM requirement. Using these dimensions, four vehicle categories, shown in Table 4, are defined. Compared to the other taxonomies, this proposal also discusses the role of human drivers (in-vehicle or teleoperators) for what they term non-safety-related situations to resolve traffic situations after the AV has come to a stopped state. E.g., if the AV would stop due to a policeman sign, a human driver might be necessary to resume the trip to prevent the vehicle from remaining in a position where it blocks other traffic. An even simpler classification is used by ADAS and AD software company Zenseact, which differentiates only between supervised and unsupervised functions to make clear what the expected role of the human user is [14]. All of these automation level definitions are focused on on-road traffic, and the driving task. In Section III we propose a similar classification, but include other automation tasks making the classification suitable also for vehicles with other forms of automation, which is applicable for many machines. c. system-system relationship Another dimension in the design space for AVs is interaction between agents in a diverse environment, e.g., between several AVs, between AVs and infrastructure, or between AVs and non-automated traffic participants, i.e., vehicles or pedestrians that have a capability to communicate with AVs but are not themselves controlled by automation. There are numerous works published related to interaction between AVs, often called cooperative or collaborative AVs. Much of the presented works are from the intelligent transport system (ITS) domain as it relies on V2X communication and is often combined with digital twins, see, e.g., [15]–[18]. Cooperative and collaborative driving is also in the scope of System-of-systems research, see, e.g, [19], [20]. Much of the work uses either the terms cooperative or collaborative for all types of AV interaction, or uses both terms interchangeably. Later, in Section III, we make an attempt to clearly define the difference between these two types of AVs, as we believe there is a significant difference when it comes to the strategic goal which should be reflected in the taxonomy. While we use these terms consistently with our own definition, it is important to notice that the terms may be used differently and inconsistently in the referenced literature. One classification of cooperative automated vehicles has been established by SAE in the standard J3216 [4]. This classification defines four different types of cooperation between on-road vehicles, shown in Table 5. We use the term cooperative (mostly) consistent with this taxonomy, which includes different strategies where several AVs communicate for mutual benefit (except possibly for the category ’prescriptive’ where the action may be for the benefit of others, e.g., a road operator temporarily prescribing a re-routing of traffic for some reason). The division in classes in this taxonomy is thus based on different mechanisms or capabilities of the cooperative action. Malik et al. present in [2] a survey related to cooperative/collaborative automated driving. A taxonomy is proposed covering: (a) background categories comprised of objectives, motivations, collaboration types, collaboration scopes, as well as applications, and (b) architecture categories consisting of interaction types, core components, architectural layers, manoeuvres, communication technologies, and coordination strategies. Further, aspects of cooperative driving are discussed including: (1) why collaborative driving is important to get full advantage of AD vehicles, (2) the motivations for vehicular agents to collaborate, (3) possible control strategies for collaborative vehicles divided as centralised coordination, decentralised with coordination, and decentralised without coordination, (4) the potential benefits of collaborative driving divided into the categories traffic efficiency, safety and miscellaneous, and (5) the collaboration types described in Table 6. It should be noted that Malik et al. mixes what we in this paper understand as the distinct types of cooperative and collaborative interaction. Unlike J3216, the cooperation/collaboration types of Malik et al. are not mainly based on the capabilities or the cooperative or collaborative action, but rather whether it is obligatory or voluntary for the individual AVs to participate. One useful definition of a system-of-systems is ”an assemblage if components which individually may be regarded as systems, and which possesses two additional properties: operational independence of the components [...] managerial independence of the components [...]" [21]. In system-of-systems research, the categories in
Table 7 are often used. The classification in this domain thus has a management perspective, like Malik et al. considering the degree of obligatory vs voluntary participation, but also ownership/management of the individual constituents. It can be noted that one of the categories is called collaborative system-of-system. However this definition is not consistent with the one we introduce in this paper. As the use of these terms is already inconsistent in literature, achieving consistency with all existing taxonomies simultaneously is not possible. A term we adopt from the system-os-systems domain, however, is the designation constituent [22] to refer to the individual systems within a system-of-systems (or, with the terms we commonly use later in this paper, in a cooperative or collaborative system). In addition to classification of the constituent vehicles, there is a classification of different levels of infrastructure support for use by CAVs. These so called infrastructure suppoer for automated driving (ISAD) levels [23] are from the EU project Inframix 1. We also consider this aspect to some degree in our proposed taxonomy. III. TAXONOMY FOR AUTOMATED VEHICLES A. SYSTEM-SYSTEM DIMENSION REVISITED In this section we propose a unified taxonomy aimed to encompass all types of AVs. The full taxonomy is shown in Table 9. We divide AVs in three major types. Individual AVs operate of their own, without assistance or communication with other vehicles, and pursue their own strategic goal. For cooperative AVs, we use the already existing definitions from SAE J3216 [4], with the additional definition that cooperative AVs are vehicles that cooperate for mutual benefit, but which have their own individual strategic goals. There are further use cases, partly covered by system-of-systems taxonomy but previously not well defined in the context of vehicle automation, where we have added the AV type denoted as collaborative AVs. The defining difference between cooperative and collaborative AVs is that for the latter, the constituents pursue a common strategic goal. This definition covers many use cases in confined areas or fleet operations. While the words cooperative and collaborative are sometimes used interchangeably, the terms are also used in other contexts with the distinction between having a shared goal versus interacting for mutual benefit but having individual goals2. These types of AVs, and the distinct classes defined within each type, are further described and exemplified in the following subsections. 1) individual classes For individual AVs, two distinct classes are defined. The first class is called ego-sensing and is an AV relying exclusively on its on-board sensors for the automated task. An example can be a highway autopilot function where the AV does not need any information beyond what is provided by its own sensors such as cameras, lidar, or radar. The second individual class is connected vehicles, often denoted as CAV, where the individual AV additionally may make use of information from cloud services and connected infrastructure, or even sensors that are part of the infrastructure, but not directly communicating with nearby vehicles. 2) cooperative classes Cooperative AVs are able to share information and coordinate their actions, but do not rely on each other to achieve their own goals. Each vehicle can operate independently, but can also benefit from information and actions of other vehicles in the system. There are four different classes of cooperation that cooperative AVs can take, status-sharing, intent-sharing, agreement-seeking and prescriptive. 2See, e.g., https://blog.jostle.me/blog/ collaboration-vs-cooperation and https://resourced. prometheanworld.com/collaborative-cooperative-learning/. Status-sharing involves the sharing of perception data for the potential use by receiving vehicles [4]. Vehicle A sending camera information informing vehicle B of a pedestrian’s location outside its’ field of view would allow for vehicle B to use this information and move forward cautiously, now aware of an occluded road user. With intent-sharing, information about a vehicle’s planned actions can be shared with another vehicle, once again allowing the receiving vehicle to plan/act accordingly [4]. For example, after approaching an intersection, vehicle A, the lead vehicle, broadcasts its intent to turn left and the following vehicle, vehicle B, receives this intent, adjusting its speed and trajectory accordingly to avoid a collision. Agreement-seeking involves a number of messages being sent among cooperative vehicles with the intention of planning actions [4]. For example, when two vehicles approach a narrow bridge from opposite directions, the vehicles exchange information (e.g., speed, trajectory, intended actions), which is then used to negotiate a mutually agreed upon plan, ensuring that both vehicles cross the bridge safely and efficiently. Prescriptive cooperation involves a road operator (e.g., a transportation authority) providing instructions to specific traffic participants, who then perform the specified command without need for agreement [4]. An example related to incident scene management could involve emergency vehicles communicating temporary road closures, requiring adjustments from nearby AVs. It should be noted that SAE J3216 includes fleet operations in this category. With our taxonomy including collaborative classes, most use cases for fleet operations would fit better in the category collaborativeorchestrated described in the next section. 3) collaborative classes While cooperative vehicles work together in order to help each other achieve their own individual goals, collaborative vehicles – in addition to having their own strategic goals – also work towards achieving a shared goal, known as the common strategic goal. This typically requires high levels of coordination among all constituents. Table 9 shows 3 types of architectural patterns which fall under the category of collaborative AVS – coordinated, choreographed and orchestrated. Coordinated collaborative AVs involve vehicles or machines engaged in specific tasks and communicating with each other during these tasks to achieve the common strategic goal. Consider a simple system that consists of two machines, a loader and a truck. The loader’s individual strategic goal is to remove material from its current location (location A) and deposit this load into the truck stationed next to it. As for the truck, it must remain stationary until a certain weight load has been met. Once this happens, the truck signals to the loader that it can take no further weight and the loader halts. The truck drives to another location (location B) where the material is then deposited. The truck then returns to location A, signals it’s return to the digger, and the cycle continues. Both the loader and truck have their own strategic goals (i.e., digging up/depositing material and moving the material), though they must work in tandem – communicating in a coordinated manner– to achieve the shared goal of removing and relocating the material from one area to another, as neither machine is able to independently accomplish this goal on its own. Choreographed collaborative AVs refer to a group of vehicles that work together in a predetermined sequence, with each vehicle having its own defined role, rather than communicating to coordinate their actions. Together, they are able to achieve a shared goal. If the digger and truck in the example above did not use communication to signal each other but the system was rather designed so that each vehicle has its own way of determining when to proceed, the system would be choreographed. E.g., the truck could be designed to automatically leave when loaded above a certain weight, while the digger could be designed to continue filling trucks as long as they are parked in the digger area of operation. Orchestrated collaborative AVs involve multiple machines or vehicles that are managed and directed by a central entity to achieve a common strategic goal. In this scenario, each individual vehicle has limited autonomy and the central authority has complete control over all constituents’ actions. An example of this could be a fleet of autonomous taxis that are directed by a central authority ensuring route optimisation, safety and reduced emissions. It should be noted that some functions may be classified differently depending on application and specific implementation. For instance, platooning could be classified as collaborative if consisting of a fleet with the same destination collaborating with a joint task, or cooperative if the platoon is constituted temporarily on a highway for mutual benefit, but the objectives and destinations of the constituents differ. b. human-system dimension revisited In this section, we define a taxonomy for the humansystem dimension, or classification of level of automation with respect to the involvement of a human user. We use a classification similar to Koopman [11], with the main difference that the automation is not meant to include only the driving task, as many types of machines have other aspects of the operation automated, which is integral to its use and also safety-critical. Our updated definitions are presented in Table 10. iv. conclusion This paper presents a unified taxonomy for AVs, including individual, cooperative, collaborative, on-road, and off-road vehicles. 