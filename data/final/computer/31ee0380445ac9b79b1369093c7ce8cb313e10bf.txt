3D object recognition has successfully become an appealing research topic in the real-world. However, most existing recognition models unreasonably assume that the categories of 3D objects cannot change over time in the real-world. This unrealistic assumption may result in significant performance degradation for them to learn new classes of 3D objects consecutively, due to the catastrophic forgetting on old learned classes. Moreover, they cannot explore which 3D geometric characteristics are essential to alleviate the catastrophic forgetting on old classes of 3D objects. To tackle the above challenges, we develop a novel Incremental 3D Object Recognition Network (i.e., InOR-Net), which could recognize new classes of 3D objects continuously via overcoming the catastrophic forgetting on old classes. Specifically, a category-guided geometric reasoning is proposed to reason local geometric structures with distinctive 3D characteristics of each class by leveraging intrinsic category information. We then propose a novel critic-induced geometric attention mechanism to distinguish which 3D geometric characteristics within each class are beneficial to overcome the catastrophic forgetting on old classes of 3D objects, while preventing the negative influence of useless 3D characteristics. In addition, a dual adaptive fairness compensations strategy is designed to overcome the forgetting brought by class imbalance, by compensating biased weights and predictions of the classifier. Comparison experiments verify the state-of-the-art performance of the proposed InOR-Net model on several public point cloud datasets. ii. related work A. 3D Object Recognition
There are many shape descriptors [6], [9] to characterize point cloud representation, but they are usually invariant to different transformations, thus the recognition task on different 3D classes cannot perform well. When Qi et al. propose to apply convolutional neural network (i.e., PointNet [5]) on point cloud data, deep learning based methods have achieved remarkable successes in 3D object recognition. For instance, PointNet++ [6], an extension version of PointNet [5], could encode hierarchical local structures of point clouds with increasing contextual scales. In addition, some permutationrobust networks [7], [19] are proposed to explore the spatiallylocal relations in the orderless point cloud data. Wu et al. [19] develop a point-to-node neighbor search mechanism to encode point cloud. Yan et al. [9] propose to eliminate the effect of outliers via an adaptive sampling. Unfortunately, the above methods suffer from large performance degradation in the real-world where the data of new 3D categories are collected consecutively. b. class-incremental learning According to the methods with access to nothing, generated data or original data (i.e., exemplars) from the old classes, we divide the extensive studies about class-incremental learning [11], [16], [20], [21] on 2D image classification [22] into three categories. For example, when the training data of old classes is unavailable, [11], [23] propose the distillation strategy [24] to overcome the catastrophic forgetting on old classes. Yang et al. [17] propose a consecutive updating mechanism for concept drift detection. Leo et al. [25] develop a classification confidence threshold to selectively finetune neural network for anti-forgetting. Wei et al. [26] focus on exploring classdisentangled representations to tackle forgetting on old classes. Yu et al. [27] introduce a self-training strategy to perform continual semantic segmentation tasks with limited forgetting. [28] designs one unified framework to address continual new classes with efficient training of model parameters. Kirkpatrick et al. [29] introduce new regulators to restrict the model’s
optimization caused by new classes, which maintains its memory for old classes. In addition, different kinds of generative adversarial networks [30] are utilized by [20], [31] to produce synthetic samples for old categories. For the exemplar replay, there are usually a small quantity of exemplars available for each old category [12]. In this case, class imbalance becomes a serious challenge [15], [32]. Belouadah et al. [33] provide a memory with negligible storage cost to store statistical information of old categories. With the training data of new categories arriving, [34] proposes to expand the neural network in a progressive manner. To address the large-scale class-incremental learning, Wu et al. [16] focus on correcting the deviation of new categories within the classifier network. A random path selection strategy is proposed by Rajasegaran et al. [35] to choose optimal information flow for new tasks. Simon et al. [36] ameliorate the knowledge distillation technology, and measure the similarity between previous and current responses via geodesic path. Hu et al. [37] aim to explore the causal effect between the old and new categories. However, due to the noisy permutations, missing structures and irregularity of point cloud, these methods [26]–[28], [36], [37] cannot effectively distinguish which 3D geometric characteristics within each class are beneficial to prevent catastrophic forgetting on old class of 3D objects. iii. the proposed model  a. problem definition and overview Problem Definition: For the experimental configurations about 3D class-incremental learning, we follow the standard settings widely-used in 2D field [12], [15], [16], [35]–[37]. Specifically, we define the streaming training data including total S incremental states as D = {D1, D2, · · · , DS}. In the s-th (s = 1, 2, · · · , S) incremental state, the training subset Ds = {xsi , ysi } ns i=1 consists of ns point clouds, where xsi ∈ RU×3 is the i-th point cloud including U sampled three-dimension points, and ysi represents its one-hot category label. The labels {ysi } ns i=1 include Ks new classes in the s-th
incremental state. They cannot overlap with Kp = ∑s−1 i=1 Ki old classes that are learned in previous s − 1 incremental states. The training subset {Di}Si=1 with different new classes arrives consecutively in this paper. Similar to [12], [15], [16], [35]–[37], we select a small quantity of samples from Kp old classes of 3D objects to construct the exemplar set M . With access to the subset Ds and the selected exemplar set M , the prediction task is to classify both Kp old categories and Ks new categories in the s-th state. The number of exemplars from M is small (i.e., |M |/Kp ns/Ks) in our experiments. Overview: The graphical pipeline of our InOR-Net model is depicted in Fig. 1. First, we forward the 3D object from Ds ∪M into the encoder E(·) to extract its low-level feature. Subsequently, the extracted feature is fed into the categoryguided geometric reasoning to capture distinctive 3D geometric characterizations within each class under the guidance of category information, and then we obtain its mid-level feature fm via optimizing Lcst. Afterwards, fm is forwarded into the critic-induced geometric attention to evaluate which 3D geometric characteristics are beneficial to overcome catastrophic
forgetting on old classes of 3D objects, while filtering out the useless geometric information via optimizing Lcri and Lreg. We apply max-pooling function to fp with geometric attention and get a global feature fg , which is then passed into the classifier C(·) to make predictions via minimizing Lclc. Moreover, the dual adaptive fairness compensations could further compensate biased weights of the classifier and biased score predictions that are brought by class imbalance between old and new categories. Our InOR-Net model could alleviate the forgetting on old classes via remembering their distinctive 3D geometric characterizations. b. category-guided geometric reasoning Generally, each point cloud can be characterized by L local geometric structures, which correspond to L point subsets{ Pl|Pl = {p̂l, pl1, pl2, · · · , plm ∈ R3} }L l=1
in the point cloud. p̂l is the centroid of the l-th local geometric structure Pl, and {pl1, pl2, · · · , plm} are m nearest neighbor points surrounding around p̂l. Obviously, p̂l determines the location of the l-th local geometric structure Pl and its m nearest neighbor points. To capture local context information, most existing researches [6], [7] utilize the random sampling or farthest point sampling strategy to select the centroids for local geometric structures {Pl}Ll=1. Though these researches guarantee that the selected centroids fully consider the entire point cloud, they cannot cover the local structures with distinctive 3D characteristics (e.g., the tail in airplane, the geometric layout in chair, etc.) that are more effective to characterize the point cloud. Moreover, they aim to explore distinctive 3D characteristics from an object, but cannot make sure that the local structures within each object can capture the discriminative category information. For example, there are many types of chairs in the real-world, which not only share the common structure layout among all kinds of chairs, but also have unique properties for each kind of chairs. However, the existing works [6], [7] focus on exploring the unique properties within each chair, while neglecting the discriminative category information (e.g., common structure layout) to distinguish the chair and other similar categories (e.g., desk, table, etc). Due to the above limitations, the performance of [6], [7] severely suffers from the noisy points (i.e., noisy local structures). To address these limitations, as shown in Fig. 1, we develop the category-guided geometric reasoning, which captures local structures with distinctive 3D characteristics by considering category information over all point cloud data rather than only an object. Intuitively, for 3D class-incremental learning, these distinctive 3D geometric characteristics within each class are essential to alleviate catastrophic forgetting on old classes. To this end, we first present how to adaptively construct L local geometric structures {Pl}Ll=1, and then consider semantic category information as guidance (i.e., category-guided reasoning) to capture distinctive 3D geometric characteristics. • Local Geometric Structures Construction: [6], [7] ini-
tialize the locations of L local geometric structures via farthest point sampling, and utilize the fixed centroids of local geometric structures to encode semantic context. Different from them, we adaptively modify the centroids of local structures (i.e., the
geometric offset prediction) as the training process. Compared with deformable convolution [38] using semantic features of 2D images for offset prediction, we employ the edge vectors of each local geometric structure as reference to learn geometric offset of the centroid via network itself [18], [39]. To be specific, we first quantify the semantic context of each edge as the contribution weight, and then integrate the weighted edge vectors of local geometric structures together to achieve offset prediction of the centroid. In other words, for each local geometric structure, the voting strategy of surrounding edge vectors with different contributions determines the centroid offset. Thus, given the l-th local geometric structure Pl constructed via farthest point sampling [6], [7], the geometric offset 4p̂l of p̂l is formulated as:
4p̂l = 1
m m∑ i=1 ( Γo((f̂l − fli); θΓo) · (p̂l − pli) ) , (1)
where Γo(·) transforms the semantic knowledge of edge vectors to scale contribution weights via a convolution layer, and θΓo denotes its parameters. (p̂l − pli) represents the ith local edge vector. f̂l ∈ Rdp and {fli ∈ Rdp}mi=1 are the semantic features of p̂l and its m nearest neighbors {pli}mi=1, respectively. dp is the feature dimension of {fli}mi=1 that are extracted via the encoder E(·), as shown in Fig. 1. To update the l-th local geometric structure, we add the offset vector 4p̂l in Eq. (1) to the original centroid p̂l, and reselect m nearest neighbors {pl1, pl2, · · · , plm} surrounding around the new centroid p̂l:
p̂l = p̂l +4p̂l, {pl1, pl2, · · · , plm} = knn(p̂l|pj ∈ R3, j = 1, · · · , U), (2)
where knn(·) [40], [41] is employed to search m nearest neighbors around the new p̂l by traversing the whole point cloud {pj}Uj=1. U is the number of points sampled from a point cloud, and we follow [5] to set U = 1024 in this paper. The semantic representation fsl ∈ Rds of the l-th local
geometric structure can then be determined by encoding the representations of m nearest neighbor points:
fsl = max i=1,2,··· ,m Γs(fli; θΓs), (3)
where {fli}mi=1 denote the representations of m nearest neighbor points around the updated p̂l. ds is the feature dimension of fsl ∈ Rds that is encoded via Γs(·). Γs(·) is a convolutional layer encoding the representations of all nearest neighbor points, and its parameters are denoted as θΓs . Thus, the features {fsl ∈ Rds}Ll=1 of L local geometric structures in each point cloud can be obtained via Eq. (3). Inspired by [6], we concatenate {fsl }Ll=1 of local geometric structures as fm ∈ RL×ds , and regard it as the low-level representations over the whole point cloud. • Category-Guided Reasoning: To further help the lo-
cal geometric structures capture distinctive 3D characteristics within each class, we employ the global category-wise prototypes as guidance, and perform a self-supervised semantic consistency between local structures and category-wise prototypes for category-guided reasoning. To this end, as shown in Fig. 1, we perform the max-pooling operation on lowlevel representations with geometric attention (i.e., fp), and obtain its global feature fg ∈ Rds for the whole point cloud. Given a mini-batch TB = {xsi , ysi }Bi=1(B ns) with B point clouds sampled from the s-th incremental state, the estimated category-wise prototype f̂kg of the k-th category is formulated as the mean feature of all global representations belonging to the k-th category (k = 1, 2, · · · ,Ks +Kp) in TB :
f̂kg = E(xsi ,ysi )∈TB [ 1
Nt B∑ i=1 fgi · 1arg max ysi =k], (4)
where Nt = ∑B i=1 1arg max ysi =k denotes the number of point clouds belonging to the k-th class. fgi ∈ Rds is the i-th point cloud’s global representation. To eliminate the sampling
randomness of mini-batch, we construct global category-wise prototype fkg for the k-th class via an exponential update:
fkg = γf k g + (1− γ)f̂kg , (5)
where γ = 0.7 is the balanced weight. The local representations {fsl ∈ Rds}Ll=1 and global category-wise prototypes {fkg ∈ Rds} Ks+Kp k=1 may have some semantic heterogeneity [42]–[44], so we employ convolutional networks Γes(·) and Γeg(·) to embed them into a semanticshared feature space. When the input point cloud belongs to the k-th class, we enforce the embedded representations {Γes(fsl ; θΓes) ∈ Rdc}Ll=1 of local geometric structures to be closer to the embedded global category-wise prototype Γeg(f k g ; θΓeg ) ∈ Rdc of the k-th class, while maximizing their dissimilarity with other embedded global prototypes {Γeg(f ig, θΓeg ) ∈ Rdc |i 6= k} Ks+Kp i=1 via optimizing Lcst:
Llcst = log ( 1 + ∑ i 6=k exp ( τN (Γes(fsl ; θΓes))>N (Γeg(f ig; θΓeg ))
− τN (Γes(fsl ; θΓes))>N (Γeg(fkg ; θΓeg )) )) ,
Lcst = E(xsi ,ysi )∈Ds∪M ∑L l=1 Llcst, (6)
where θΓeg and θΓes denote the network parameters. dc is the feature dimension of embedding space. N (x) = x−mean(x)‖x‖ represents a `2 normalization function, and mean(x) denotes the mean value of x. Before performing a self-supervised semantic consistency metric via Eq. (6), we first normalize the embedded representations Γes(fsl ; θΓes) and Γeg(f k g ; θΓeg ) via `2 normalization function N (·), and then utilize a scale value τ = 64 to re-scale the embedded representations. Existing works [45], [46] have shown the re-scaling strategy could stabilize the training process and make 3D characteristics within each class more discriminative. Intuitively, when minimizing Eq. (6), we enforce local geometric structures to explore unique 3D characteristics within each class, while neglecting the properties common with other classes. These distinctive 3D characteristics are essential to alleviate forgetting on old classes of 3D objects. c. critic-induced geometric attention Although the category-guided geometric reasoning could construct L discriminative local geometric structures to capture distinctive 3D characteristics, these characteristics contributes unequally to address the catastrophic forgetting on old classes. That is to say, some local geometric structures containing more common 3D characteristics may strengthen the forgetting, while the others with more distinctive 3D characteristics would alleviate the forgetting. To address this issue, as presented in Fig. 1, we develop the critic-induced geometric attention to emphasize unique 3D geometric characteristics within each class, while mitigating the forgetting caused by common 3D properties. Specifically, we first use the geometric attention network Γa(·) to calibrate the contributions of local geometric structures {Pl}Ll=1, and further introduce the critical supervision network Γc(·) as guidance to evaluate the quality of the contributions quantified via Γa(·). Γc(·) can provide positive
supervision to guide Γa(·) maximize the contribution gain, even though misleading quantification of Γa(·) appears. • Geometric Attention Network Γa(·): According to the vanilla attention strategy [47] in image understanding, we introduce a residual learning to the geometric attention network Γa(·). It can calibrate the weights of different geometric structures. Therefore, we obtain the final low-level semantic representation fp ∈ RL×ds via the attention mechanism:
fp = Am fm + fm = ψs ( Γu(ψr(Γd(fm; θΓd)); θΓu) ) fm + fm, (7)
where Am = ψs ( Γu(ψr(Γd(fm; θΓd)); θΓu) ) ∈ RL×ds represents the geometric attention (a.k.a. the contributions of local geometric structures). is the Hadamard product. ψs(·) and ψr(·) are the sigmoid and ReLU functions. Γu(·) and Γd(·) denote the channel-upscaling and channel-downscaling layers with the ratio as r = 4. θΓu and θΓd are their weights, which are both denoted as the parameters θΓa of Γa(·) for simplification. As shown in Fig. 1, we then perform maxpooling on fp to extract global feature fg ∈ Rds , and forward it into C(·) for object recognition. • Critical Supervision Network Γc(·): As aforementioned, Γc(·) focuses on maximizing the gain of geometric attention Am over the basic network via a task reward strategy. To this end, as depicted in Fig. 1, the critical supervision network Γc(·) takes both fp and Am as the inputs. It contains two branches, i.e., a state branch with a convolutional block, a flatten operation and two fully-connected layers to extract semantic context from fp; and a policy branch with a convolutional block, a flatten operation and a fully-connected layer to encode quantified contribution Am. Afterwards, the outputs of both state and policy branches are concatenated together, and are fed into a fully-connected layer to obtain a scalar gain Vcri = Γc(fp,Am; θΓc), where θΓc is the network weights. Two losses (i.e., the critic loss Lcri and regression loss Lreg) are designed to maximize the gain with positive guidance. 1. Critic Loss Lcri: For training the geometric attention network Γa(·), the critic loss Lcri is proposed to maximize the scalar gain value Vcri with respect to the geometric attention Am (i.e., minimizing Lcri in Eq. (8)):
Lcri = Efp∈Ds∪M [−Vcri] = Efp∈Ds∪M [−Γc(fp,Am; θΓc)]. (8)
Intuitively, Lcri encourages Γc(·) to highlight the local geometric structures with higher contribution scores. It maximizes the positive gain by generating higher gain value Vcri. 2. Regression Loss Lreg: The regression loss Lreg is designed to guide Γc(·) feedback accurate supervision for Γa(·) via a new reward R. Specifically, R is composed of a classification reward Rc and an amelioration reward Ra, i.e., R = Rc + Ra. Rc measures whether the geometric attention Am learned via Γa(·) leads to correct prediction, which is formulated as follows:
Rc =
{ 1, if arg maxC(fg; θC) = arg max y,
0, otherwise, (9)
where θC denotes the parameters of classifier C(·), and C(fg; θC) is the probability outputs of global feature fg with
Algorithm 1 Training Pipeline of Our InOR-Net Model. 1: Input: The subset Ds = {xsi , ysi } ns i=1 including the data
of new categories, the exemplar set M , and {λ1, λ2}. 2: Initialize: {θE , θC , θΓc , θΓa}; 3: While not converged do 4: Construct a mini-batch TB = {xsi , ysi }Bi=1 from Ds∪M ; 5: Update {θE , θC} via minimizing Lclc + λ2Lcst; 6: Update θΓa via minimizing Lclc + λ1Lcri + λ2Lcst; 7: Update θΓc via minimizing Lreg; 8: End 9: Store statistical information to compensate the biased
predictions via Eq. (13) in the inference phase; 10: Return {θE , θC , θΓc , θΓa};
the geometric attention Am. y ∈ Ds ∪ M is the one-hot groundtruth of the input point cloud. Moreover, the amelioration reward Ra examines whether Am learned via Γa(·) facilitates the positive prediction, where Ra is defined as:
Ra =
{ 1, if C(fg; θC) k>C(fg′ ; θC) k, k = arg max y
0, otherwise, (10)
where C(fg; θC)k and C(fg′ ; θC)k respectively represent the k-th category probability predicted by the classifier C(·) with geometric attention Am or not. Here, fg′ can be obtained when we directly perform max-pooling operation on fm without using Am. We then develop a reward regression loss Lreg to guide Γc(·) feedback accurate supervision. Lreg aims to minimize the gap between the estimated scalar gain Vcri and defined reward R:
Lreg = Efp∈Ds∪M [ (Vcri −R)2], (11)
where Vcri = Γc(fp,Am; θΓc), and R = Rc +Ra. d. dual adaptive fairness compensations Although the above modules can explore distinctive 3D characteristics within local geometric structures for each class, the classifier C(·) is easily prone to forget the old classes since there is a severe class imbalance issue between old and new categories of 3D objects (|M | ns). To address this issue, most 2D researches [12], [15], [16], [35] propose to pay more attention on old classes via the knowledge distillation strategy. However, they cannot prevent the fully-connected layers of classifier C(·) from being highly biased, thus strengthening the forgetting on old classes. The classifier C(·) often predicts well on new classes with a large number of 3D objects, while performing badly on old classes without abundant data. To overcome above issues, the dual adaptive fairness compensations strategy is designed to correct prediction bias among the old and new categories of 3D objects. It consists of a weight fairness compensation to correct the biased weights of classifier C(·) in the training phase, and a score fairness compensation to balance the biased predictions on new 3D categories in the test phase. • Weight Fairness Compensation: Denote the weight W l of the last fully-connected layer in the classifier C(·) as W l = [W lold,W l new] ∈ Rdw×(Kp+Ks), where Kp and
Chair Bed Monitor Bathtub Lamp Table
Ks respectively denote the numbers of old and new categories, and dw is the input feature dimension of last fullyconnected layer in C(·). The weight matrices W lold and W lnew are defined as W lold = [w1, w2, · · · , wKp ] ∈ Rdw×Kp and W lnew = [wKp+1, wKp+2, · · · , wKp+Ks ] ∈ Rdw×Ks . The corresponding norms of the weight matrices W lold and W l new are written as Nold = [||w1||, ||w2||, · · · , ||wKp ||] ∈ RKp and Nnew = [||wKp+1||, ||wKp+2||, · · · , ||wKp+Ks ||] ∈ RKs . Therefore, the normalized weight matrix W̃ lnew for new classes of 3D objects is formulated as W̃ lnew = mean(Nold) mean(Nnew)
·W lnew. After applying weight fairness compensation, the corrected weight W̃ l of the last fully-connected layer is:
W̃ l = [W lold, W̃ l new] = [W l old,
mean(Nold) mean(Nnew) ·W lnew]. (12)
Intuitively, Eq. (12) encourages the average norm of W lnew from new 3D classes to approximate W lold from old classes. Such design guarantees the prediction fairness among the old and new categories by adaptively adjusting the probabilities of new classes with mean(Nold)mean(Nnew) . Moreover, it can cooperate with the aforementioned critic network Γc(·) together to effectively address the catastrophic forgetting on old classes. • Score Fairness Compensation: In addition to the biased classifier C(·) in the training phase, the biased predictions during the inference phase are also non-negligible. To address this concern, we leverage the statistical information of old classes during the training phase to modify the prediction
scores of new categories in the inference phase [18], [33]. When adequate 3D objects of old classes are available, the predictions for them are more reliable. Thus, we record their initial statistical information for rectification when the old classes are initially learned in each incremental state. Then the rectified probability Cs(fg; θC)k of the k-th category is written as:
Cs(fg; θC) k = C(fg; θC)k · ψsi(k) ψs(k) · ψ(s) ψ(si) , if new category,
C(fg; θC) k, otherwise,
(13)
where ψsi(k) and ψs(k) respectively represent the mean scores classified as the k-th categories in the initial si-th state and the current s-th state. Here, the initial si-th state indicates that all 3D objects of the k-th category are available. ψ(si) and ψ(s) denote the average scores of new categories in the si-th and s-th incremental states. We need to mention that only if the given 3D objects are initially predicted as the new classes, Eq. (13) applies rectification to their predicted scores. Intuitively, Eq. (13) can guarantee the test fairness among the old and new categories of 3D objects by adaptively adjusting the probabilities of new classes with ψsi (k)ψs(k) · ψ(s) ψ(si) in the inference phase. E. Implementation Details For the network configuration, as shown in Table I, we
provide the detailed architecture description of the proposed InOR-Net model. Specifically, we use PointNet [5] as the encoder E(·) to extract the low-level representations of point clouds, and employ a four-layer fully-connected network as the classifier C(·). The channels of C(·) are set as {1024, 512, 256,number of classes} in this paper. The Adam optimizer with the initial learning rate as 0.001 is utilized to optimize our model, and its weight decay is set as 0.0005. The proposed InOR-Net model is implemented via PyTorch, and we follow the parameter initialization manner1 proposed
1https://github.com/fxia22/pointnet.pytorch
in [5] to initialize our model. In Section III-B, we empirically set the number of local geometric structures as L = 64 via conducting the parameter experiments in Section IV-F. The mini-batch size TB is set as 64 for all benchmark datasets. Inspired by [36], we utilize the similar method (i.e., herding strategy) to select the exemplar set M . Overall, the formulation Lobj of our InOR-Net model is written as follows:
Lobj = Lclc + Lreg + λ1Lcri + λ2Lcst, (14) where Lclc =E(xsi ,ysi )∈Ds∪M [− ∑Kp+Ks k=1 (y s i ) klog(C(fg; θC)
k)] is the cross-entropy loss for classification. λ1, λ2 ≥ 0 are the balanced weights, which are empirically set as λ1 = 0.01, λ2 = 0.1. We also summarize the optimization procedure of our InOR-Net model, as shown in Algorithm 1. Inference: For performance evaluation, we directly forward the 3D object into the encoder E(·) to extract fm via categoryguided geometric reasoning, and obtain fp via geometric attention network Γa(·). After performing max-pooling on fp, we get the global feature fg , and forward it into the classifier C(·) to compute softmax probabilities that are rectified via Eq. (13) for the final 3D object recognition. iv. experiments  a. datasets and evaluation metric • ShapeNet [48] is composed of 35037 CAD samples for training and 5053 CAD samples for validation, which are collected from online repositories. We use 53 categories in the comparison experiments, and select 1000 CAD samples to be stored in the exemplar set M . The total incremental states S is set as 9, and each incremental state has an increment of six classes, except for the last one with five new classes. •ModelNet [49] with 40 different CAD categories contains
9843 samples for training and 2468 samples for evaluation. All CAD samples are clean models. The exemplar set M stores 800 CAD samples. We define the total incremental states S as 10, and each incremental state will collect four new classes. • ScanNet [50] consists of 17 different classes collected
from the scanned and reconstructed scenes. When compared
with ShapeNet [48] and ModelNet [48], it is a more challenging dataset due to many noisy geometric structures. The training and test sets respectively have 12060 and 3416 samples. We store 600 CAD samples in the exemplar set M , and define total incremental states S = 9, where each incremental state has an increment of two classes, except for the last one with only one incremental class. Moreover, some example samples of three benchmark datasets are visualized in Fig. 2. As for the selection of exemplar set M and incremental states S, we follow the standard settings of class-incremental learning proposed in [12], [15], [16], [35]–[37], and utilize the same experimental settings to compare with other stateof-the-art baseline methods for fair comparisons. Specifically, considering the number of 3D object classes in each incremental state, we select the number of total incremental states to be around 10 for more new categories in each incremental task, while ensuring that the number of incremental states S is as large as possible. Besides, the number of exemplars from M satisfies |M |/Kp ns/Ks, and we empirically set the
number of M as 1000, 800, 600 for ShapeNet [48], ModelNet [49] and ScanNet [50] respectively. Evaluation Metric: Following other baseline methods [12], [16], [18], [37], we utilize the top-1 accuracy [52], [53] as the evaluation metric to conduct comparison experiments. b. comparison experiments The comparison experiments on ShapeNet [48], ModelNet [49], ScanNet [50] are shown in Tables II, III and IV. For a fair comparison, all baseline methods utilize PointNet [5] to obtain local feature of point cloud, and are trained with the same data augmentation mechanism in [5]. According to the results, we observe our InOR-Net model outperforms the conference version I3DOL [18] about 1.7% ∼ 2.1% (average accuracy) on three benchmark datasets. The substantial extensions about exploring 3D geometric characteristics and alleviating catastrophic forgetting promote the object recognition ability of our InOR-Net model against the conference method [18]. Moreover, the average accuracy of Ours significantly outperforms
other comparison methods [11], [12], [15], [16], [20], [33], [35]–[37] by a large margin about 2.9% ∼ 26.7%. It illustrates that our model has more advantages than 2D methods in addressing 3D class-incremental learning. Specifically, when compared with them, our model is effective to explore distinctive 3D characteristics within each class under the category information as guidance via the category-guided geometric reasoning. Our InOR-Net model also considers different contributions of 3D characteristics to address the forgetting via critic-induced geometric attention. The recognition results of our InOR-Net model are better than knowledge distillation based approaches [12], [15], [16], [35]–[37], since the dual adaptive fairness compensations could effectively alleviate catastrophic forgetting by correcting prediction bias among old and new categories in the training and test stages. c. ablation studies To demonstrate the necessity of proposed modules in our InOR-Net model, we introduce detailed ablation studies on three benchmark datasets, as shown in Tables II, III and IV. Ours-w/oCGR, Ours-w/oCGA, Ours-w/oWFC and Oursw/oSFC represent the performance of our model without using the category-guided geometric reasoning (CGR), criticinduced geometric attention (CGA), weight fairness compensation (WFC) and score fairness compensation (SFC). Tables II, III and IV show that the average accuracy degrades 1.2% ∼ 3.9% when any component of our model is absent. It verifies that the proposed modules cooperate well to
address 3D class-incremental learning. Specifically, the lack of dual adaptive fairness compensations causes the degradation about 1.2% ∼ 2.2% average accuracy, which validates the effectiveness to alleviate the forgetting via correcting the prediction bias. When removing the category-guided geometric reasoning, the average accuracy of our model decreases 3.5% ∼ 3.9%. The worse performance explains its importance to explore unique 3D characteristics within each class. Oursw/oCGA performs worse than Ours about 2.6% ∼ 3.0%. It validates the effectiveness of critic-induced geometric attention to highlight distinctive 3D characteristics. d. qualitative analysis of exemplar set This section investigates the effect of exemplar set M on model performance. As depicted in Fig. 3, we present comparison experiments on benchmark datasets when setting different sizes of the exemplar set M . Specifically, we set the sample number of M as {800, 1200}, {600, 1000} and {400, 800} for ShapeNet [48], ModelNet [49] and ScanNet [50] datasets respectively. According to Fig. 3, we can observe that our model still outperforms all comparison baselines when setting a small sample number of exemplar set M , which further validates the superiority of our model. This observation also illustrates the effectiveness of our model against other comparison methods, when addressing the forgetting on old classes of 3D objects. Moreover, training our model with more exemplars significantly facilitates to alleviate the catastrophic
forgetting by exploring distinctive 3D geometric characteristics and addressing the class imbalance. e. qualitative analysis of incremental states As depicted in Fig. 4, we introduce the comparison ex-
periments between our model and other baseline methods on benchmark datasets, when setting different incremental states S with Tables II, III and IV. From the depicted curves in Fig. 4, we observe that all comparison methods perform worse than Ours, even though each incremental state has more new 3D classes. It validates the generalization of our model to alleviate the catastrophic forgetting under different experimental configurations. Compared with the conference version I3DOL [18], our model could effectively quantify the contributions of distinctive 3D characteristics within each class via the critic-induced geometric attention, and address the forgetting caused by class imbalance via the dual adaptive fairness compensations. These substantial extensions lead to the performance improvements of our model. Besides, the recognition results of our model are significantly better than other 2D baseline approaches [15], [20], [33], [35]–[37], since the category-guided geometric reasoning captures distinctive 3D properties within each class via using category information as learning guidance. f. qualitative analysis of parameters {λ1, λ2, l} This subsection presents the parameter experiments about
λ1, λ2 in Eq. (14) and L in Section III-B on three benchmark
datasets, by tuning them in range of {1× 10−4, 1× 10−3, 1× 10−2, 1 × 10−1, 1} and {16, 32, 48, 64, 80}, respectively. As shown in Fig. 5, when we set λ1 = 0.01, λ2 = 0.1, L = 64, our model achieves the optimal average accuracy, and we utilize these parameter values in comparison experiments. Fig. 5 also shows the performance of our model has great stability even though {λ1, λ2, L} have a wide selection range. Furthermore, when L = 64 and fixing other parameters {λ1, λ2}, our model has the best performance on benchmark datasets. It validates each point cloud could be characterized well by 64 local geometric structures. Besides, the performance of our model degrades when setting an inappropriate value for L. It illustrates that more local geometric structures can bring more noise information, while less local geometric structures may lose some informative knowledge. Our model can capture unique 3D characteristics within each class via the category-guided geometric reasoning (i.e., λ2Lcst). λ1Lcri provides the positive supervision to guide Γa(·) maximize the gain of unique 3D characteristics via tuning the parameter λ1. g. convergence analysis We introduce the convergence investigation of our InOR-Net model in this subsection, as shown in Fig. 6. From the convergence curves, we can observe that when the number of training epoches is about 140, the accuracy performance of our InORNet model converges to a stable value on three benchmark datasets. Moreover, the stable performances across incremental states verify our model can recognize new categories of 3D
objects consecutively while tackling the forgetting on old categories. It also demonstrates that the proposed modules cooperate well to address 3D class-incremental learning. h. qualitative analysis of time and memory complexities As shown in Table V, we conduct time and computational parameters comparisons between our InOR-Net model and other approaches on ModelNet [49] under the same settings. The training time (h) denotes the averaged model convergence time (hour) across all incremental states, the test time (s) shows the inference time cost (second) of mini-batch data, and the #Parameters (M) represents computational network parameters of the model trained with TITAN XP GPU. As introduced in Table V, we conclude that our proposed InORNet model significantly outperforms [20], [36], [37], [51] by a large margin, and is comparable with [12], [15], [16], [18], [33], [35] in terms of training time, test time and network parameters. Our model sacrifices marginal computational time and parameters, but achieves significant performance improvement (see Tables II, III and IV) than competing approaches, which is acceptable in real-world applications. i. qualitative analysis of catastrophic forgetting In this subsection, we present the comparison experiments on ModelNet [49] dataset in terms of averaged F1 score and Recall across all incremental states to investigate catastrophic forgetting, as shown in Table VI. Our proposed model outperforms other baseline comparison methods [12], [15], [16], [18], [20], [33], [36], [37] about 2.3%∼19.7% in terms of averaged F1 score and Recall. This improvement validates the superiority of our InOR-Net model to identify new categories consecutively under a streaming manner. Moreover, it verifies
our model could perform well across all classes (both old and new classes) rather than only some specific classes, and also illustrates the effectiveness of our model to alleviate catastrophic forgetting on old classes. j. qualitative analysis of substantial improvement In order to show whether the improvement of our INOR-Net model compared with other baseline approaches is significant, we introduce the t-test experiments via five random runs in this subsection. When the p value of t-test is lower than 0.05, we consider the improvement of object recognition ability is significant. As presented in Table VII, the p value of Ours vs I3DOL [18] is much lower than 0.05, which validates that our InOR-Net model has a substantial improvement over the previous conference version I3DOL [18] on three benchmark datasets. In addition, we introduce t-test experiments between Ours and other baselines [16], [20], [33], [35]–[37]. The p values of these comparisons are significantly lower than 0.05, which supports the superior recognition results of our model to tackle catastrophic forgetting on old categories of 3D objects. v. conclusion and future work In this paper, we propose a novel Incremental 3D Object Recognition Network (InOR-Net) to recognize novel categories of 3D objects under a streaming manner, without the catastrophic forgetting on old 3D classes. Specifically, we focus on capturing the distinctive 3D characteristics within each class via a category-guided geometric reasoning, and identifying which 3D geometric characteristics are important to alleviate the forgetting on old classes of 3D objects via a critic-induced geometric attention. A dual adaptive fairness compensations strategy including both weights and prediction scores corrections is designed to tackle the forgetting brought by class imbalance problem. We verify the superior performance of the proposed InOR-Net model via extensive comparison experiments on representative point cloud datasets. The proposed model lacks some theoretical analysis to guarantee the convergence in the theory perspective, and may suffer from recognition performance degradation when the collected point cloud is heavily polluted by noise and loses some core geometric structures.