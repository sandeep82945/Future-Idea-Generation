Lyric translation plays a pivotal role in amplifying the global resonance of music, bridging cultural divides, and fostering universal connections. Translating lyrics, unlike conventional translation tasks, requires a delicate balance between singability and semantics. In this paper, we present a computational framework for the quantitative evaluation of singable lyric translation, which seamlessly integrates musical, linguistic, and cultural dimensions of lyrics. Our comprehensive framework consists of four metrics that measure syllable count distance, phoneme repetition similarity, musical structure distance, and semantic similarity. To substantiate the efficacy of our framework, we collected a singable lyrics dataset, which precisely aligns English, Japanese, and Korean lyrics on a line-by-line and sectionby-section basis, and conducted a comparative analysis between singable and non-singable lyrics. Our multidisciplinary approach provides insights into the key components that underlie the art of lyric translation and establishes a solid groundwork for the future of computational lyric translation assessment. 2. background Previous research indicates that linguistic analysis methods designed for standard text may not achieve desired outcomes when used to examine lyrics [9]. Although automated evaluation metrics, such as n-gram-based [10–12] or neural approaches [13], have proven valuable and effective in assessing conventional machine translation tasks, they
ar X
iv :2
30 8. 13 71
5v 1
[ cs
.C L
] 2
6 A
ug 2
02 3
fall short in evaluating lyric translation. This is due to the unique characteristics of lyrics that render the translation process subject to many constraints and less direct [14]. One of the most significant constraints is the syllable count. This is because the original and translated lyrics must match the same melody lines, while it is a common practice to tweak the melody to accommodate minor changes in syllable count [4, 15]. In fact, conveying the same message in different languages requires vastly different syllable counts. For example, “Happy New Year” in English consists of 4 syllables, whereas 15 and 9 are required for Japanese (あけましておめでとうございます) and Korean (새 해 복 많이 받으세요), respectively. For the numerical comparison, we examined PAWS-X, a dataset that contains 23,659 English sentences paired with human-translated sentences in various languages [16]. The average number of syllables per sentence in the dataset is 50.89 for Japanese, whereas 36.18 per English and 40.40 per Korean. With these statistics, it can be deduced that Japanese necessitates approximately 41% more syllables than English and 26% more syllables than Korean to express an equivalent message. This limitation forces translators to often modify the meaning of original lyrics by adding, omitting, or even tweaking the message. However, translated lyrics still aim to capture the theme, mood, and spirit of the original lyrics [17]. Therefore, while original and translated lyrics need not be semantically identical, they still need to be semantically relevant [4, 18]. It is also crucial to preserve the frequency of phoneme repetition (e.g., rhyme) in translated lyrics, particularly when the music demands it [17]. For instance, some sections, such as choruses, require a substantial degree of phoneme repetition, while others do not. Moreover, due to the inherent connection between lyrics and music, lyrics must be arranged in a way that complements the music [19]. As a result, musically similar sections should maintain resembling linguistic features, including the choice of phonemes and the frequency of phoneme repetition [20]. 3. dataset Although some websites provide user-translated multilingual lyrics, we found that most of them lack singability, as these translations were focused on delivering the meaning of the original lyrics rather than making them performable. While there are a few singable translations available, they are often not aligned on a line-by-line nor section-by-section basis due to the subjective nature of the lyric structure that there is no universal agreement on what to call a line and what to call a section. The absence of alignment makes it difficult to compare the original lyrics with their translated versions. To address this issue, we collected a set of singable lyrics, sourced from either official lyrics of commercial songs or user-translated ones found on YouTube, meticulously aligned on a line-by-line basis in English, Japanese, and Korean. This approach ensures that lyrics on the same line share the same melodies. Moreover, the dataset divides the lyrics into sections, allowing for section-by-section analysis. Alongside the lyrics, it
provides essential metadata such as genre, artist, original language, and the official status of lyrics. The dataset consists of 162 songs, each having lyrics in the three languages. It covers a diverse range of genres, including 109 K-pop, 23 animation music (e.g., Disney), 13 J-pop, 10 theatre music, and more. Table 1 shows sample data. 4. evaluating singability Our primary goal is to develop an evaluation framework that automatically assesses the quality of translated lyrics. One of the most important factors determining the quality is singability, defined as not only the ability of being sung, but also the suitability (easiness) of being sung [18]. To ensure such singability, we aim to provide metrics from three distinct perspectives by making sure that they i) maintain the song’s melodic integrity, ii) preserve the degree of phoneme repetition, and iii) consider the underlying musical structure. To substantiate the reliability of our evaluation metrics, we conducted a comparative analysis of singable lyrics versus non-singable lyrics based on each proposed evaluation metric. In all our comparative analyses, we utilized our dataset for singable lyrics, where official lyrics served as both source and target lyrics, and unofficial functioned as only target lyrics. For non-singable lyrics, we obtained pairs of original singable (source) and human-translated non-singable (target) lyrics, aligned line-wise and sectionwise, for 3,642 songs from https://lyricstranslate.com/. Section English Japanese (English translation) Korean (English translation) pho
E(A1), J(A1), K(A1) Do you wanna build a snowman? Come on, let’s go and play! I never see you anymore Come out the door It’s like you’ve gone away
雪だるま作ろう (Let’s build a snowman) ドアを開けて (Please open the door) 一緒に遊ぼう (Let’s play together) どうして (Why) 出てこないの? (don’t you come out?) 같이눈사람만들래? (Do you wanna build a snowman?) 제발좀나와봐 (Please come out) 언니를만날수없어 (I can’t meet you) 같이놀자 (Let’s play together) 나혼자심심해 (I’m lonely alone) 0.85, 0.73, 0.77
E(B1), J(B1), K(B1) We used to be best buddies And now we’re not I wish you would tell me why! 前は仲良く(We were close before) してたのに (We used to be) なぜ会えないの (Why can’t we meet each other?) 그렇게친했는데 (We were close before) 이젠아냐 (and we’re not) 그이유를알고파 (I want to know the reason why)
0.92, 0.80, 0.91
E(A2), J(A2), K(A2) Do you wanna build a snowman? Or ride our bike around the halls? I think some company is overdue I’ve started talking to the pictures on the walls! 雪だるま作ろう (Let’s build a snowman) 自転車に乗ろう(Let’s ride a bike) ずっと一人でいると (When I’m alone all the time) 壁の絵とおしゃべりしちゃう (I’m almost talking to the pictures on the walls) 같이눈사람만들래? (Do you wanna build a snowman?) 아니면자전거탈래? (or do you wanna ride a bike?) 이제는나도지쳐가나봐 (Seems I’m getting tired) 벽에다말을하며놀고있잖아 (because I’ve started talking to the walls) 0.79, 0.73, 0.82
E(B2), J(B2), K(B2) It gets a little lonely All these empty rooms Just watching the hours tick by
さびしい部屋で (In a lonely room) 柱時計 (the wall clock) 見てたりするの (I look at or something)
사실은조금외로워 (In fact, I’m a little lonely) 텅빈방에선 (In empty rooms) 시계소리만들려 (All I can hear is the clock’s ticking) 0.90, 0.88, 0.96
Table 3. Lyric excerpt from “Do You Want to Build a Snowman” from the animation “Frozen,” singable in all languages. Sections A1 and A2 form a musically similar pair, while B1 and B2 are also musically similar to each other. Each section is denoted as E(A1), . . . , E(B2) in English, J(A1), . . . , J(B2) in Japanese, and K(A1), . . . ,K(B2) in Korean. 4.1 line syllable count distance It is crucial to preserve the syllable counts between the original and translated lyrics for each line as similar as possible in order to maintain the integrity of a song’s melody [21]. Therefore, it is unsurprising that our evaluation framework incorporates a metric to assess the differences in syllable counts. Let the line syllable counts for a pair of lyrics that consist of n lines, X = {x1, ..., xn} and X̃ = {x̃1, ..., x̃n} be denoted as {syl(x1), ..., syl(xn)} and {syl(x̃1), ..., syl(x̃n)} where each element refers to the syllable count of each line. For instance, if the first line of the English lyrics X is “Silent night holy night” and the corresponding line in the Korean lyrics X̃ is “Goyohanbam-georukhanbam (고요한밤거룩한밤)”, the value of syl(x1) is 6 and syl(x̃1) is 8. We define the line syllable count distance between a pair of lyrics X and X̃ (Dissyl(X, X̃)) in order to evaluate the disparities in syllable counts, as follows. Dissyl(X, X̃) = 1 2n ∑n i=1( |syl(xi)−syl(x̃i)| syl(xi) + |syl(xi)−syl(x̃i)|syl(x̃i) ) (1) We compare the line syllable count distance of singable and non-singable lyrics. As shown in Table 2, non-singable lyrics display a considerably greater Dissyl(X, X̃) compared to singable lyrics due to the varying syllable count requirements across languages. 4.2 phoneme repetition similarity Rhyme, defined as the repetition of a vowel sound and any subsequent sounds [22], has historically been a fundamental element in the realm of poetry, including in Western languages like English. However, the concept of rhyme has not been as prevalent in Japanese or Korean poetry [23]. In fact, traditional Korean poetry did not incorporate this concept [24]. Despite the increasing tendency to adopt the concept of rhyme in Japanese and Korean lyrics due to intercultural exchanges, we observed that lyrics in these languages often rely more on repeating grammatical elements. For example, in section A1 of Table 3, the Japanese pair “tsukurou (作ろう, Let’s build)” and “asobou (遊ぼう, Let’s play)” generates a sense of rhyme because both end
with the same conjugation “ou” meaning “let’s”. Similarly, in Section A2, the Korean pair “mandeullae (만들래, Do you wanna build)” and “tallae (탈래, Do you wanna ride)” creates a sense of repetition because both end with “llae” meaning “Do you wanna”. Another example is the repetition of particles at the end of sentences, such as “yo (よ)” and “no (の)” in Japanese and “yo (요)” and “da (다)” in Korean, which convey cultural nuances related to formality. We therefore propose that English, Japanese, and Korean share common ground in adopting phoneme repetition for poetic expression. However, as such repetition is not necessarily called rhyme in Japanese and Korean, we will refrain from using the term “rhyme” and instead employ the term “phoneme repetition.”
We noticed that each section’s degree of phoneme repetition remains consistent across different languages when the lyrics are singable. For example, in Table 3, the first section of the original English lyrics (E(A1)) displays a strong degree of phoneme repetition, with three rhyming pairs: “come-come”, “play-away”, and “anymore-door” (In this paper, we denote a section as an uppercase with a number and a line as a lower case with a number). Similarly, both the Japanese and Korean translations (J(A1), K(A1)) also exhibit a substantial degree of phoneme repetition, featuring three pairs of repeated phonemes in each: “doa (ドア)”-“dou (どう)”, “tsukurou (作ろう)”-“asobou (遊ぼう)”, “akete (開けて)”-“shite (して)” in Japanese, and “gachi (같이)”-“gachi (같이)”, “mandeul (만들)”“eonnireul (언니를)”, “mandeullae (만들래)”-“simsimhae (심심해)” in Korean. However, we realized that it is not fair to directly compare the number of phoneme repetitions when attempting to quantify the degree of phoneme repetition as each language has a different number of vowels and consonants: English has 15 vowels and 24 consonants, whereas Japanese has 5 and 15 and Korean has 21 and 19. Hence, in an attempt to minimize the differences in the number of phonemes, we treated acoustically similar vowels as the same vowel in English, such as ‘IH’-‘IY’, ‘UH’-‘UW’, or ‘EH’-‘AE’(e.g., ’mass’ and ’mess’) [25] because they can still form slant rhymes [26]. Conversely, we considered ‘A’-‘YA’, ‘O’-‘YO’, and ‘U’-‘YU’ as sep-
arate vowels in Japanese, as they are unlikely to function as the same grammatical components. In Korean, we regarded the perceptually similar vowels (e.g., ‘AE’-‘E’or ‘OE’-‘OI’-‘OAE’) as the same vowels [27, 28]. To quantitatively represent the degree of phoneme repetition, we utilized the concept of distinct-2, the ratio of the number of distinct bi-grams to the total number of bigrams [29]. While the original concept formed bi-grams using two consecutive words, we used two consecutive phonemes to assess the degree of repetition because lower distinct-2 values indicate higher repetition and vice versa. The phoneme distinct-2 (pho) of a section Xi, is defined as follows:
pho(Xi) = unique bi-gram # in Xi total bi-gram # in Xi . (2)
For example, consider a section with a single line “twinkle twinkle little star”, denoted as X1. First, we decomposed the section into phonemes and added the ‘<eos>’to each line: ‘T’, ‘W’, ‘IH’, ‘NG’, ‘K’, ‘AH’, . . . , ‘S’, ‘T’, ‘AA’, ‘R’, and ‘<eos>’. Next, we grouped each component into bi-grams: ‘TW’, ‘WIH’, ‘IHNG’, ‘NGK’, ‘KAH’, ‘AHL’, . . . , ‘ST’, ‘TAA’, ‘AAR’, ‘R<eos>’. Finally, we calculated the phoneme distinct-2 of the section (pho(X1)) by dividing the number of unique bi-grams by the total number of bi-grams (17/23 = 0.74). To measure the similarity between two sections in terms of the degree of phoneme repetition, we introduce the phoneme repetition similarity (Simpho). Given two sets of lyrics with m sections, X = {X1, ..., Xm} and X̃ = {X̃1, ..., X̃m}, the phoneme repetition similarity between X and X̃ is defined as the Spearman correlation between {pho(X1), ..., pho(Xm)} and {pho(X̃1), ..., pho( ˜Xm)}, as shown below. Simpho(X, X̃) = corr({pho(X1), ..., pho(Xm)}, {pho(X̃1), ..., pho(X̃m)}) (3) We present the statistical results for the average phoneme repetition similarity of singable and non-singable lyrics in Table 4. The table clearly exhibits a higher correlation between the original lyrics and singable translated lyrics in terms of the phoneme distinct-2 than non-singable lyrics. This result suggests that singable lyric translation takes into account the degree of phoneme repetition within each section to convey a sense of repetition for that section. 4.3 musical structure distance Upon examining our section-divided singable lyrics data, we identified two tendencies in lyrics when musical sections
are repeated (e.g., the repetition of the chorus). First, we observed that musically similar sections tend to share the same phonemes and, as expected, the same phrases. For instance, in Table 3, musically similar sections share the same vowels (e.g., “why” in E(B1) and “by” in E(B2)) or identical phrases (e.g., “Do you wanna build a snowman” in E(A1) and E(A2)) in order to create a sense of consistency. As a result, when calculating the phoneme distinct-2 (pho) for two concatenated sections, musically similar sections are likely to have smaller values than musically different sections. For example, pho(E(A1 ++A2)) is 0.70 (‘++’ denotes the concatenation of text), whereas pho(E(A1++B1)) is 0.82, where A1 is musically similar to A2 but not to B1. However, a low value of pho does not always imply musical similarity, as a meager pho value in one section could result in a low pho of two concatenated sections despite the musical dissimilarity (e.g., “lalalalalalalalalalalalalala” ++ “do you wanna build a snowman?”). From this case, we derived our second observation that a significant difference in pho for each section could imply musical differences. Accordingly, we also realized that musically similar sections tend to have a similar degree of pho. For instance, in Table 3, both A1 and A2, a set of musically similar sections, exhibit relatively low pho, indicating a strong degree of phoneme repetition (rhyme), with similar values to each other across all languages. Likewise, both B1 and B2, another pair of musically similar sections, demonstrate a higher pho, with similar values to each, in all languages. Therefore, to quantify the musical similarity between sections, we examined whether they have 1) a tendency to share the same phoneme by obtaining pho(Xi++Xj), and 2) similar pho values by calculating |pho(Xi)− pho(Xj)|. Given that higher values represent dissimilarity in both cases, we define the musical dissimilarity between two sections, diss(Xi, Xj), as the sum of these two values, as follows. diss(Xi, Xj) = pho(Xi++Xj) + |pho(Xi)− pho(Xj)| (4)
As shown in Figure 1, self-dissimilarity matrices employing our definition of musical dissimilarity look highly similar across English, Japanese, and Korean, where all are singable, visually representing musical structure. Finally, we quantitatively evaluated the distance between matrices. We refer to this distance between matrices as the musical structure distance, as it represents the structural element of lyrics. In summary, the musical structure distance
between lyrics in different languages X and X̃, each consisting of m sections, Dismus(X, X̃), is defined as follows:
Dismus(X, X̃) = 1
m2 √∑m i,j=1 (diss(Xi, Xj)− diss(X̃i, X̃j))2
(5) In Table 5, we provide a summary of the average musical structure distance for singable lyrics, human-translated nonsingable lyrics, and machine-translated non-singable lyrics generated by automatically translating official singable lyrics from 80 English, 162 Japanese, and 161 Korean songs using Google Translator. Our findings show that singable lyrics exhibit the lowest Dismus values, while machine-translated non-singable lyrics display the highest, suggesting that machine-translated ones lack structural coherence the most. As human-translated non-singable lyrics maintain structural coherence in aspects such as word choice and nuances, they demonstrate lower distances than machine-translated counterparts. 5. evaluating semantics Semantic relatedness to the original lyrics is by no means less fundamental than syllable counts, phoneme repetition, and structural factors [18]. We therefore introduce a fourth metric, semantic similarity, to ensure the semantic relevance of translated lyrics to the original. 5.1 semantic similarity To numerically assess the semantic textual similarity (sts) between a pair of lyrics, we first obtained the contextual embeddings of each text from lyrics using a pre-trained Sentence BERT model 1 [31] and then calculated the cosine similarity between the embeddings. As this model was trained for English, the Japanese and Korean lyrics were automatically translated using Google Translator before obtaining the embeddings. We started by examining hierarchical semantic similarity using cross-scape plots [32], as shown in Figure 2. Given a pair of lyrics X = {x1, . . . , xn} and X̃ = {x̃1, . . . , x̃n} with n lines each, the first (leftmost) block of the lowest line represents the semantic textual similarity between x1 and x̃1 (denoted as sts(x1, x̃1)) while the last (rightmost) block signifies sts(xn, x̃n). The first (leftmost) block of the second-lowest line denotes sts(x1++x2, x̃1++x̃2), and the second block corresponds to sts(x2++x3, x̃2++x̃3). Lastly,
1 We used all-MiniLM-L6-v2 [30]. the highest block (line) represents the similarity between the entire lyrics, sts(x1 ++ · · ·++ xn, x̃1 ++ · · ·++ x̃n). In each plot of Figure 2, there are semantic disparities at lower levels, but similarities increase at higher (broader) levels. We have two explanations for this. First, the number of musical notes within a single lyric line may be adequate to deliver a specific message in one language but insufficient in another language. Therefore, it is common for a message conveyed in one line in one language to span two lines in another language. As an example, we provide Table 6, which presents the semantic textual similarity (sts) between Japanese and English lyrics of the J-pop song “A Thousand Winds (千の風になって)”. As demonstrated in the table, the similarity between Japanese and English at a broader level (sts(x1++x2, x̃1++x̃2)) can be higher than at the line level (sts(x1, x̃1), sts(x2, x̃2)) because Japanese generally requires more syllables than English and it often takes two lines in Japanese to express a single-line message in English. Second, the semantic similarities at broader levels can be higher because of grammatical/linguistic differences. Each language has its own natural word order patterns. For example, in the phrase “I’m going to travel to find the gold,” it is natural in English to mention “I’m going to travel” before “to find the gold.” However, in Japanese and Korean, expressing “to find the gold (金を探しに,금을찾으러)” before “I’m going to travel (旅に出る,떠난다)” is a more typical and natural construction. Table 7 shows that these differences between languages make line-level semantic assessments insufficient. Since lines 1, 2, and 3 in the English version correspond to lines 3, 1, and 2 respectively in the Japanese version, these pairs exhibit low semantic similarities at the line level (sts(x1, x̃1), sts(x2, x̃2), sts(x3, x̃3)), while demonstrating higher similarity when considered as a whole (sts(x1++x2++x3, x̃1++x̃2++x3)). Considering these factors, it becomes evident that
Line # English
Japanese (English translation) sts
1 Dare to try and reach out for hеaven
望むように生きるなら (If you want to become what you’re meant to be) 0.22
2 You must become what you’rе meant to be
星からの金を求め (to find the gold from stars) 0.27
3 And bring the gold of heaven to the world
一人旅に出るのよ (Dare to embark on a solo journey) 0.13
1-3 Dare to try and reach out for hеaven You must become what you’rе meant to be And bring the gold of heaven to the world 望むように生きるなら星からの 金を求め一人旅に出るのよ (Dare to embark on a solo journey if you want to become what you’re meant to be to find the gold from stars) 0.53
Table 7. Semantic textual similarity (sts) between English and Japanese versions of “Gold von den Sternen”. Figure 3. The line-wise (Left) and section-wise (Right) semantic similarity matrices between Japanese and Korean versions of “Wie wird man seinen Schatten los?”
singable lyric translations do not prioritize line-wise semantic similarity. Rather, we observed that singable translations aim to preserve semantic connections at the section level since the organization of the lyric storyline follows a sectionwise approach. To illustrate this, we present Figure 3, which displays both line-wise and section-wise semantic similarity matrices for the Japanese and Korean versions of “How do you get rid of your shadow? (Wie wird man seinen Schatten los? )” from the German musical “Mozart!”. As shown in the Figure, the section-wise matrix represents the semantic relatedness more clearly than the line-wise matrix. Therefore, we propose assessing section-wise semantic relatedness for evaluating singable lyric translation. To achieve this, we define the semantic similarity between a pair of lyrics X = {X1, ..., Xm} and X̃ = {X̃1, ..., X̃m}, consisting of m sections and n = n(X1) + · · · + n(Xm) lines, where n(Xi) denotes the number of lines in the i-th section, as follows:
Simsem(X, X̃) = ∑m i=1( n(Xi) n sts(Xi, X̃i)). (6)
Table 8 compares singable and non-singable lyrics in terms of line-wise semantic similarities ( 1n ∑n i=1 sts(xi, x̃i)) and section-wise similarities, using our proposed metric (Simsem). The table reveals that non-singable translations exhibit high semantic similarity for both line-wise and section-wise measures, with similar values for each. In contrast, singable translations show low line-wise similarity, as expected, since they do not prioritize line-wise semantic similarity. However, when evaluated using section-wise similarity, they display a level of similarity comparable to that between “Machine learning is so easy” and “Deep learning is so straightforward”, which is 0.623 when measured with the same pre-trained model [30]. 6. discussions and conclusions In this paper, we introduced a computational evaluation framework for singable lyric translation, grounded in the musical, linguistic, and cultural understanding of lyrics, comprised of four evaluation metrics, line syllable count distance (Dissyl), phoneme repetition similarity (Simpho), musical structure distance (Dismus), and semantic similarity (Simsem). These metrics are designed to ensure that the translated lyrics maintain the integrity of melodies, degree of phoneme repetition, structural coherence, and semantics of the original lyrics. Our framework is automated, guaranteeing objectivity and efficiency in terms of time and cost. We showed the efficacy of our evaluation metrics by offering comparative statistics between singable and nonsingable lyrics. In addition, our analysis revealed that the degree of phoneme repetition in the original lyrics is frequently mirrored in the translated lyrics, musically similar sections tend to share the same phonemes and display comparable degrees of phoneme repetition, and section-wise analysis is better suited for evaluating semantic similarity for lyric translation than line-wise analysis. Nonetheless, there remains room for improvement. Although we have assembled a singable lyrics dataset, aligned across English, Japanese, and Korean, our dataset has some limitations; it lacks musical information and its volume is limited. As a result, we have not been able to incorporate musical notes into our experiment or conduct comparative studies across various genres. We recognize that an ideal lyric translation evaluation system should take into account the relationship between musical notes and phonemes, as well as adapt to different genres. Moreover, although we have endeavored to incorporate cultural understandings of poetry in different languages. For example, we noticed that cultural similarities might have an impact on the extent of semantic similarities. This is demonstrated in an English translation of “MIC Drop”, a K-pop song by BTS originally written in Korean, made by YouTuber Iris Phuong. The translated singable lyrics do not include a translation of the term “hyodo (효도, taking care of parents)” as there is no direct equivalent in English, while the Japanese version of the song effortlessly conveys the concept